<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Debian 10挂载加swap</title>
    <url>/2023/111727163.html</url>
    <content><![CDATA[<p>以根目录挂载为4G例：<br>dd if=/dev/zero of=/swapfile count=4096 bs=1M</p>
<p>ls / | grep swapfile<br>chmod 600 /swapfile<br>ls -lh /swapfile<br>-rw——- 1 root root 4.0G Aug 17 12:14 /swapfile<br>通过运行以下命令告诉服务器设置swap文件：<br>mkswap /swapfile<br>swapon /swapfile<br>free -m<br>vi /etc/fstab<br>/swapfile swap swap defaults 0 0<br>保存。</p>
]]></content>
      <categories>
        <category>系统</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title>Centos同时安装python2和python3</title>
    <url>/2023/11203350.html</url>
    <content><![CDATA[<p>   在centos中，自带有python2，因此需要经常安装python3。但是这里有一个坑，就是centos的yum是用python2写的，如果正常编译安装python3，那么yum就会直接挂了。为了方便以后编译安装python3，不用天天去网上找教程仅供参考。</p>
<p>首先连上服务器，看下python版本：</p>
<p> python -V</p>
<p>centos默认带有python2.7.5：</p>
<p>接下来我们开始安装python3。</p>
<p>1 安装python3所需要的组件</p>
<p>yum -y install zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel gcc make wget libffi-devel</p>
<p>2 备份现有的python2</p>
<p>cd /usr/bin</p>
<p>mv python python.bak</p>
<p>mv pip pip.bak</p>
<p>不用猜当前yum肯定挂了不能用了。</p>
<ol start="3">
<li><p>卸载python3.6.5</p>
<p>在这里去python的官网，找到需要的python版本链接，然后通过wget方式直接下载到linux服务器，当然你也可以从浏览器下载，然后上传到linux服务器。</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">cd /usr/local/</span><br><span class="line">wget https://www.python.org/ftp/python/3.6.5/Python-3.6.5.tar.xz</span><br></pre></td></tr></tbody></table></figure>

<p>tar -xvJf Python-3.6.5.tar.xz</p>
<p>cd Python-3.6.5</p>
<p>指定安装路径</p>
<p>./configure –prefix=/usr/local/python3 –enable-optimizations</p>
<p>编译并安装</p>
<p>make &amp;&amp; make install</p>
<p>最后显示Successfully installed pip-9.0.3 setuptools-39.0.1</p>
<p>修改软连接，将python3指向python，顺便把pip也重新指向：</p>
<p>ln -s /usr/local/python3/bin/python3 /usr/bin/python</p>
<p>ln -s /usr/local/python3/bin/pip3 /usr/bin/pip</p>
<p>查看版本号：</p>
<p>[root@localhost /home/tools/Python-3.6.5]$python -V<br>Python 3.6.5<br>[root@localhost /home/tools/Python-3.6.5]$python2 -V<br>Python 2.7.5</p>
<p>4.修改yum配置：</p>
<p>装完了python3之后，我们要修一下yum了，不然以后都没法装软件和环境了。</p>
<p>vim /usr/bin/yum</p>
<p>把头部的 #! /usr/bin/python 修改为 #! /usr/bin/python2  修改保存。</p>
<p>vim /usr/libexec/urlgrabber-ext-down</p>
<p>#! /usr/bin/python修改为#! /usr/bin/python2 保存退出。</p>
<p>至此，yum 可以正常使用了。</p>
</li>
</ol>
]]></content>
  </entry>
  <entry>
    <title>Debian10 安装ossfs</title>
    <url>/2023/111750151.html</url>
    <content><![CDATA[<p>1.<br>sudo apt-get install automake autotools-dev g++  git libcurl4-gnutls-dev libfuse-dev libssl-dev libxml2-dev  make pkg-config<br>2.<br>git clone <a href="https://github.com/aliyun/ossfs.git">https://github.com/aliyun/ossfs.git</a><br>cd ossfs/<br> ./autogen.sh<br>  ./configure<br>Sudo   make<br> Sudo make install<br>3.配置bucket信息和accessKey信息：<br>echo Bucket名称:要是用的AccessKeyId:对应的AccessKeySecret  &gt; /etc/passwd-ossfs<br>示例：<br>mkdir -p /data/ossfs<br>cosfs examplebucket-1250000000 /data/ossfs -ourl=<a href="http://cos.ap-guangzhou.myqcloud.com/">http://cos.ap-guangzhou.myqcloud.com</a> </p>
<p>ossfs ts-1121-patch-oss  /data/ossfs/ -ourl=<a href="https://oss-cn-hangzhou-internal.aliyuncs.com/">https://oss-cn-hangzhou-internal.aliyuncs.com</a> -oallow_other</p>
<p>其中：<br><mountpoint> 为本地挂载目录（例如/mnt）。<br><region> 为地域简称， 例如 ap-guangzhou 、 eu-frankfurt 等。更多地域简称信息，请参见 可用地域。<br>-odbglevel 指定日志级别，默认为crit，可选值为crit、error、warn、info、debug。<br>-oallow_other 允许非挂载用户访问挂载文件夹。</region></mountpoint></p>
<p>创建启动脚本：<br>Vim /etc/init.d/ossfs<br>ossfs demo-patch-oss /data/ossfs/ -ourl=oss-cn-hangzhou-internal.aliyuncs.com -oallow_other<br>Chmod u+x /etc/init.dossfs</p>
<p>Centos：<br>chkncondif ossf on<br>Debian;<br>update-rc.d  ossfs  defaults</p>
]]></content>
      <categories>
        <category>系统</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title>Rsync同步文件</title>
    <url>/2023/081064777.html</url>
    <content><![CDATA[<p>Rsync常用的一款同步文件工具。配置也很方便。</p>
<p>&nbsp;</p>
<p>yum install sync -y或者apt-get install sync</p>
<ul>
<li>服务安装好之后，/etc下没有配置文件，一般情况可以copy示例文件到/etc下</li>
</ul>
<p>&nbsp;</p>
<p>#cp&nbsp;/usr/share/doc/rsync/examples/rsyncd.conf&nbsp;/etc</p>
<p>&nbsp;</p>
<p>vim /etc/rsyncd.conf</p>
<p>uid = common</p>
<p>gid = common</p>
<p>use chroot = no</p>
<p>max connections = 10</p>
<p>strict modes = yes</p>
<p>hosts allow = 192.168.2.12&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; #可以空格，允许多个</p>
<p>hosts deny = *</p>
<p>port = 5699&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;#默认开启端口</p>
<p>pid file = /var/run/rsyncd.pid</p>
<p>lock file = /var/run/rsync.lock</p>
<p>log file = /var/log/rsyncd.log</p>
<p>[hmt]</p>
<p>path = /data/www/html/</p>
<p>comment = hello</p>
<p>ignore errors</p>
<p>read only = no</p>
<p>write only = no</p>
<p>hosts allow = 192.168.2.12&nbsp;</p>
<p>list = false</p>
<p>auth users = hmt</p>
<p>secrets file = /etc/rsync.password</p>
<ul>
<li>建立/etc/rsyncd/rsyncd.secrets文件</li>
</ul>
<p>#vim /etc/rsync.password</p>
<p>#cat /etc/rsyncd/rsyncd.secrets</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;hmt:123456</p>
<ul>
<li>为了密码的安全性，我们必须把权限设为600</li>
</ul>
<p> chown root:root /etc/rsyncd/rsyncd.secrets</p>
<p>chmod 600&nbsp;&nbsp;/etc/rsync.password</p>
<p> chmod 600&nbsp;/etc/rsyncd/rsyncd.secrets</p>
<p> vim /etc/rsyncd/rsyncd.motd</p>
<p>&nbsp;</p>
<p>启动rsync：</p>
<p>systemctl start rsyncd.service</p>
<p>&nbsp;lsof -i:5699</p>
<p>lsof -i:5699</p>
<p>COMMAND PID USER&nbsp; &nbsp;FD&nbsp; &nbsp;TYPE&nbsp; &nbsp;DEVICE SIZE/OFF NODE NAME</p>
<p>rsync&nbsp; &nbsp;750 root&nbsp; &nbsp; 4u&nbsp; IPv4 22661487&nbsp; &nbsp; &nbsp; 0t0&nbsp; TCP *:5699 (LISTEN)</p>
<p>rsync&nbsp; &nbsp;750 root&nbsp; &nbsp; 5u&nbsp; IPv6 22661488&nbsp; &nbsp; &nbsp; 0t0&nbsp; TCP *:5699 (LISTEN)</p>
<p>至此服务器端安装完毕；</p>
<p>客户端安装配置：</p>
<p>&nbsp;</p>
<p>yum -y install rsync</p>
<p>&nbsp;客户端需要vim&nbsp;/etc/rsync.password&nbsp;</p>
<p>cat&nbsp;&nbsp;/etc/rsync.password</p>
<p>123456</p>
<p>运行：</p>
<p>rsync -avz –port 5699 –password-file=/etc/rsync.password <a href="mailto:hmt@192.168.2.12">hmt@192.168.2.12</a>::hmt&nbsp; /data/www/html</p>
<p>Password: 这里要输入rsync的密码，是服务器端提供的，在前面的例子中，我们用的是 asdf，输入的密码并不显示出来；输好后就回车；&nbsp;注：&nbsp;这个命令的意思就是说，用rsync 用户登录到服务器上，把/data/www/html&nbsp;数据，同步到本地目录/data/www/html/上。当然本地的目录是可以你自己定义的，比如 dave也是可以的；当你在客户端上，当前操作的目录下没有/tmp/test/这个目录时，系统会自动为你创建一个；当存在/tmp/test/这个目录中，你要注意它的写权限。</p>
<p>参数说明：</p>
<p>&nbsp;-a 参数，相当于-rlptgoD，</p>
<p>&nbsp;&nbsp;&nbsp;-r 是递归 -l 是链接文件，意思是拷贝链接文件；</p>
<p>&nbsp;&nbsp;&nbsp;-p 表示保持文件原有权限；</p>
<p>&nbsp;&nbsp;&nbsp;-t 保持文件原有时间；<br>&nbsp;&nbsp;&nbsp;-g 保持文件原有用户组；</p>
<p>&nbsp;&nbsp;&nbsp;-o 保持文件原有属主；</p>
<p>&nbsp;&nbsp;&nbsp;-D 相当于块设备文件；</p>
<p>&nbsp;&nbsp;&nbsp;-z 传输时压缩；</p>
<p>&nbsp;&nbsp;&nbsp;-P 传输进度；</p>
<p>&nbsp;&nbsp;&nbsp;-v 传输时的进度等信息，和-P有点关系</p>
<p>&nbsp;<br>*</p>
<p>rsync -avzP &nbsp;–delete <a href="mailto:rsync@192.168.2.150">rsync@192.168.2.150</a>::hometools&nbsp;/tmp/test/</p>
<p>–delete 选项，表示服务器上的数据要与客户端完全一致，如果 /tmp/test/目录中有服务器上不存在的文件，则删除。最终目的是让/tmp/test/目录上的数据完全与服务器上保持一致；用的时候要小心点，最好不要把已经有重要数所据的目录，当做本地更新目录，否则会把你的数据全部删除；
&nbsp;</p>
<p>计划任务同步：</p>
<p>*/5 * * * * rsync -zvaP <a href="mailto:rsync@192.168.2.150">rsync@192.168.2.150</a>::hometools /tmp/test/ –password-file=/etc/rsyncd/rsyncd.secrets</p>
<p>*/5 * * * * rsync -avz –port 5699 –password-file=/etc/rsync.password <a href="mailto:hmt@192.168.2.12">hmt@192.168.2.12</a>::hmt&nbsp; /data/www/html</p>
<p>&nbsp;</p>
]]></content>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title>Tengine 安装</title>
    <url>/2023/111458217.html</url>
    <content><![CDATA[<p>Tengine安装</p>
<p>Tengine 是由淘宝网发起的 Web 服务器项目。它在 Nginx 的基础上，针对大访问量网站的需求，添加了很多高级功能和特性。Tengine 的性能和稳定性已经在大型的网站如淘宝网，天猫商城等得到了很好的检验。它的最终目标是打造一个高效、稳定、安全、易用的 Web 平台。</p>
<p>Tengine 特性：</p>
<p>支持 HTTP 的 CONNECT 方法，可用于正向代理场景；</p>
<p>支持异步 OpenSSL，可使用硬件如：QAT 进行 HTTPS 的加速与卸载；</p>
<p>增强相关运维、监控能力，比如异步打印日志及回滚，本地 DNS 缓存，内存监控等；</p>
<p>Stream 模块支持 server_name 指令；</p>
<p>更加强大的负载均衡能力，包括一致性 hash 模块、会话保持模块，还可以对后端的服务器进行主动健康检查，根据服务器状态自动上线下线，以及动态解析 upstream 中出现的域名；</p>
<p>输入过滤器机制支持。通过使用这种机制 Web 应用防火墙的编写更为方便；</p>
<p>支持设置 proxy、memcached、fastcgi、scgi、uwsgi 在后端失败时的重试次数；</p>
<p>动态脚本语言 Lua 支持。扩展功能非常高效简单；</p>
<p>支持按指定关键字(域名，url等)收集 Tengine 运行状态；</p>
<p>组合多个 CSS、JavaScript 文件的访问请求变成一个请求；</p>
<p>自动去除空白字符和注释从而减小页面的体积</p>
<p>自动根据 CPU 数目设置进程个数和绑定 CPU 亲缘性；</p>
<p>监控系统的负载和资源占用从而对系统进行保护；</p>
<p>显示对运维人员更友好的出错信息，便于定位出错机器；；</p>
<p>更强大的防攻击（访问速度限制）模块；</p>
<p>更方便的命令行参数，如列出编译的模块列表、支持的指令等；</p>
<p>支持 Dubbo 协议；</p>
<p>可以根据访问文件类型设置过期时间；</p>
<p>下载源码包：</p>
<p>tengine 源码：<a href="http://tengine.taobao.org/download_cn.html">http://tengine.taobao.org/download_cn.html</a></p>
<p>pcre 源码：<a href="http://www.pcre.org/">http://www.pcre.org/</a></p>
<p>openssl 源码：<a href="https://www.openssl.org/source/">https://www.openssl.org/source/</a></p>
<p>zlib 源码：<a href="http://www.zlib.net/">http://www.zlib.net/</a></p>
<p>安装包：</p>
<p>支持lua模块</p>
<p>wget <a href="http://luajit.org/download/LuaJIT-2.0.4.tar.gz">http://luajit.org/download/LuaJIT-2.0.4.tar.gz</a></p>
<p>#wget <a href="https://github.com/simpl/ngx_devel_kit/archive/v0.3.0.tar.gz">https://github.com/simpl/ngx_devel_kit/archive/v0.3.0.tar.gz</a></p>
<p>#wget <a href="https://github.com/openresty/lua-nginx-module/archive/v0.10.13.tar.gz">https://github.com/openresty/lua-nginx-module/archive/v0.10.13.tar.gz</a></p>
<p>安装LuaJIT</p>
<p>tar xf LuaJIT-2.0.4.tar.gz</p>
<p>#cd xf LuaJIT-2.0.4</p>
<p>#make PREFIX=/usr/local/luajit</p>
<p>#make install PREFIX=/usr/local/luajit</p>
<p>#ln -s /usr/local/luajit/lib/libluajit-5.1.so.2 /lib64/libluajit-5.1.so.2</p>
<p>添加环境变量</p>
<p>export LUAJIT_LIB=/usr/local/luajit/lib</p>
<p>export LUAJIT_INC=/usr/local/luajit/include/luajit-2.0</p>
<p>#source /etc/profile</p>
<p>安装tingine</p>
<p>#tar xf v0.3.0.tar.gz</p>
<p>#tar xf v0.10.13.tar.gz</p>
<p>#tar xf nginx-1.12.0.tar.gz</p>
<p>debain 环境下安装：<br>sudo apt-get install -y  openssl libssl-dev<br>sudo apt-get install  -y libpcre3 libpcre3-dev<br>apt-get install  -y zlib1g-dev<br>Centos环境下安装：<br>yum -y update &amp;&amp; yum install -y gcc wget tree pcre-devel <br>zlib-devel openssl openssl-devel <br>libxml2 libxml2-dev libxslt-devel gd-devel <br>ncurses-devel perl perl-ExtUtils-Embed <br>gperftools </p>
<p>cd tengine-2.2.2</p>
<p> ./configure –conf-path=/etc/nginx/nginx.conf –user=www-data –group=www-data –prefix=/etc/nginx –sbin-path=/usr/sbin/nginx –with-ipv6  –error-log-path=/var/log/nginx/error.log –http-log-path=/var/log/nginx/access.log  –pid-path=/var/run/nginx.pid –lock-path=/var/lock/nginx.lock –http-client-body-temp-path=/var/cache/nginx/client_temp  –http-proxy-temp-path=/var/cache/nginx/proxy_temp –http-fastcgi-temp-path=/var/cache/nginx/fastcgi_temp  –http-uwsgi-temp-path=/var/cache/nginx/uwsgi_temp –http-scgi-temp-path=/var/cache/nginx/scgi_temp  –without-select_module –without-http_uwsgi_module –without-http_empty_gif_module –with-http_ssl_module –with-http_addition_module  –with-http_sub_module –with-http_dav_module –with-http_flv_module –with-http_gunzip_module  –with-http_gzip_static_module –with-http_random_index_module  –with-http_secure_link_module –with-http_stub_status_module –with-http_realip_module  –with-http_concat_module=shared –with-http_sysguard_module=shared  –with-http_dyups_module –with-file-aio –add-module=../ngx_devel_kit-0.3.0/  –add-module=../lua-nginx-module-0.10.13/ \</p>
<p>Make </p>
<p>Make install</p>
<p>Make会报错：cc1: all warnings being treated as errors</p>
<p>make[1]: *** [objs/Makefile:617: objs/src/core/ngx_murmurhash.o] Error 1</p>
<p>make[1]: Leaving directory ‘/home/tools/install/tengine-2.2.2’</p>
<p>vim objs/Makefile：</p>
<p>CFLAGS =  -pipe  -O -W -Wall -Wpointer-arith -Wno-unused -Werror -g  -DNDK_SET_VAR</p>
<p> -Werror -g去掉</p>
<p>CFLAGS =  -pipe  -O -W -Wall -Wpointer-arith -Wno-unused  -DNDK_SET_VAR</p>
<p>sed -i “s/ -Werror -g / /g” ./objs/Makefile<br>make &amp;&amp; make install<br>echo <code>nginx -v</code></p>
<p>#不显示版本号<br>sed -i “/server_tokens off;/a server_tag off; \n server_info off;” nginx.conf<br>mkdir -p /var/cache/nginx/scgi_temp<br>chown www-data.root /var/cache/nginx/scgi_temp</p>
<p>添加系统服务：</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">cat &gt;&gt;/etc/systemd/system/nginx.service &lt;&lt;EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=The nginx HTTP and reverse proxy server</span><br><span class="line">After=syslog.target network.target remote-fs.target nss-lookup.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=forking</span><br><span class="line">PIDFile=/var/run/nginx.pid</span><br><span class="line">ExecStartPre=/usr/sbin/nginx -t -c /etc/nginx/nginx.conf</span><br><span class="line">ExecStart=/usr/sbin/nginx -c /etc/nginx/nginx.conf</span><br><span class="line">ExecReload=/usr/sbin/nginx -s reload</span><br><span class="line">ExecStop=/usr/sbin/nginx -s stop</span><br><span class="line">ExecQuit=/usr/sbin/nginx -s quit</span><br><span class="line">PrivateTmp=true</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></tbody></table></figure>

<p>后续就是优化配置了。</p>
]]></content>
      <categories>
        <category>系统</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title>ELK安装调试及遇到的问题</title>
    <url>/2023/111459226.html</url>
    <content><![CDATA[<h1 id="1-前期准备："><a href="#1-前期准备：" class="headerlink" title="1.前期准备："></a>1.前期准备：</h1><p>如果是es非root用户启动es，可以把*改成非root用户，例如 es soft nofile 65535修改 /etc/security/limits.conf</p>
<p>在文件末尾中增加下面内容# 每个进程可以打开的文件数的限制* soft nofile 65536* hard nofile 65536</p>
<p>修改/etc/security/limits.d/20-nproc.conf</p>
<p>在文件末尾中增加下面内容# 每个进程可以打开的文件数的限制* soft nofile 65536* hard nofile 65536# 操作系统级别对每个用户创建的进程数的限制* hard nproc 4096# 注： * 带表 Linux 所有用户名称</p>
<p>修改 /etc/sysctl.conf</p>
<p>在文件中增加下面内容# 一个进程可以拥有的 VMA(虚拟内存区域)的数量,默认值为 65536</p>
<p>vm.max_map_count=655360</p>
<h1 id="2-ELK组建安装："><a href="#2-ELK组建安装：" class="headerlink" title="2.ELK组建安装："></a>2.ELK组建安装：</h1><p>导入官网秘钥</p>
<p>rpm –import   <a href="https://artifacts.elastic.co/GPG-KEY-elasticsearch">https://artifacts.elastic.co/GPG-KEY-elasticsearch</a></p>
<p>vim  /etc/yum.repos.d/elasticsearch.repo</p>
<p>[elasticsearch-7.x]</p>
<p>name=Elasticsearch repository for 7.x packages</p>
<p>baseurl=<a href="https://artifacts.elastic.co/packages/7.x/yum">https://artifacts.elastic.co/packages/7.x/yum</a></p>
<p>gpgcheck=1</p>
<p>gpgkey=<a href="https://artifacts.elastic.co/GPG-KEY-elasticsearch">https://artifacts.elastic.co/GPG-KEY-elasticsearch</a></p>
<p>enabled=1</p>
<p>autorefresh=1</p>
<p>type=rpm-md</p>
<p>yum install elasticsearch kibana logstash   -y</p>
<p>systemctl restart elasticsearch</p>
<p>systemctl enable elasticsearch</p>
<p>设置各类应用密码</p>
<p>/usr/share/elasticsearch/bin/elasticsearch-setup-passwords interactive</p>
<p>elastic 用户为超级管理员</p>
<p>systemctl restart kibana</p>
<p>systemctl enable kibana</p>
<p>systemctl restart logstash.service</p>
<p>systemctl enable logstash.service</p>
<p>Vim etc/elasticsearch/elasticsearch.yml</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">path.data: /data/elk/elasticsearch</span><br><span class="line">#path.data: /var/lib/elasticsearch</span><br><span class="line"></span><br><span class="line"># Path to log files:</span><br><span class="line">#</span><br><span class="line">path.logs: /data/elk/elasticsearch/logs</span><br><span class="line">#path.logs: /var/log/elasticsearch</span><br><span class="line"></span><br><span class="line">#置集群的名称</span><br><span class="line">cluster.name: elasticsearch</span><br><span class="line"> # 当前节点的名称</span><br><span class="line">node.name: node-1</span><br><span class="line"></span><br><span class="line"> # 绑定IP地址，外网访问0.0.0.0 否则绑定localhost</span><br><span class="line">network.host: 0.0.0.0</span><br><span class="line">http.port: 9200</span><br><span class="line"> # 允许跨域请求</span><br><span class="line">http.cors.enabled: true</span><br><span class="line">http.cors.allow-origin: "*"</span><br><span class="line">http.cors.allow-headers: Authorization,X-Requested-With,Content-Length,Content-Type</span><br><span class="line"> # 访问需要密码</span><br><span class="line">xpack.security.enabled: true</span><br><span class="line">xpack.security.transport.ssl.enabled: true</span><br><span class="line"></span><br><span class="line"> # 初始化，必须要配置</span><br><span class="line">cluster.initial_master_nodes: ["node-1"]</span><br><span class="line"># ----------------------------------- Memory -----------------------------------</span><br><span class="line">xpack.security.transport.ssl.verification_mode: certificate</span><br><span class="line">xpack.security.transport.ssl.keystore.path: cert/elastic-certificates.p12</span><br><span class="line">xpack.security.transport.ssl.truststore.path: cert/elastic-certificates.p12</span><br><span class="line"># Lock the memory on startup:</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>

<p>vim /etc/kibana/kibana.yml</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">server.port: 5601</span><br><span class="line"> # 绑定IP</span><br><span class="line">server.host: "0.0.0.0"</span><br><span class="line"> # </span><br><span class="line">elasticsearch.hosts: ["http://192.168.8.6:9200"]</span><br><span class="line"></span><br><span class="line"> # 访问密码,这里等下要设置,先配置好</span><br><span class="line">elasticsearch.username: "elastic"</span><br><span class="line">elasticsearch.password: "elastic"</span><br><span class="line">xpack.monitoring.enabled: true</span><br><span class="line"> # 界面使用中文</span><br><span class="line">i18n.locale: "zh-CN"</span><br><span class="line"># Enables you to speci</span><br></pre></td></tr></tbody></table></figure>

<p>vim  /etc/logstash/logstash.yml</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">path.data: /data/elk/logstash</span><br><span class="line">http.host: "0.0.0.0"</span><br><span class="line">#http.port: 5044</span><br><span class="line"></span><br><span class="line"># 访问需要验证, 先配置，等下设置密码</span><br><span class="line">xpack.monitoring.enabled: true</span><br><span class="line">xpack.monitoring.elasticsearch.username: elastic</span><br><span class="line">xpack.monitoring.elasticsearch.password: elastic</span><br><span class="line">xpack.monitoring.elasticsearch.hosts: ["http://192.168.8.6:9200"]</span><br><span class="line"># ------------ Pipeline Settings --------------</span><br><span class="line">#</span><br><span class="line">api.http.port: 9600-9700</span><br><span class="line">#</span><br><span class="line">#</span><br><span class="line">log.level: debug</span><br><span class="line">#log.level: info</span><br><span class="line">path.logs: /data/elk/logstash/logs</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>

<p>Vim pipelines.yml</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">- pipeline.id: main</span><br><span class="line">  path.config: "/etc/logstash/conf.d/*.conf"</span><br></pre></td></tr></tbody></table></figure>



<p>控制web页面使用的功能：</p>
<p>xpack.apm.enabled: false            设置为false禁用X-Pack性能管理功能。</p>
<p>xpack.graph.enabled: false          设置为false禁用X-Pack图形功能。</p>
<p>xpack.ml.enabled: false             设置为false禁用X-Pack机器学习功能。</p>
<p>xpack.monitoring.enabled: false     设置为false禁用X-Pack监视功能。</p>
<p>xpack.reporting.enabled: false      设置为false禁用X-Pack报告功能。</p>
<p>xpack.security.enabled: false       设置为false禁用X-Pack安全功能。（引起报错）</p>
<p>xpack.watcher.enabled: false        设置false为禁用观察器。</p>
<p><a href="https://www.elastic.co/guide/en/kibana/current/settings-xpack-kb.html">https://www.elastic.co/guide/en/kibana/current/settings-xpack-kb.html</a></p>
<p>调试的时候可能需要ES Head插件，curl -X GET “localhost:9200”</p>
<ol>
<li><p>确认Elasticsearch服务的运行状态：可以通过运行curl -X GET “localhost:9200”来检查Elasticsearch服务是否在运行，并检查是否能够从浏览器中访问到ES Head插件的界面。</p>
</li>
<li><p>检查ES Head插件的配置文件：确保您已经正确配置了ES Head插件，主要包括Elasticsearch服务器的地址和端口号等信息。您可以在ES Head插件的配置文件中查看并修改这些配置。</p>
</li>
<li><p>检查网络连接和防火墙设置：确保您的网络连接正常，并且没有遇到任何网络问题。如果您的计算机上运行有防火墙，您需要检查防火墙设置，确保允许ES Head插件与Elasticsearch服务器进行通信。</p>
</li>
<li><p>更新ES Head插件版本：如果您正在使用旧版本的ES Head插件，尝试将插件升级到最新版本，并确保与您正在使用的Elasticsearch服务器兼容。</p>
</li>
</ol>
<p>cd elasticsearch-head</p>
<p>///修改Gruntfile.js ， vi Gruntfile.js</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">connect: {</span><br><span class="line">			server: {</span><br><span class="line">				options: {</span><br><span class="line">					port: 9100,</span><br><span class="line">					hostname: "192.168.8.6",	</span><br><span class="line">					base: '.',</span><br><span class="line">					keepalive: true</span><br><span class="line">				}</span><br><span class="line">			}</span><br><span class="line">		}</span><br></pre></td></tr></tbody></table></figure>

<p>///修改elasticsearch-head默认连接地址，</p>
<p>cd elasticsearch-head/_site/</p>
<p>vi app.js</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">init: function(parent) {</span><br><span class="line">			this._super();</span><br><span class="line">			this.prefs = services.Preferences.instance();</span><br><span class="line">			this.base_uri = this.config.base_uri || this.prefs.get("app-base_uri") || "http://192.168.8.6:9200";</span><br><span class="line">			if( this.base_uri.charAt( this.base_uri.length - 1 ) !== "/" ) {</span><br><span class="line">				// XHR request fails if the URL is not ending with a "/"</span><br><span class="line">				this.base_uri += "/";</span><br><span class="line">			}</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>

<p>启动方式2种：</p>
<p>1:</p>
<p>cd elasticsearch-head</p>
<p>npm run start</p>
<p>2:</p>
<p>cd elasticsearch-head</p>
<p>node_modules/grunt/bin/grunt server</p>
<p>Debian 安装filebeat</p>
<p>获取filebeat安装包密钥</p>
<p>wget -qO - <a href="https://artifacts.elastic.co/GPG-KEY-elasticsearch">https://artifacts.elastic.co/GPG-KEY-elasticsearch</a> | sudo apt-key add -</p>
<p>安装apt和https协议转换工具</p>
<p>apt-get install apt-transport-https</p>
<p>添加安装源到本地</p>
<p>echo “deb <a href="https://artifacts.elastic.co/packages/7.x/apt">https://artifacts.elastic.co/packages/7.x/apt</a> stable main” | sudo tee -a /etc/apt/sources.list.d/elastic-7.x.list</p>
<p>更新软件列表并安装filebeat</p>
<p>sudo apt-get update &amp;&amp; sudo apt-get install filebeat</p>
<p>查看filebeat版本</p>
<p>filebeat version</p>
<p>Filebeat 配置：</p>
<p>type：指定数据的输入类型，这里是log，即日志，是默认值，还可以指定为stdin，即标准输入。</p>
<p>enabled: true：启用手工配置filebeat，而不是采用模块方式配置filebeat。启动后才能使用我们指定的模块。否则使用filebeat默认的模块;</p>
<p>encoding: gbk 中文编码；清单详见characters encoding</p>
<p>paths：用于指定要监控的日志文件，可以指定一个完整路径的文件，也可以是一个模糊匹配格式，例如：</p>
<p>，该配置表示将获取/data/nginx/logs目录下的所有以.log结尾的文件，注意这里有个破折号“-”，要在paths配置项基础上进行缩进，不然启动filebeat会报错，另外破折号前面不能有tab缩进，建议通过空格方式缩进。</p>
<p>，该配置表示将获取/var/log目录的所有子目录中以”.log”结尾的文件，而不会去查找/var/log目录下以”.log”结尾的文件。</p>
<p>name： 设置filebeat收集的日志中对应主机的名字，如果配置为空，则使用该服务器的主机名。这里设置为IP，便于区分多台主机的日志信息。</p>
<p>logging.level:debug;filebeat日志级别</p>
<p>include_lines: [‘request’,’response’] 匹配关键字所在行。</p>
<p>moitoring.enabled:false;filebeat监控开关，默认为启动；</p>
<p>multiline.type: pattern 多行模式类型：pattern:正则表达式</p>
<p>multiline.pattern: ‘^[[:space:]]+(at|.{3})[[:space:]]+\b|^Caused by:’</p>
<p>multiline.negate: false 根据您配置其他多行选项的方式，与指定正则表达式匹配的行将被视为上一行的延续或新多行事件的开始</p>
<p>multiline.match: after</p>
<p>千辛万苦终于建立索引有数据出来了，但是乱码…</p>
<p>[2023-10-08T16:30:50,921][WARN ][logstash.codecs.line     ][main][73bbfd3e8a1ad5e719cadc016524498db78b02b7eb1ac2e3ddc8ca7d9c5e649b] Received an event that has a different character encoding than you configured. {:text=&gt;”\"\x8CT\xAE\xD7c~s\xF5i\xFA\xD5\<br>u001D[3O\xDF\xF5\u001Ei\xD0\xC6\xE8Hv&lt;\x93\xEFϚcnA\x83\x94\xFA\xC6\xEFp\xF9۪4\xF6t:\x9D\xFE<br>\xBE\xE2+\a\x8A\xEF\xBBf]\xDF\xE3n\xF6\xFAA{jI}\xFC\xFDŹ\xDB\xF6\xE1e\xEB\xE2<br>\x95\xE2\xAD=\xC5}OY\x97\x82e]5\xCB\xCF\xE6\xAC\u000F\xED\xB9s\xE4\xA83\xB3\xDF:u\xCE\<br>xDA7\xE5_\xB3*\xAB=\x8B2\x88c\xA2*XsUZ)# \u0014\xD0\u0004\x8CI”, :expected_charset=&gt;”UTF-8”}</p>
<p>网络上好多事字符集问题，改过</p>
<p>Charset =&gt; “GBK”Charset =&gt; “UTF-8”Charset =&gt; “GB2312”</p>
<p>等等最终还是没能解决，乱码依旧…</p>
<p>后来来回折腾原来在这样的配置下面是需要配置ssl的，可以参考： <a href="https://boke.wsfnk.com/archives/330.html">https://boke.wsfnk.com/archives/330.html</a></p>
<p>环境：ELK：192.168.8.6 centos 7.8</p>
<p>Filebeat:192.168.8.105 192.168.8.106 debian10.</p>
<p>具体Centos：</p>
<p>Centos：</p>
<p>cp  /etc/pki/tls/openssl.cnf  /etc/pki/tls/openssl.cnf_bak</p>
<p>vi /etc/pki/tls/openssl.cnf</p>
<p>#在[ v3_ca ]下面填写subjectAltName = IP:192.168.8.6</p>
<p>[ v3_ca ]</p>
<p>subjectKeyIdentifier=hash</p>
<p>subjectAltName = IP:192.168.8.6 log端处于内网，需要外网抓取数据建议ip写成公网出口ip放行端口</p>
<p>添加以后执行：</p>
<p>openssl req -subj ‘/CN=192.168.8.6/‘ -x509 -days 3650 -batch -nodes -newkey rsa:2048 -keyout private/logstash.key -out certs/logstash.crt</p>
<p>会生成/etc/pki/tls/certs/logstash.crt和/etc/pki/tls/private/logstash.key</p>
<p>同样：filebeat：</p>
<p>Debian：</p>
<p>Cd  /etc/ssl&amp;&amp;cp openssl.conf openssl.conf_bak &amp;&amp; vim openssl.cnf</p>
<p>[ v3_ca ]</p>
<p>Extensions for a typical CA</p>
<p>PKIX recommendation.</p>
<p>subjectKeyIdentifier=hash</p>
<p>subjectAltName = IP:192.168.8.106</p>
<p>openssl req -subj ‘/CN=192.168.8.106/‘ -x509 -days 3650 -batch -nodes -newkey rsa:2048 -keyout private/filebeat.key -out certs/filebeat.crt</p>
<p>/etc/ssl/certs/filebeat.crt  和/etc/ssl/private/filebeat.key</p>
<p>接下来需要把logstash.crt 放到filebeat所在服务器的/etc/ssl/certs证书目录下面，</p>
<p>而每个filebeat的证书同样也放到logstash服务器的证书目录下面：</p>
<p>Cd /etc/pki/tls/certs&amp;&amp; ls</p>
<p>logstash.crt beat2.crt filebeat-gs1.crt</p>
<p>如果 filebeat-gs1.crt  filebeat-gs2.crt 会有个抓不到数据，命名不一致区分开就好。</p>
<p>然后修改/etc/logstash/conf.d/filebeat-logstash.conf</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">input {</span><br><span class="line">     beats {</span><br><span class="line">          port =&gt; 5045</span><br><span class="line">          type =&gt; "gs1"</span><br><span class="line">    ssl =&gt; true</span><br><span class="line">    ssl_certificate_authorities =&gt; ["/etc/pki/tls/certs/filebeat-gs1.crt"]</span><br><span class="line">    ssl_certificate =&gt; "/etc/pki/tls/certs/logstash.crt"</span><br><span class="line">    ssl_key =&gt; "/etc/pki/tls/private/logstash.key"</span><br><span class="line">    ssl_verify_mode =&gt; "force_peer"</span><br><span class="line">          codec =&gt; json {</span><br><span class="line">                  charset =&gt; "UTF-8"</span><br><span class="line">           }</span><br><span class="line">       }</span><br><span class="line">}</span><br><span class="line">input{</span><br><span class="line">     beats {</span><br><span class="line">          port =&gt; 5046</span><br><span class="line">          type =&gt; "gs2"</span><br><span class="line">    ssl =&gt; true</span><br><span class="line">    ssl_certificate_authorities =&gt; ["/etc/pki/tls/certs/beat2.crt"]</span><br><span class="line">    ssl_certificate =&gt; "/etc/pki/tls/certs/logstash.crt"</span><br><span class="line">    ssl_key =&gt; "/etc/pki/tls/private/logstash.key"</span><br><span class="line">    ssl_verify_mode =&gt; "force_peer"</span><br><span class="line">          codec =&gt; json {</span><br><span class="line">                  charset =&gt; "UTF-8"</span><br><span class="line">           }</span><br><span class="line"></span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">filter {</span><br><span class="line">        grok {</span><br><span class="line">    match =&gt; { "message" =&gt; "%{COMBINEDAPACHELOG}" }</span><br><span class="line">  }</span><br><span class="line">  date {</span><br><span class="line">    match =&gt; [ "timestamp" , "dd/MMM/yyyy:HH:mm:ss Z" ]</span><br><span class="line">  }</span><br><span class="line"> mutate{</span><br><span class="line">        remove_field  =&gt; "beat.hostname"</span><br><span class="line">        #remove_field =&gt; "beat.name"</span><br><span class="line">        remove_field =&gt; "version"</span><br><span class="line">        remove_field =&gt; "_type"</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">}</span><br><span class="line">output {</span><br><span class="line">         if [type] ==  "gs1"{</span><br><span class="line">            elasticsearch {</span><br><span class="line">                  index =&gt; "gs1_log_%{+yyyy.MM.dd}"</span><br><span class="line">                   hosts =&gt; "192.168.8.6:9200"</span><br><span class="line">                    codec =&gt; plain {</span><br><span class="line">                        charset =&gt; "UTF-8"</span><br><span class="line">                   }</span><br><span class="line">                   user =&gt; "elastic"</span><br><span class="line">                   password =&gt; "elastic"</span><br><span class="line">                 }</span><br><span class="line">              }</span><br><span class="line">         if  [type] == "gs2"{</span><br><span class="line">            elasticsearch {</span><br><span class="line">                  index =&gt; "gs2_log_%{+yyyy.MM.dd}"</span><br><span class="line">                   hosts =&gt; "192.168.8.6:9200"</span><br><span class="line">                   codec =&gt; plain {</span><br><span class="line">                        charset =&gt; "UTF-8"</span><br><span class="line">                     }</span><br><span class="line">                   user =&gt; "elastic"</span><br><span class="line">                   password =&gt; "elastic"</span><br><span class="line">                 }</span><br><span class="line">              }</span><br><span class="line">}</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>

<p>logstash配置大致如此，优化另说。</p>
<p>filebeat.yml配置如下：</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">filebeat.yml</span><br><span class="line">    #- c:\programdata\elasticsearch\logs\*</span><br><span class="line">  fields:</span><br><span class="line">          type: gs1</span><br><span class="line">          ip: 192.168.8.106</span><br><span class="line">          fields_under_root: true</span><br><span class="line"></span><br><span class="line">          #  multiline.pattern: '^instance_id'</span><br><span class="line">          #  multiline.negate: true</span><br><span class="line">          #  multiline.match: after</span><br><span class="line">          #  multiline.max_lines: 500 </span><br><span class="line"></span><br><span class="line">  #  multiline.pattern: '^[I,]|^[D,]|^[E,]|^[W,]|^[#]'</span><br><span class="line">  #  multiline.max_lines: 100</span><br><span class="line">  #  multiline.timeout: 20s</span><br><span class="line"></span><br><span class="line">    #monitoring.enabled: true</span><br><span class="line">inputs.container.enabled: true</span><br><span class="line">#xpack.monitoring.elasticsearch.username: elastic</span><br><span class="line">#xpack.monitoring.elasticsearch.password: elastic</span><br><span class="line"></span><br><span class="line">filebeat.config.modules:</span><br><span class="line">  # Glob pattern for configuration loading</span><br><span class="line">  path: ${path.config}/modules.d/*.yml</span><br><span class="line"></span><br><span class="line">  # Set to true to enable config reloading</span><br><span class="line">  reload.enabled: false</span><br><span class="line"></span><br><span class="line">  # The Logstash hosts</span><br><span class="line">output.logstash:</span><br><span class="line">    hosts: ["192.168.8.6:5045"]</span><br><span class="line">    ssl.certificate_authorities: ["/etc/ssl/certs/logstash.crt"]</span><br><span class="line">    ssl.certificate: "/etc/ssl/certs/filebeat.crt"</span><br><span class="line">ssl.key: "/etc/ssl/private/filebeat.key"</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>

<p>这样总算有正常数据了</p>
<p><img src="/../images/20231114_2.png"></p>
<p>Filebeat 重新抓取数据：</p>
<p>filebeat设置从头读取配置文件</p>
<p>流程：关闭filebeat –&gt; 删掉registry文件 –&gt; 启动filebeat</p>
<p>停止filebeat</p>
<p>删除filebeat日志记录日志位置文件</p>
<p>rm -rf /var/lib/filebeat/registry</p>
<p>find / -name registry</p>
<p>/var/lib/filebeat/registry</p>
<p>rm -rf /var/lib/filebeat/registry</p>
<p>重新启动filebeat</p>
<h1 id="3-遇到的问题："><a href="#3-遇到的问题：" class="headerlink" title="3.遇到的问题："></a>3.遇到的问题：</h1><h2 id="3-1-安装遇到证书报错"><a href="#3-1-安装遇到证书报错" class="headerlink" title="3.1.安装遇到证书报错:"></a>3.1.安装遇到证书报错:</h2><p>Err:20 <a href="https://packages.sury.org/php">https://packages.sury.org/php</a> buster Release                                  </p>
<p>  Certificate verification failed: The certificate is NOT trusted. The certificate chain uses expired certificate.  Could not handshake: Error in the certificate verification. [IP: 143.244.50.90 443]</p>
<p>Get:21 <a href="https://artifacts.elastic.co/packages/7.x/apt">https://artifacts.elastic.co/packages/7.x/apt</a> stable/main amd64 Packages [118 kB]</p>
<p>Reading package lists… Done    </p>
<p>E: The repository ‘<a href="https://packages.sury.org/php">https://packages.sury.org/php</a> buster Release’ does not have a Release file.</p>
<p>N: Updating from such a repository can’t be done securely, and is therefore disabled by default.</p>
<p>N: See apt-secure(8) manpage for repository creation and user configuration details.</p>
<p>root@test:/home/tools# apt-get install ca-certificates</p>
<p>sudo apt-get install –reinstall ca-certificates</p>
<p>sudo apt-get update</p>
<h2 id="3-2-Logstash-报错："><a href="#3-2-Logstash-报错：" class="headerlink" title="3.2.Logstash 报错："></a>3.2.Logstash 报错：</h2><p> Your settings are invalid. Reason: Path “/data/elk/logstash/dead_letter_queue” must be a writable directory. It is not writable.</p>
<p>Your settings are invalid. Reason: Path “/data/elk/logstash/dead_letter_queue” must be a writable directory. It is not writable.</p>
<p>An unexpected error occurred! {:error=&gt;java.nio.file.AccessDeniedException: /data/elk/logstash/.lock, :</p>
<p>权限问题给权限；</p>
<h2 id="3-3-Logstash-报错："><a href="#3-3-Logstash-报错：" class="headerlink" title="3.3.Logstash 报错："></a>3.3.Logstash 报错：</h2><p>syslog listener died {:protocol=&gt;:tcp, :address=&gt;”0.0.0.0:5044”, :exceptinotallow=&gt;#&lt;Errno::EADDRINUSE: Address already in use - bind(2) for “0.0.0.0” port 5044&gt;, :backtrace=&gt;[“org/jruby/ext/socket/RubyTCPServer.java:123:in <code>initialize'", "org/jruby/RubyIO.java:876:in </code>new’”, “/usr/share/logstash/vendor/bundle/jruby/2.5.0/gems/logstash-input-syslog-3.6.0/lib/logstash/inputs/syslog.rb:208:in <code>tcp_listener'", "/usr/share/logstash/vendor/bundle/jruby/2.5.0/gems/logstash-input-syslog-3.6.0/lib/logstash/inputs/syslog.rb:172:in </code>server’”, “/usr/share/logstash/vendor/bundle/jruby/2.5.0/gems/logstash-input-syslog-3.6.0/lib/logstash/inputs/syslog.rb:156:in `block in run’”]}</p>
<p>是因为非ROOT用户启动的程序禁止监听1-1024的端口，要到修改服务启动的用户为ROOT，要到把监听端口修改为1024以上的端口即可。</p>
<p>vim /etc/systemd/system/logstash.service</p>
<p>[Service]</p>
<p>Type=simple</p>
<p>User=root</p>
<p>Group=root</p>
<p>….</p>
<p>curl –user elastic:changeme ‘<a href="http://127.0.0.1:9200/_xpack/license">http://127.0.0.1:9200/_xpack/license</a>‘</p>
<p>{</p>
<p>  “license” : {</p>
<p>“status” : “active”,</p>
<p>“uid” : “ad2ea283-fbdf-483a-9c53-e09f43c14a97”,</p>
<p>“type” : “basic”,</p>
<p>“issue_date” : “2023-09-19T07:37:00.727Z”,</p>
<p>“issue_date_in_millis” : 1695109020727,</p>
<p>“max_nodes” : 1000,</p>
<p>“issued_to” : “elasticsearch”,</p>
<p>“issuer” : “elasticsearch”,</p>
<p>“start_date_in_millis” : -1</p>
<p>  }</p>
<p>}</p>
<h2 id="3-4-配置缺失"><a href="#3-4-配置缺失" class="headerlink" title="3.4.配置缺失"></a>3.4.配置缺失</h2><p>有时候直接复制的比如input 只复制到nput少了i，或者格式错了等等；</p>
<p>[ERROR][logstash.agent ] Failed to execute action {:actinotallow=&gt;LogStash::PipelineAction::Create/pipeline_id:main, :exceptinotallow=&gt;”LogStash::ConfigurationError”, :message=&gt;”Expected one of [ \t\r\n], "#", "input", "filter", "output" at line 1, column 1 (byte 1)”, :backtrace=&gt;[“/usr/share/logstash/logstash-core/lib/logstash/compiler.rb:32:in <code>compile_imperative'", "org/logstash/execution/AbstractPipelineExt.java:189:in </code>initialize’”, “org/logstash/execution/JavaBasePipelineExt.java:72:in <code>initialize'", "/usr/share/logstash/logstash-core/lib/logstash/java_pipeline.rb:48:in </code>initialize’”, “/usr/share/logstash/logstash-core/lib/logstash/pipeline_action/create.rb:52:in <code>execute'", "/usr/share/logstash/logstash-core/lib/logstash/agent.rb:392:in </code>block in converge_state’”]}</p>
<p>测试：</p>
<p>/usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/log.conf  -t</p>
<p>Using bundled JDK: /usr/share/logstash/jdk</p>
<p>OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.</p>
<p>WARNING: Could not find logstash.yml which is typically located in $LS_HOME/config or /etc/logstash. You can specify the path using –path.settings. Continuing using the defaults</p>
<p>Could not find log4j2 configuration at path /usr/share/logstash/config/log4j2.properties. Using default config which logs errors to the console</p>
<p>等等可以看日志找出这些问题；本次安装遇到最大问题是乱码，做一次点滴笔记。</p>
<hr>
]]></content>
      <categories>
        <category>系统</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title>apache多网站对应80端口</title>
    <url>/2023/062862696.html</url>
    <content><![CDATA[<p>一台服务器绑定多个域名，已经装了apache，nginx就不使用了，利用apache主机头名虚拟主机用80端口对应多个网站，万能的网络上面有文档如下：</p>
<p>Aapche 如果需要绑定多个域名到一个IP上,是支持的。需要注意以下2点:</p>
<p>1 必须要开启 NameVirtualHost开关选项，</p>
<p>如：NameVirtualHost 220.231.220.231:80</p>
<p>2 NameVirtualHost 需要指定具体的端口</p>
<p>例如”:80″,跟&lt;VirtualHost 220.231.32.*:80&gt;对应，否则会报错:</p>
<p>mixing * ports and non-* ports with a NameVirtualHost address is not supported, proceeding with undefined results。</p>
<p>翻译过来就是: NameVirtualHost 地址，指定端口和不指定端口混合使用是不支持的，将会产生未逾期的后果。</p>
<p>未逾期的后果就是: 第2个不起作用，仅当一个站点设置起作用。</p>
<p>按着做下来：</p>
<p>IncludeOptional conf.d/*.conf</p>
<p>ServerSignature Off</p>
<p>NameVirtualHost 220.231.220.231:80</p>
<p>&lt;VirtualHost 220.231.220.231:80&gt;&nbsp;&nbsp;</p>
<p>ServerAdmin&nbsp; &nbsp;<a href="mailto:postmaster@aaa.net">postmaster@aaa.net</a>&nbsp;</p>
<p>directoryIndex&nbsp; index.html index.php index.htm&nbsp;&nbsp;</p>
<p>ServerName <a href="http://www.aaa.net/">www.aaa.net</a></p>
<p>DocumentRoot&nbsp; /data/www/wress/</p>
<p>&lt;Directory “/data/www/wress/“&gt;&nbsp;&nbsp;</p>
<p>&nbsp; &nbsp;Options -Indexes&nbsp;&nbsp;</p>
<p>&nbsp; &nbsp;Options FollowSymLinks Indexes</p>
<p>&nbsp; &nbsp; AllowOverride All&nbsp;&nbsp;</p>
<p>&nbsp;&nbsp;</p>
<p>&nbsp; &nbsp; Require all granted&nbsp;&nbsp;</p>
<p>&nbsp;&nbsp;</p>
<p>ErrorLog logs/<a href="http://www.aaa.net-error_log/">www.aaa.net-error_log</a></p>
<p>&nbsp;CustomLog logs/<a href="http://www.aaa.net-access_log/">www.aaa.net-access_log</a> common</p>
<p>&nbsp;</p>
<p>&lt;VirtualHost 220.231.220.231:80&gt;</p>
<p>ServerAdmin&nbsp; <a href="mailto:postmaster@aaa.net">postmaster@aaa.net</a></p>
<p>directoryIndex&nbsp; index.html index.php index.htm&nbsp;&nbsp;</p>
<p>ServerName img.aaa.net</p>
<p>#ServerName 220.231.220.231</p>
<p>DocumentRoot&nbsp; /data/www/html/</p>
<p>&lt;Directory “/data/www/html/“&gt;</p>
<p>&nbsp; &nbsp; Options -Indexes&nbsp;&nbsp;</p>
<p>&nbsp; &nbsp; Options FollowSymLinks Indexes</p>
<p>&nbsp; &nbsp; AllowOverride All</p>
<p>&nbsp; &nbsp;Require all granted</p>


<p>ErrorLog logs/img.aaa.net-error_log</p>
<p>CustomLog logs/img.aaa.net-access_log common</p>


<h2 id="这样都可以访问，apache也可以实现，做个小笔记。"><a href="#这样都可以访问，apache也可以实现，做个小笔记。" class="headerlink" title="这样都可以访问，apache也可以实现，做个小笔记。"></a>这样都可以访问，apache也可以实现，做个小笔记。</h2>]]></content>
  </entry>
  <entry>
    <title>centos U盘安装查找U盘设备名</title>
    <url>/2023/111459478.html</url>
    <content><![CDATA[<p>制作启动盘：UltraISO.exe 打开镜像文件，–启动—写入硬盘镜像—默认—开始大概7分钟后就制作完成。 这样制作以后U盘原数据就没了当心。</p>
<p>主板del进cmos选择Usb首启动，看到3个选项：安装，测试&amp;安装,trouble修复，移动到第一项Install&nbsp;centos7</p>
<p>很多时候卡到这边过不去，<br>按tab键编辑路径，将&nbsp;<br>vmlinuz initrd=initrd.img inst.stage2=hd:LABEL=CentOS\x207\x20x86_64 quiet&nbsp;<br>改成&nbsp;<br>vmlinuz initrd=initrd.img&nbsp;linux dd&nbsp;quiet&nbsp;<br>回车&nbsp;<br>然后就能在显示出的列表中 查看你的硬盘信息，很清晰就能知道哪一个是你的U盘（一般显示的几个 格式为NTFS的都是你电脑自身的盘符，另外的一个就是你的U盘，记下你的U盘的盘符名字 我的就是sdb4）&nbsp;</p>
<p>系统会显示当前块设备：</p>
<p>Sda1&nbsp; nfs&nbsp;</p>
<p>Sda2&nbsp; nfs</p>
<p>Sdb4&nbsp;&nbsp; vfat</p>
<p>类似这些提示ccontinue 或者r reflush刷下块设备</p>
<p>起初u盘没刷出来，刷新出来的sdb4<br>重新启动电脑，重复上面的步骤 这一次 将&nbsp;<br>vmlinuz initrd=initrd.img inst.stage2=hd:LABEL=CentOS\x207\x20x86_64 quiet&nbsp;<br>改成&nbsp;<br>vmlinuz initrd=initrd.img&nbsp;inst.stage2=hd:/dev/sdb4（你自己的U盘盘符）&nbsp;quiet&nbsp;<br>回车 等待安装程序启动，进行CentOS的安装</p>
<hr>
]]></content>
  </entry>
  <entry>
    <title>centos7 改网卡名eth0</title>
    <url>/2023/111420634.html</url>
    <content><![CDATA[<p>安装完Centos7系统，网卡命名跟之前发生了变化,不是eth0，虽然唯一好确定但是作为centos6.X过来的还是不好记，那就把网卡名字重新命名为eth0吧。</p>
<p>1.先编辑网卡的配置文件将里面的NAME DEVICE项修改为eth0，vim /etc/sysconfig/network-scripts/ifcfg-enp2s0</p>
<p>NAME=enp2s0 改为eth0</p>
<p>DEVICE=enp2s0 改为 eth0</p>
<p>2.cd /etc/sysconfig/network-scripts/ mv&nbsp;ifcfg-enp2s0 ifcfg-eth0</p>
<p>3.禁用该可预测命名规则。对于这一点，你可以在启动时传递“net.ifnames=0 biosdevname=0 ”的内核参数。这是通过编辑/etc/default/grub并加入“net.ifnames=0 biosdevname=0 ”到GRUBCMDLINELINUX变量来实现的。</p>
<p>&nbsp;vim /etc/default/grub&nbsp;添加红色部分；</p>
<p>GRUB_CMDLINE_LINUX=”crashkernel=auto rd.lvm.lv=cl/root&nbsp;net.ifnames=0 biosdevname=0&nbsp;&nbsp;rd.lvm.lv=cl/swap rhgb quiet” &nbsp;</p>
<p>4.运行命令grub2-mkconfig -o /boot/grub2/grub.cfg&nbsp;来重新生成GRUB配置并更新内核参数。</p>
<p>&nbsp;grub2-mkconfig -o /boot/grub2/grub.cfg</p>
<p>Generating grub configuration file …</p>
<p>Found linux image: /boot/vmlinuz-3.10.0-514.el7.x86_64</p>
<p>Found initrd image: /boot/initramfs-3.10.0-514.el7.x86_64.img</p>
<p>Found linux image: /boot/vmlinuz-0-rescue-50b1d05808e44d898bef511aa2945d76</p>
<p>Found initrd image: /boot/initramfs-0-rescue-50b1d05808e44d898bef511aa2945d76.img</p>
<p>done</p>
<p>5.重启机器改名eth0生效；</p>
<p>PS:有时候重启以后会自动生成一个不是我们指定的ip，这个时候需要把网卡mac地址加进去 ifcfg-eth0中：HWADDR=30:5a:3a:e0:90:3c</p>
<p>也可以修改</p>
<p>cd /etc/udev/rules.d/</p>
<p>vim&nbsp;70-persistent-net.rules</p>
<p>注释掉原来的，添加新或者修改：</p>
<p>SUBSYSTEM==”net”, ACTION==”add”, DRIVERS==”?<em>“, ATTR{address}==”00:0c:29:1f:1a:f5”, KERNEL==”eth</em>“, NAME=”eth0”</p>
<p>修改为：</p>
<p>SUBSYSTEM==”net”, ACTION==”add”, DRIVERS==”?<em>“, ATTR{address}==”30:5a:3a:e0:90:3c”, KERNEL==”eth</em>“, NAME=”eth0”</p>
<h2 id="重启机器试试"><a href="#重启机器试试" class="headerlink" title="重启机器试试~"></a>重启机器试试~</h2>]]></content>
      <tags>
        <tag>点滴</tag>
      </tags>
  </entry>
  <entry>
    <title>coredump 路径格式</title>
    <url>/2023/062743960.html</url>
    <content><![CDATA[<p>Coredump</p>
<p>业务进程宕机以后开发需要查看dump查找定位问题，所有服务器初始化环境时候统一定制coredump路径；</p>
<p>1.Core文件简介</p>
<p>Core文件其实就是内存的映像，当程序崩溃时，存储内存的相应信息，主用用于对程序进行调试。当程序崩溃时便会产生core文件，其实准确的应该说是core dump 文件,默认生成位置与可执行程序位于同一目录下，文件名为core,其中是某一数字。</p>
<p>2.开启或关闭Core文件的生成</p>
<p>关闭或阻止core文件生成：</p>
<p>$ulimit -c 0</p>
<p>打开core文件生成：</p>
<p>$ulimit -c unlimited</p>
<p>检查core文件的选项是否打开：</p>
<p>$ulimit -a</p>
<p>ulimit参数含义如下：&nbsp;</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -a&nbsp;&nbsp;&nbsp;&nbsp; All current limits are reported<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -c&nbsp;&nbsp;&nbsp;&nbsp; The maximum size of core files created<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -d&nbsp;&nbsp;&nbsp;&nbsp; The maximum size of a process data segment<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -e&nbsp;&nbsp;&nbsp;&nbsp; The maximum scheduling priority (“nice”)<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -f&nbsp;&nbsp;&nbsp;&nbsp; The maximum size of files written by the shell and its children<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -i&nbsp;&nbsp;&nbsp;&nbsp; The maximum number of pending signals<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -l&nbsp;&nbsp;&nbsp;&nbsp; The maximum size that may be locked into memory<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -m&nbsp;&nbsp;&nbsp;&nbsp; The maximum resident set size (has no effect on Linux)<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -n&nbsp;&nbsp;&nbsp;&nbsp; The maximum number of open file descriptors (most systems do not allow this value to be set)<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -p&nbsp;&nbsp;&nbsp;&nbsp; The pipe size in 512-byte blocks (this may not be set)<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -q&nbsp;&nbsp;&nbsp;&nbsp; The maximum number of bytes in POSIX message queues<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -r&nbsp;&nbsp;&nbsp;&nbsp; The maximum real-time scheduling priority<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -s&nbsp;&nbsp;&nbsp;&nbsp; The maximum stack size<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -t&nbsp;&nbsp;&nbsp;&nbsp; The maximum amount of cpu time in seconds<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -u&nbsp;&nbsp;&nbsp;&nbsp; The maximum number of processes available to a single user<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -v&nbsp;&nbsp;&nbsp;&nbsp; The maximum amount of virtual memory available to the shell<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -x&nbsp;&nbsp;&nbsp;&nbsp; The maximum number of file locks</p>
<p>&nbsp;</p>
<p>#ulimit -a</p>
<p>core file size&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (blocks, -c) unlimited</p>
<p>data seg size&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (kbytes, -d) unlimited</p>
<p>scheduling priority&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (-e) 0</p>
<p>file size&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (blocks, -f) unlimited</p>
<p>pending signals&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (-i) 127974</p>
<p>max locked memory&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (kbytes, -l) 64</p>
<p>max memory size&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (kbytes, -m) unlimited</p>
<p>open files&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (-n) 100000</p>
<p>pipe size&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (512 bytes, -p) 8</p>
<p>POSIX message queues&nbsp;&nbsp;&nbsp;&nbsp; (bytes, -q) 819200</p>
<p>real-time priority&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (-r) 0</p>
<p>stack size&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (kbytes, -s) 8192</p>
<p>cpu time&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (seconds, -t) unlimited</p>
<p>max user processes&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (-u) 655360</p>
<p>virtual memory&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (kbytes, -v) unlimited</p>
<p>file locks&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (-x) unlimited而我们需要修改的是open files (-n) 1024的值</p>
<p>于是命令就是limit -n 2048(随各自需要设置)</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>以上配置只对当前会话起作用，下次重新登陆后，还是得重新配置。要想配置永久生效，得在/etc/profile或者/etc/security/limits.conf文件中进行配置。</p>
<p>首先以root权限登陆，然后打开/etc/security/limits.conf文件，进行配置：</p>
<p>#vim /etc/security/limits.conf</p>
<p><domain> &nbsp; &nbsp;<type> &nbsp; &nbsp;<item> &nbsp; &nbsp; &nbsp; &nbsp;<value></value></item></type></domain></p>
<p>&nbsp; &nbsp; &nbsp; &nbsp;* &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;soft &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;core &nbsp; &nbsp; &nbsp; &nbsp; unlimited</p>
<p>或者在/etc/profile中作如下配置：</p>
<p>#vim /etc/profile</p>
<p>ulimit -S -c unlimited &gt;/dev/null 2&gt;&amp;1</p>
<p>或者想配置只针对某一用户有效，则修改此用户的<del>/.bashrc或者</del>/.bash_profile文件：</p>
<p>limit -c unlimited</p>
<p>ulimit -c 0 是禁止产生core文件，而ulimit -c 1024则限制产生的core文件的大小不能超过1024kb</p>
<p>3.设置Core Dump的核心转储文件目录和命名规则</p>
<p>/proc/sys/kernel/core_uses_pid可以控制产生的core文件的文件名中是否添加pid作为扩展，如果添加则文件内容为1，否则为0<br>/proc/sys/kernel/core_pattern可以设置格式化的core文件保存位置或文件名，比如原来文件内容是core-%e<br>可以这样修改:<br>echo “/data/common/coredump/core-%e-%p-%t” &gt;/proc/sys/kernel/core_pattern<br>将会控制所产生的core文件会存放到/data/common/coredump目录下，产生的文件名为core-进程名-pid-时间戳<br>以下是参数列表:<br>&nbsp;&nbsp;&nbsp; %p - insert pid into filename 添加pid<br>&nbsp;&nbsp;&nbsp; %u - insert current uid into filename 添加当前uid<br>&nbsp;&nbsp;&nbsp; %g - insert current gid into filename 添加当前gid<br>&nbsp;&nbsp;&nbsp; %s - insert signal that caused the coredump into the filename 添加导致产生core的信号<br>&nbsp;&nbsp;&nbsp; %t - insert UNIX time that the coredump occurred into filename 添加core文件生成时的unix时间<br>&nbsp;&nbsp;&nbsp; %h - insert hostname where the coredump happened into filename 添加主机名<br>&nbsp;&nbsp;&nbsp; %e - insert coredumping executable name into filename 添加命令名</p>
<p>4.core文件的使用</p>
<p>在core文件所在目录下键入:<br>gdb -c core &nbsp; （-c指定core文件）<br>它会启动GNU的调试器，来调试core文件，并且会显示生成此core文件的程序名，中止此程序的信号等等<br>如果你已经知道是由什么程序生成此core文件的，比如MyServer崩溃了生成core.12345，那么用此指令调试:<br>gdb -c core MyServer</p>
<p>&nbsp;源：<a href="https://www.cnblogs.com/xiaodoujiaohome/p/6222895.html">https://www.cnblogs.com/xiaodoujiaohome/p/6222895.html</a>&nbsp;</p>
<p>5.永久生效：<br>当前不重启生效：<br>你可以用下列方式来完成<br>sysctl -w kernel.core_pattern=/data/common/coredump/core-%e-%p-%t&nbsp;</p>
<p>或</p>
<p>echo “/data/common/coredump/core-%e-%p-%t” &gt;/proc/sys/kernel/core_pattern</p>
<p>这些操作一旦计算机重启，则会丢失，如果你想持久化这些操作，可以在 /etc/sysctl.conf文件中增加：<br>kernel.core_pattern=/data/common/coredump/core-%e-%p-%t&nbsp;</p>
<p>加好后，如果你想不重启看看效果的话，则用下面的命令：<br>sysctl -p<br>vim /etc/sysctl.conf</p>
<p>net.ipv4.ip_forward = 0</p>
<p>net.ipv4.conf.default.rp_filter = 1</p>
<p>net.ipv4.conf.default.accept_source_route = 0</p>
<p>kernel.core_uses_pid = 1</p>
<p>net.ipv4.tcp_syncookies = 1</p>
<p>kernel.msgmnb = 65536</p>
<p>kernel.msgmax = 65536</p>
<p>net.ipv6.conf.lo.disable_ipv6 = 1</p>
<p>net.ipv4.conf.all.promote_secondaries = 1</p>
<p>net.ipv4.conf.default.promote_secondaries = 1</p>
<p>net.ipv6.neigh.default.gc_thresh3 = 4096</p>
<p>net.ipv4.neigh.default.gc_thresh3 = 4096</p>
<p>kernel.softlockup_panic = 1</p>
<p>kernel.sysrq = 1</p>
<p>net.ipv6.conf.all.disable_ipv6 = 1</p>
<p>net.ipv6.conf.default.disable_ipv6 = 1</p>
<p>vm.overcommit_memory = 1</p>
<p>kernel.numa_balancing = 0</p>
<p>kernel.shmmax = 68719476736</p>
<p>kernel.printk = 5</p>
<p>kernel.core_pattern = /data/common/coredump/core-%e-%p-%t</p>
<hr>
]]></content>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title>debian安装gitea</title>
    <url>/2023/120864459.html</url>
    <content><![CDATA[<p>   项目需要自己的git仓库，github，gitee，阿里云效都可以，gitea没用过，尝试装一下。</p>
<h2 id="1-mariadb安装"><a href="#1-mariadb安装" class="headerlink" title="1.mariadb安装"></a>1.mariadb安装</h2><p> lsb_release  -a</p>
<p>root@github:/home/tools# lsb_release  -a</p>
<p>No LSB modules are available.</p>
<p>Distributor ID:	Debian</p>
<p>Description:	Debian GNU/Linux 10 (buster)</p>
<p>Release:	10</p>
<p>Codename:	buster</p>
<p>apt install mariadb-server mariadb-client</p>
<p> sudo mysql_secure_installation</p>
<p>- Set root password? [Y/n] y</p>
<p>-Remove anonymous users? [Y/n] y</p>
<p>- Disallow root login remotely? [Y/n] y</p>
<p>- Remove test database and access to it? [Y/n] y</p>
<p>- Reload privilege tables now? [Y/n] y</p>
<p>一路回车，Set root password? [Y/n] y</p>
<p>Enter current password for root (enter for none): </p>
<p>OK, successfully used password, moving on…</p>
<p>Setting the root password ensures that nobody can log into the MariaDB</p>
<p>root user without the proper authorisation.</p>
<p>Set root password? [Y/n] y</p>
<p>New password: </p>
<p>Re-enter new password: </p>
<p>Password updated successfully!</p>
<p>Reloading privilege tables..</p>
<p>接下来设置数据库</p>
<p> MariaDB [(none)]&gt; CREATE DATABASE gitea;</p>
<p>MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON gitea.* TO ‘giteadb‘@’localhost’ IDENTIFIED BY ‘gitea#ba1’;</p>
<p>MariaDB [(none)]&gt; FLUSH PRIVILEGES;</p>
<p>MariaDB [(none)]&gt; QUIT;</p>
<h2 id="2-gitea-安装"><a href="#2-gitea-安装" class="headerlink" title="2.gitea 安装"></a>2.gitea 安装</h2><p>sudo apt install git</p>
<p>adduser –system –shell /bin/bash –gecos ‘Git Version Control’ –group –disabled-password –home /data/gitrepo git</p>
<p>下载gitea最新版本：120M左右<br>curl -s <a href="https://api.github.com/repos/go-gitea/gitea/releases/latest">https://api.github.com/repos/go-gitea/gitea/releases/latest</a> |grep browser_download_url | cut -d ‘“‘ -f 4 | grep ‘\linux-amd64$’ | wget -i -</p>
<p>mv gitea-*-linux-amd64 /usr/local/bin/gitea</p>
<p>chmod +x /usr/local/bin/gitea</p>
<p>root@git:/home/tools/gitea# gitea –version</p>
<p>Gitea version 1.20.0 built with GNU Make 4.1, go1.20.6 : bindata, sqlite, sqlite_unlock_notify</p>
<p>接下来，您需要为 Gitea 创建一个目录结构。</p>
<p>mkdir -p /etc/gitea /var/lib/gitea/{custom,data,indexers,public,log}</p>
<p>然后，使用以下命令设置适当的权限和所有权：</p>
<p>chown git:git /var/lib/gitea/{data,indexers,log}</p>
<p>chmod 750 /var/lib/gitea/{data,indexers,log}</p>
<p>chown root:git /etc/gitea</p>
<p>chmod 770 /etc/gitea</p>
<p>创建 Gitea Systemd 文件。 Gitea创建服务/etc/systemd/system/gitea.service:</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">[Unit]</span><br><span class="line">Description=Gitea (Git with a cup of tea)</span><br><span class="line">After=syslog.target</span><br><span class="line">After=network.target</span><br><span class="line">After=mysql.service</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">LimitMEMLOCK=infinity</span><br><span class="line">LimitNOFILE=65535</span><br><span class="line">RestartSec=2s</span><br><span class="line">Type=simple</span><br><span class="line">User=git</span><br><span class="line">Group=git</span><br><span class="line">WorkingDirectory=/var/lib/gitea/</span><br><span class="line">ExecStart=/usr/local/bin/gitea web -c /etc/gitea/app.ini</span><br><span class="line">Restart=always</span><br><span class="line">Environment=USER=git </span><br><span class="line">HOME=/data/gitrepo</span><br><span class="line">GITEA_WORK_DIR=/var/lib/gitea</span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></tbody></table></figure>

<p>systemctl daemon-reload</p>
<p>systemctl enable  gitea.service</p>
<p>systemctl start gitea.service</p>
<p>初始化：</p>
<p><img src="/../images/20231208_1.png"><br><img src="/../images/20231208_2.png"></p>
<p>最终会生成一个/etc/gitea/app.ini文件：可以做域名，端口根据自己需求调整：</p>
<p>cat /etc/gitea/app.ini</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">APP_NAME = Gitea: Git with a cup of tea</span><br><span class="line">RUN_USER = git</span><br><span class="line">WORK_PATH = /usr/local/bin</span><br><span class="line">RUN_MODE = prod</span><br><span class="line"> </span><br><span class="line">[server]</span><br><span class="line">SSH_DOMAIN = repo.yjzs.orlesh.com</span><br><span class="line">DOMAIN = 域名</span><br><span class="line">HTTP_PORT = gitea端口自定义10048</span><br><span class="line">ROOT_URL = https://域名</span><br><span class="line"></span><br><span class="line">APP_DATA_PATH = /usr/local/bin/data</span><br><span class="line">START_SSH_SERVER = true</span><br><span class="line">DISABLE_SSH = false</span><br><span class="line"></span><br><span class="line">\#SSH_PORT = 22</span><br><span class="line">SSH_PORT = 可以自定义</span><br><span class="line">LFS_START_SERVER = true</span><br><span class="line">LFS_JWT_SECRET = ……</span><br><span class="line">OFFLINE_MODE = false </span><br><span class="line"></span><br><span class="line">[database]</span><br><span class="line">DB_TYPE = mysql</span><br><span class="line">HOST = 127.0.0.1:3306</span><br><span class="line">NAME = gitea</span><br><span class="line">USER = gitea</span><br><span class="line">PASSWD = `passwd`</span><br><span class="line">SCHEMA = </span><br><span class="line">SSL_MODE = disable</span><br><span class="line">PATH = /usr/local/bin/data/gitea.db</span><br><span class="line">LOG_SQL = false</span><br><span class="line"></span><br><span class="line">[repository]</span><br><span class="line">ROOT = /data/gitrepo/</span><br><span class="line"></span><br><span class="line">[lfs]</span><br><span class="line">PATH = /usr/local/bin/data/lfs</span><br><span class="line">[mailer]</span><br><span class="line">ENABLED = false</span><br><span class="line">[service]</span><br><span class="line">REGISTER_EMAIL_CONFIRM = false</span><br><span class="line">ENABLE_NOTIFY_MAIL = false</span><br><span class="line">DISABLE_REGISTRATION = false</span><br><span class="line">ALLOW_ONLY_EXTERNAL_REGISTRATION = false</span><br><span class="line">ENABLE_CAPTCHA = false</span><br><span class="line">REQUIRE_SIGNIN_VIEW = false</span><br><span class="line">DEFAULT_KEEP_EMAIL_PRIVATE = false</span><br><span class="line">DEFAULT_ALLOW_CREATE_ORGANIZATION = true</span><br><span class="line">DEFAULT_ENABLE_TIMETRACKING = true</span><br><span class="line">NO_REPLY_ADDRESS = noreply.域名</span><br><span class="line"></span><br><span class="line">[openid]</span><br><span class="line">ENABLE_OPENID_SIGNIN = true</span><br><span class="line">ENABLE_OPENID_SIGNUP = true</span><br><span class="line">[cron.update_checker]</span><br><span class="line">ENABLED = false</span><br><span class="line"> </span><br><span class="line">[session]</span><br><span class="line">PROVIDER = file</span><br><span class="line"></span><br><span class="line">[log]</span><br><span class="line">MODE = console</span><br><span class="line">LEVEL = info</span><br><span class="line">ROOT_PATH = /usr/local/bin/data/log</span><br><span class="line"></span><br><span class="line">[repository.pull-request]</span><br><span class="line">DEFAULT_MERGE_STYLE = merge</span><br><span class="line"></span><br><span class="line">[repository.signing]</span><br><span class="line">DEFAULT_TRUST_MODEL = committer</span><br><span class="line">[security]</span><br><span class="line">……</span><br><span class="line"></span><br><span class="line"> </span><br></pre></td></tr></tbody></table></figure>

<p>Nginx 配置转发：</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line"></span><br><span class="line">server { </span><br><span class="line">   listen    80; </span><br><span class="line">   server_name  域名; </span><br><span class="line">   \# http默认重定向到https </span><br><span class="line">   return   301 https://$server_name$request_uri; </span><br><span class="line"></span><br><span class="line">} </span><br><span class="line"></span><br><span class="line">server {</span><br><span class="line"></span><br><span class="line">  listen 443 ssl;</span><br><span class="line"> server_name 域名;</span><br><span class="line">  access_log /var/log/nginx/gitea_access.log;</span><br><span class="line">  error_log /var/log/nginx/gitea_error.log;</span><br><span class="line"></span><br><span class="line">  ssl_certificate  /etc/nginx/cert/域名.pem; </span><br><span class="line">  ssl_certificate_key /etc/nginx/cert/域名.key;  </span><br><span class="line">   ssl_session_timeout 5m; </span><br><span class="line">   ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; </span><br><span class="line">  ssl_protocols TLSv1 TLSv1.1 TLSv1.2; </span><br><span class="line">  ssl_prefer_server_ciphers on; </span><br><span class="line">   client_max_body_size 1024m; </span><br><span class="line"> </span><br><span class="line"> allow 192.168.8.10;  </span><br><span class="line">  deny all;</span><br><span class="line">  location / {</span><br><span class="line">   proxy_pass http://localhost:10048;</span><br><span class="line">  }</span><br><span class="line">}</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>

<h2 id="3-gitea-操作"><a href="#3-gitea-操作" class="headerlink" title="3.gitea 操作"></a>3.gitea 操作</h2><p>调试完成就可以访问配置的域名，进入gitea后台：右上角设置，设置SSH/GPGg密钥和管理后台添加账户；</p>
<p>创建仓库：</p>
<p><img src="/../images/20231208_3.png"></p>
<p>本地设置：</p>
<p>在安装完git和TortoiseGit后，使用ssh的配置如下：<br>生成ssh key<br> 运行Git Bash<br> 进到ssh目录： cd ~/.ssh/<br> 如果提示不存在，创建.ssh：mkdir ~/.ssh/<br> 配置用户名和邮箱：</p>
<p>Git config –global user.name “your name”</p>
<p>Git config –global user.email “<a href="mailto:your_email@example.com">your_email@example.com</a>”</p>
<p> 生成key：ssh-keygen -t rsa -C “<a href="mailto:your_email@example.com">your_email@example.com</a>“<br> 连续按三次回车即可<br> 最后得到了两个文件：id_rsa和id_rsa.pub<br> 复制ssh内容：cat is_rsa.pub 添加到gitea 的SSH/GPGg密钥那边</p>
<p>需要创建一个远程空仓库，可以使用GitHub、GitLab等平台创建。获取仓库的URL，以便后续推送代码时使用。</p>
<p>克隆远程仓库</p>
<p>在推送代码之前，首先需要将远程仓库克隆到本地。可以使用以下命令进行克隆：</p>
<p>git remote add  origin ssh:/git url </p>
<p>建议用ssh:/git 远程库url，https url会报一些错误：比如，</p>
<p>error: RPC failed; curl 56 HTTP/2 stream 5 was reset</p>
<p>send-pack: unexpected disconnect while reading sideband packet</p>
<p>fatal: the remote end hung up unexpectedly</p>
<p>Everything up-to-date</p>
<p> 设置了git config –global http.postBuffer 524288000似乎效果不大</p>
<p> Git基本操作：</p>
<p>新建代码库：</p>
<p># 在当前目录新建一个Git代码库</p>
<p>$ git init</p>
<p># 新建一个目录，将其初始化为Git代码库</p>
<p>$ git clone [url]</p>
<p># 列出当前所有配置， 包含本地、全局、系统配置</p>
<p>$ git config –list</p>
<p># 列出本地配置</p>
<p>git config –local –list</p>
<p># 列出全局配置</p>
<p>git config –global –list</p>
<p># 列出系统配置</p>
<p>git config –system –list</p>
<p># 添加指定文件到暂存区</p>
<p>$ git add [file1] [file2] …</p>
<p># 添加指定目录到暂存区，包括子目录</p>
<p>$ git add [dir]</p>
<p># 添加当前目录的所有文件到暂存区</p>
<p>$ git add .</p>
<p># 添加每个变化前，都会要求确认# 对于同一个文件的多处变化，可以实现分次提交</p>
<p>$ git add -p</p>
<p># 删除工作区文件，并且将这次删除放入暂存区</p>
<p>$ git rm [file1] [file2] …</p>
<p># 停止追踪指定文件，但该文件会保留在工作区</p>
<p>$ git rm –cached [file]</p>
<p># 改名文件，并且将这个改名放入暂存区</p>
<p>$ git mv [file-original] [file-renamed]</p>
<p># 提交暂存区到仓库区</p>
<p>$ git commit -m [message]</p>
<p># 提交暂存区的指定文件到仓库区</p>
<p>$ git commit [file1] [file2] … -m [message]</p>
<p># 提交工作区自上次commit之后的变化，直接到仓库区</p>
<p>$ git commit -a</p>
<p># 提交时显示所有diff信息</p>
<p>$ git commit -v</p>
<p># 使用一次新的commit，替代上一次提交# 如果代码没有任何新变化，则用来改写上一次commit的提交信息</p>
<p>$ git commit –amend -m [message]</p>
<p># 重做上一次commit，并包括指定文件的新变化</p>
<p>$ git commit –amend [file1] [file2] …</p>
<p># 列出所有远程分支</p>
<p>$ git branch -r</p>
<p># 列出所有本地分支和远程分支</p>
<p>$ git branch -a</p>
<p># 新建一个分支，但依然停留在当前分支</p>
<p>$ git branch [branch-name]</p>
<p># 新建一个分支，并切换到该分支</p>
<p>$ git checkout -b [branch]</p>
<p># 新建一个分支，指向指定commit</p>
<p>$ git branch [branch] [commit]</p>
<p># 新建一个分支，与指定的远程分支建立追踪关系</p>
<p>$ git branch –track [branch] [remote-branch]</p>
<p># 切换到指定分支，并更新工作区</p>
<p>$ git checkout [branch-name]</p>
<p># 切换到上一个分支</p>
<p>$ git checkout -</p>
<p># 合并指定分支到当前分支</p>
<p>$ git merge [branch]</p>
<p># 选择一个commit，合并进当前分支</p>
<p>$ git cherry-pick [commit]</p>
<p># 删除分支</p>
<p>$ git branch -d [branch-name]</p>
<p># 删除远程分支</p>
<p>$ git push origin –delete [branch-name]</p>
<p>$ git branch -dr [remote/branch]</p>
<p>Windows系统上面的更新脚本：</p>
<figure class="highlight bat"><table><tbody><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">::::::::::::::::::::::::::::::::::::::::::::</span><br><span class="line"></span><br><span class="line">::    Usage: ./update.bat "msg"     ::</span><br><span class="line"></span><br><span class="line">::::::::::::::::::::::::::::::::::::::::::::</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">@<span class="built_in">echo</span> off</span><br><span class="line"></span><br><span class="line"><span class="built_in">setlocal</span> enabledelayedexpansion</span><br><span class="line"></span><br><span class="line">@<span class="built_in">echo</span> "<span class="built_in">start</span> update!"</span><br><span class="line"></span><br><span class="line"><span class="built_in">pause</span></span><br><span class="line"></span><br><span class="line">:: 下方设置参数</span><br><span class="line"></span><br><span class="line">@<span class="built_in">set</span> <span class="built_in">DATE</span>="<span class="variable">%date%</span> <span class="variable">%time%</span>"</span><br><span class="line"></span><br><span class="line">@<span class="built_in">set</span> FILE="%<span class="number">0</span>"</span><br><span class="line"></span><br><span class="line">@<span class="built_in">set</span> MSG="%<span class="number">1</span>"</span><br><span class="line"></span><br><span class="line"><span class="built_in">pause</span></span><br><span class="line"></span><br><span class="line">:: 下方将双引号删除</span><br><span class="line"></span><br><span class="line">@<span class="built_in">set</span> FILE=<span class="variable">%FILE:"=%</span></span><br><span class="line"></span><br><span class="line">@<span class="built_in">set</span> MSG=<span class="variable">%MSG:"=%</span></span><br><span class="line"></span><br><span class="line">@<span class="built_in">set</span> <span class="built_in">DATE</span>=<span class="variable">%DATE:"=%</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">pause</span></span><br><span class="line"></span><br><span class="line">:: 下方更新git</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> E:\work\sdk_server_release</span><br><span class="line"></span><br><span class="line"><span class="built_in">dir</span></span><br><span class="line"></span><br><span class="line">git status</span><br><span class="line"></span><br><span class="line">git remote -v</span><br><span class="line"></span><br><span class="line">:: 多人协作首先pull一下到本地</span><br><span class="line"></span><br><span class="line">git pull origin master</span><br><span class="line"></span><br><span class="line"><span class="built_in">pause</span></span><br><span class="line"></span><br><span class="line">git status</span><br><span class="line"></span><br><span class="line"><span class="built_in">pause</span></span><br><span class="line"></span><br><span class="line">git config --global http.postBuffer <span class="number">524288000</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> "<span class="built_in">set</span> postbuffer"</span><br><span class="line"></span><br><span class="line"><span class="built_in">pause</span></span><br><span class="line"></span><br><span class="line">@git add .</span><br><span class="line"></span><br><span class="line"><span class="built_in">pause</span></span><br><span class="line"></span><br><span class="line">@git commit -m "<span class="variable">%FILE%</span> : <span class="variable">%MSG%</span> <span class="variable">%DATE%</span>"</span><br><span class="line"></span><br><span class="line"><span class="built_in">pause</span></span><br><span class="line"></span><br><span class="line">@git push origin master</span><br><span class="line"></span><br><span class="line"><span class="built_in">pause</span></span><br><span class="line"></span><br><span class="line">::::::::::::::::::::::::::::::::::::::::::::</span><br><span class="line"></span><br><span class="line">::   written by -_-     ::</span><br><span class="line"></span><br><span class="line">::::::::::::::::::::::::::::::::::::::::::::</span><br></pre></td></tr></tbody></table></figure>

]]></content>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>docker 安装walle2部署项目</title>
    <url>/2023/112024358.html</url>
    <content><![CDATA[<p>​     项目从git上面拉取代码，然后打包推送到服务器，更新启动服务，开发大神需要ci/cd平台，当前开源的可能walle和蓝鲸cmdb系统比较实用，123正反面选择了walle，据说已经停了好久，不过对于项目来说够用了，开始吧。</p>
<h1 id="1-walle2-安装"><a href="#1-walle2-安装" class="headerlink" title="1. walle2 安装"></a>1. walle2 安装</h1><p>前期准备：</p>
<p>cat /etc/redhat-release &amp;&amp; uname -a</p>
<p>CentOS Linux release 7.8.2003 (Core)</p>
<p>Linux centos7-1 3.10.0-1127.el7.x86_64 </p>
<p>systemctl stop firewalld &amp;&amp; systemctl disable firewalld</p>
<p>echo SELINUX=disabled &gt; /etc/sysconfig/selinux </p>
<p>cp  /etc/sysctl.conf /etc/sysctl.conf.bak</p>
<p>echo net.ipv4.tcp_syncookies = 1 &gt;&gt; /etc/sysctl.conf</p>
<p>echo net.ipv4.tcp_tw_reuse = 1 &gt;&gt; /etc/sysctl.conf</p>
<p>echo net.ipv4.tcp_tw_recycle = 1 &gt;&gt; /etc/sysctl.conf</p>
<p>echo net.ipv4.tcp_fin_timeout = 10 &gt;&gt; /etc/sysctl.conf</p>
<p>echo net.ipv4.ip_forward = 1  &gt;&gt; /etc/sysctl.conf</p>
<p>sysctl -p</p>
<p>1.Docker 安装：</p>
<p>yum install -y yum-utils device-mapper-persistent-data lvm2</p>
<p>yum-config-manager –add-repo <a href="http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo">http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</a></p>
<p>yum install docker-ce docker-ce-cli containerd.io</p>
<p>systemctl start dockersystemctl enable docker</p>
<p>注意：在安装过程中，也许会遇到Requires: container-selinux &gt;= 2.9 的异常；可以打开 Centos下载包中的最新container-selinux包的地址,</p>
<p>然后运行：yum install -y <a href="http://mirror.centos.org/centos/7/extras/x86_64/Packages/container-selinux-2.68-1.el7.noarch.rpm">http://mirror.centos.org/centos/7/extras/x86_64/Packages/container-selinux-2.68-1.el7.noarch.rpm</a></p>
<p>当然也可以：</p>
<p>curl -fsSL <a href="https://get.docker.com/">https://get.docker.com</a> -o get-docker.sh</p>
<p>bash  get-docker.sh运行安装docker</p>
<p>2.docker-compose安装：</p>
<p>curl -L <a href="https://github.com/docker/compose/releases/download/1.24.0/docker-compose-%60uname">https://github.com/docker/compose/releases/download/1.24.0/docker-compose-`uname</a> -s<code>-</code>uname -m` -o /usr/local/bin/docker-compose</p>
<p>chmod +x /usr/local/bin/docker-compose</p>
<p>3.创建初始文件：walle.env：</p>
<p>在docker-compose.yml同级目录新建出示文件walle.env，连接数据库MYSQL_USER默认使用root,如需使用其他用户，需自建用户更改walle.env文件</p>
<p>vim walle.env</p>
<p>Set MySQL/Rails environment</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">MYSQL_USER=root</span><br><span class="line">MYSQL_PASSWORD=walle#123</span><br><span class="line">MYSQL_DATABASE=walle</span><br><span class="line">MYSQL_ROOT_PASSWORD=walle#123</span><br><span class="line">MYSQL_HOST=db</span><br><span class="line">MYSQL_PORT=3306</span><br></pre></td></tr></tbody></table></figure>

<p>MYSQL_ROOT_PASSWORD=walle#123 这个是那个的root密码没明白-_-</p>
<p>4.编写docker-compose的yaml文件：</p>
<p>参考： <a href="https://walle-web.io/docs/installation_docker.html">https://walle-web.io/docs/installation_docker.html</a></p>
<figure class="highlight yml"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># docker version:  18.06.0+</span></span><br><span class="line"><span class="comment"># docker-compose version: 1.23.2+</span></span><br><span class="line"><span class="comment"># OpenSSL version: OpenSSL 1.1.0h</span></span><br><span class="line"><span class="attr">version:</span> <span class="string">"3.7"</span></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">web:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">alenx/walle-web:2.1</span></span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">walle-nginx</span></span><br><span class="line">    <span class="attr">hostname:</span> <span class="string">nginx-web</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="comment"># 如果宿主机80端口被占用，可自行修改为其他port(&gt;=1024)</span></span><br><span class="line">      <span class="comment"># 0.0.0.0:要绑定的宿主机端口:docker容器内端口80</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">"80:80"</span></span><br><span class="line">    <span class="attr">depends_on:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">python</span></span><br><span class="line">    <span class="attr">networks:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">walle-net</span></span><br><span class="line">    <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">python:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">alenx/walle-python:2.1</span></span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">walle-python</span></span><br><span class="line">    <span class="attr">hostname:</span> <span class="string">walle-python</span></span><br><span class="line">    <span class="attr">env_file:</span></span><br><span class="line">      <span class="comment"># walle.env需和docker-compose在同级目录</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">./walle.env</span></span><br><span class="line">    <span class="attr">command:</span> <span class="string">bash</span> <span class="string">-c</span> <span class="string">"cd /opt/walle_home/ &amp;&amp; /bin/bash admin.sh migration &amp;&amp;  python waller.py"</span></span><br><span class="line">    <span class="attr">expose:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">"5000"</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">/opt/walle_home/plugins/:/opt/walle_home/plugins/</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">/opt/walle_home/codebase/:/opt/walle_home/codebase/</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">/opt/walle_home/logs/:/opt/walle_home/logs/</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">/root/.ssh:/root/.ssh/</span></span><br><span class="line">    <span class="attr">depends_on:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">db</span></span><br><span class="line">    <span class="attr">networks:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">walle-net</span></span><br><span class="line">    <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">db:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">mysql</span></span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">walle-mysql</span></span><br><span class="line">    <span class="attr">hostname:</span> <span class="string">walle-mysql</span></span><br><span class="line">    <span class="attr">env_file:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">./walle.env</span></span><br><span class="line">    <span class="attr">command:</span> [ <span class="string">'--default-authentication-plugin=mysql_native_password'</span>, <span class="string">'--character-set-server=utf8mb4'</span>, <span class="string">'--collation-server=utf8mb4_unicode_ci'</span>]</span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">"3306:3306"</span></span><br><span class="line">    <span class="attr">expose:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">"3306"</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">/data/walle/mysql:/var/lib/mysql</span></span><br><span class="line">    <span class="attr">networks:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">walle-net</span></span><br><span class="line">    <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line"></span><br><span class="line"><span class="attr">networks:</span></span><br><span class="line">  <span class="attr">walle-net:</span></span><br><span class="line">    <span class="attr">driver:</span> <span class="string">bridge</span></span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>



<p>5.一键启动：<br>docker-compose up -d注意：要再yaml目录下，而且env文件也要再此目录下。</p>
<p>docker-compose up -d&amp;&amp; docker-compose logs -f</p>
<p><img src="/../images/20231120_1.png"></p>
<p>docker ps -a #查看镜像</p>
<p>docker-compose down #关闭并删除镜像</p>
<p>docker-compose  start/stop/rm  容器  #打开/停止/删除镜像</p>
<p>常用操作</p>
<p>构建服务</p>
<p>docker-compose build</p>
<p>启动服务,启动过程中可以直接查看终端日志，观察启动是否成功</p>
<p>docker-compose up</p>
<p>启动服务在后台，如果确认部署成功，则可以使用此命令，将应用跑在后台，作用类似 nohup python waller.py &amp;</p>
<p>docker-compose up -d</p>
<p>查看日志,效果类似 tail -f waller.log</p>
<p>docker-compose logs -f</p>
<p>停止服务,会停止服务的运行，但是不会删除服务所所依附的网络，以及存储等</p>
<p>docker-compose stop</p>
<p>删除服务，并删除服务产生的网络，存储等，并且会关闭服务的守护</p>
<p>docker-compose down</p>
<p>docker 安装walle2部署项目<br><a href="https://blog.51cto.com/xpu2001/6951109">https://blog.51cto.com/xpu2001/6951109</a></p>
<p>docker-compose down</p>
<p>[root@iZt4niz156030y3q2videiZ bin]# ./docker-compose stop</p>
<p><img src="/images/20231120_2.png"></p>
<p>[root@iZt4niz156030y3q2videiZ bin]# ./docker-compose  start</p>
<p><img src="/images/20231120_3.png"></p>
<p>常见错误</p>
<p>1.如果遇见一下错误（Can’t connat to mysql server on ‘db’），请docker-compose down之后再docker-compose up一次就可以了，这是mysql没有初始化完，就启动了python-server.</p>
<p><img src="/images/20231120_4.png"></p>
<p>[root@iZt4niz156030y3q2videiZ bin]# docker ps</p>
<p>CONTAINER ID   IMAGE                    COMMAND                  CREATED       STATUS         PORTS                               NAMES</p>
<p>ecc54f24309b   alenx/walle-web:2.1      “nginx -g ‘daemon of…”   2 hours ago   Up 2 seconds   0.0.0.0:80-&gt;80/tcp                  walle-nginx</p>
<p>ceae5c89959f   alenx/walle-python:2.1   “bash -c ‘cd /opt/wa…”   2 hours ago   Up 2 seconds   5000/tcp                            walle-python</p>
<p>b62c91374266   mysql                    “docker-entrypoint.s…”   2 hours ago   Up 3 seconds   0.0.0.0:3306-&gt;3306/tcp, 33060/tcp   walle-mysql</p>
<h1 id="2-项目部署"><a href="#2-项目部署" class="headerlink" title="2.项目部署"></a>2.项目部署</h1><p>登录进去有5个默认账号：</p>
<p>超管：<a href="mailto:super@walle-web.io">super@walle-web.io</a> \ Walle123</p>
<p>所有者：<a href="mailto:owner@walle-web.io">owner@walle-web.io</a> \ Walle123</p>
<p>负责人：<a href="mailto:master@walle-web.io">master@walle-web.io</a> \ Walle123</p>
<p>开发者：<a href="mailto:developer@walle-web.io">developer@walle-web.io</a> \ Walle123</p>
<p>访客：<a href="mailto:reporter@walle-web.io">reporter@walle-web.io</a> \ Walle123</p>
<p>用超管进去，可以编辑账号信息，和管理空间。至于这几个账号权限和关系，参照： <a href="https://walle-web.io/docs/configuration-user.html">https://walle-web.io/docs/configuration-user.html</a></p>
<p>账号和空间配置完毕以后，进入环境管理，一般开发环境，线上和测试环境，或者自定义。</p>
<p>环境管理-添加项目环境：</p>
<p><img src="/images/20231120_5.png"></p>
<p>服务器管理–添加服务器:</p>
<p><img src="/images/20231120_6.png"></p>
<p>项目管理–添加项目</p>
<p><img src="/images/20231120_7.png"></p>
<p><img src="/images/20231120_8.png" alt="9"></p>
<p>做了一个简单测试，看下效果：git提取代码，更新到服务器上面，用supervisor启动服务进程。</p>
<p>创建上线单：</p>
<p><img src="/images/20231120_9.png"></p>
<p>提交，审核，上线：</p>
<p><img src="/images/20231120_10.png"></p>
<p>服务器效果：</p>
<p> public -&gt; /data/www/release/19_18_20230802_18365</p>
<p>cd /data/www/release/ &amp;&amp; ls</p>
<p>11_10_20230728_142237  11_10_20230728_142342  11_12_20230731_175251  11_13_20230801_103508  11_15_20230801_173410  11_16_20230801_181332  11_17_20230802_161908  19_18_20230802_183658</p>
<p>每次更新做的软连接，对应data/www/release下面的几个版本号；回滚就是把连接做到原来的补丁上面；</p>
<p>似乎walle2没有增量，单个文件更新功能，或者没找到在哪，walle1有这个功能，实属可惜。</p>
<p>说明：walle服务器需要到所管理的服务器实现免密访问，如果用其他用户也需要把用户的做免密。</p>
<p>碰到的问题：项目管理，免密已经做好了测试正常，但是检测不通过，日志报timeout</p>
<p>ERROR /opt/walle_home/walle/service/waller.py 111 waller.run task_id=0, user:www host:192.168.8.96 command:[ -d wwwroot ] || mkdir -p wwwroot, status=1, message:</p>
<p>error: [Errno 110] Connection timed out</p>
<p><img src="/images/20231120_11.png"></p>
<p>没头绪，后面一次次尝试中发现，是docker cat /etc/docker/daemon.json</p>
<p>Iptables设置的问题，可以尝试去掉再试试。</p>
<p>{</p>
<p>  “iptables”:false</p>
<p>}</p>
<p>做个简单笔记而已。</p>
<p>参考：</p>
<p> <a href="https://walle-web.io/docs/configuration-user.html">https://walle-web.io/docs/configuration-user.html</a></p>
<p> <a href="https://www.yj-example.cn/?p=505">https://www.yj-example.cn/?p=505</a></p>
<hr>
]]></content>
      <categories>
        <category>系统</category>
      </categories>
      <tags>
        <tag>点滴</tag>
      </tags>
  </entry>
  <entry>
    <title>frp搭建</title>
    <url>/2023/062739776.html</url>
    <content><![CDATA[<p> &nbsp; 开发不在公司需要连到公司内网调试业务，有点周折，frp内网穿透来帮忙。网上很多文章，自己做个小笔记。</p>
<p>首先到官网：</p>
<p>&nbsp;<a href="https://github.com/fatedier/frp/releases">https://github.com/fatedier/frp/releases</a></p>
<p>下载: frp_0.16.0_linux_amd64.tar.gz服务器端</p>
<p>解压出来ls:</p>
<p>frpc&nbsp; frpc_full.ini&nbsp; frpc_http.ini&nbsp; frpc.ini&nbsp; frps&nbsp; frps_full.ini&nbsp; frps.ini&nbsp; LICENSE&nbsp; nohup.out</p>
<p>服务器端只需要两个文件frps和frps.ini,其中frps为可执行文件，frps.ini为配置文件默认配置文件如下：其中bind_addr为本机IP,bind_port为frp对客户端的端口号，auto_token是客户端连接服务器端的口令。</p>
<p>[common]</p>
<p>Bind_addr=0.0.0.0</p>
<p>Bind_port =4443</p>
<p>Auto_token = frp</p>
<p>配置好以后可以运行起来./frps -c ./frps.ini</p>
<p>最好后台运行：nohup ./frps -c ./frps.ini &amp;</p>
<p>2018/05/17 10:49:11 [I] [service.go:96] frps tcp listen on 0.0.0.0:4443</p>
<p>2018/05/17 10:49:11 [I] [main.go:112] Start frps success</p>
<p>&nbsp;需要穿透端口的服务器端开启：</p>
<p>nohup ./frps -c ./frps.ini &amp;</p>
<p>同样将客户端解压后有七个文件，只需要frpc和frpc.ini,配置文件如下：</p>
<p>&nbsp;[common]</p>
<p>Server_addr = 123.123.123.123</p>
<p>Server_port = 4443</p>
<p>Auto-token = frp</p>
<p>[ssh_1]</p>
<p>Type = tcp</p>
<p>Local_ip = 127.0.0.1</p>
<p>Local_port = 22</p>
<p>Remote_port = 10085</p>
<p>注意：server_addr是服务器端的公网IP地址，server_port是frp服务端口号，auto_token是连接服务器的口令，必须和服务器保持一致。[ssh_1]是客户端通过服务器与用户之间的通道名，每个客户端必须不一样，remote_port是服务器端对外提供本机服务的端口号，即用户连接123.123.123.123:10085，相当于连接127.0.0.1:22,即arm板上的ssh服务</p>
<p>运行客户端：./frpc -c ./frpc.ini</p>
<p>&nbsp;</p>
<p>当前的配置</p>
<p>more frpc.ini</p>
<p>[common]</p>
<p>server_addr = dem.abc.com</p>
<p>server_port = 7000</p>
<p>[game]</p>
<p>type = tcp</p>
<p>local_ip = 192.168.1.232</p>
<p>local_port = 9001</p>
<p>remote_port = 6000</p>
<p>&nbsp;</p>
<p>[http]</p>
<p>type = tcp</p>
<p>local_ip = 192.168.1.232</p>
<p>local_port = 80</p>
<p>remote_port = 6001</p>
<p>&nbsp;</p>
<p>[mysql]</p>
<p>type = tcp</p>
<p>local_ip = 192.168.1.235</p>
<p>local_port = 3306</p>
<p>remote_port = 13306</p>
<p>more frpc_http.ini</p>
<p>[common]</p>
<p>server_addr = dem.abc.com</p>
<p>server_port = 7000</p>
<p>&nbsp;</p>
<p>[http]</p>
<p>type = tcp</p>
<p>local_ip = 192.168.1.232</p>
<p>local_port = 80</p>
<p>remote_port = 6001</p>
<p>这样demo.abc.com 的13306映射到3306,6001映射到80端口等等；</p>
<p>在客户端开启：最好后台运行启动客户端proxy：</p>
<p>nohup ./frpc&nbsp; -c ./frpc.ini &amp;</p>
<p>[I] [control.go:240] [e465e02f8bad1e5b] login to server success, get run id [e465e02f8bad1e5b], server udp port [0]</p>
<p>2018/05/17 10:48:16 [I] [control.go:165] [e465e02f8bad1e5b] [http] start proxy success</p>
<p>2018/05/17 10:48:16 [I] [control.go:165] [e465e02f8bad1e5b] [mysql] start proxy success</p>
<p>2018/05/17 10:49:11 [I] [service.go:96] frps tcp listen on 0.0.0.0:7000</p>
<p>2018/05/17 10:49:11 [I] [main.go:112] Start frps success</p>
<p>2018/05/17 10:49:11 [I] [main.go:114] PrivilegeMode is enabled, you should pay more attention to security issues</p>
<p>&nbsp;</p>
<p>PS：配置很简单，但是记得nohup ./frps -c ./frps.ini &amp; 在要穿透的远程服务器开启，nohup ./frpc&nbsp; -c ./frpc.ini &amp; 在内网开启，记得开放远程服务器穿透端口；</p>
<hr>
]]></content>
      <categories>
        <category>系统</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2023/062516107.html</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></tbody></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></tbody></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></tbody></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></tbody></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
  </entry>
  <entry>
    <title>hello,mongodb</title>
    <url>/2023/12146947.html</url>
    <content><![CDATA[<p>Mongodb 安装：</p>
<h2 id="一-debian安装"><a href="#一-debian安装" class="headerlink" title="一. debian安装:"></a>一. debian安装:</h2><ol>
<li>导入apt包管理系统需要使用的公钥。<br>在终端执行以下命令以从&nbsp;<a href="https://www.mongodb.org/static/pgp/server-5.0.asc">https://www.mongodb.org/static/pgp/server-5.0.asc</a>&nbsp;导入 MongoDB GPG 公钥。<br>wget -qO - <a href="https://www.mongodb.org/static/pgp/server-5.0.asc">https://www.mongodb.org/static/pgp/server-5.0.asc</a> | sudo apt-key add -<br>该操作应该会以OK响应。<br>但是，如果你收到错误提示未安装gnupg的错误，则需要：<br>安装gnupg及其所需的库：<br>  sudo apt-get install gnupg<br>安装完成后，再次导入密钥<br>  wget -qO - <a href="https://www.mongodb.org/static/pgp/server-5.0.asc">https://www.mongodb.org/static/pgp/server-5.0.asc</a> | sudo apt-key add -</li>
<li>为 MongoDB 创建/etc/apt/sources.list.d/mongodb-org-5.0.list文件<br>Debian 10:<br>echo “deb <a href="http://repo.mongodb.org/apt/debian">http://repo.mongodb.org/apt/debian</a> buster/mongodb-org/5.0 main” | sudo tee /etc/apt/sources.list.d/mongodb-org-5.0.list</li>
<li>更新apt源<br>sudo apt-get update</li>
<li>安装 MongoDB 包<br>sudo apt-get install -y mongodb-org</li>
<li>运行MongoDB<br>默认情况下，MongoDB实例存储位置：<br>其数据文件位于&nbsp;/var/lib/mongodb<br>其日志文件在&nbsp;/var/log/mongodb<br>如果通过程序包管理器安装，则这些默认目录是在安装过程中创建的。<br>如果通过下载tarball手动安装，则可以使用mkdir -p <directory>或sudo mkdir -p <directory>来创建目录<br>默认情况下，MongoDB使用mongodb用户帐户运行。如果更改运行MongoDB进程的用户，则还必须修改对/var/lib/mongodb和/var/log/mongodb&nbsp;目录的权限，以使该用户可以访问这些目录。<br>要指定其他日志文件目录和数据文件目录，请在/etc/mongod.conf中编辑systemLog.path和storage.dbPath。确保运行MongoDB的用户有权访问这些目录。<br>启动流程：<br>按照以下步骤在运行 MongoDB社区版。 此处假设你使用的是官方的mongodb-org包，而不是 Debian 提供的非官方的mongodb包，并且使用的是默认设置。<br>初始化系统：<br>要运行和管理mongod进程，需要使用操作系统的内置init系统。 最新版本的 Linux 倾向于使用systemd(&nbsp;systemctl命令 )，而旧版本的 Linux 倾向于使用System V init(service命令)。<br>如果你不确定你的平台使用哪个初始化系统，请运行以下命令：<br>ps –no-headers -o comm 1<br>systemd(systemctl):<br>.启动MongoDB<br>sudo systemctl start mongod<br>如果在启动 mongod 时出现类似以下的错误：<br>Failed to start mongod.service: Unit mongod.service not found.<br>首先运行以下命令：<br>sudo systemctl daemon-reload<br>然后再次运行上面的启动命令。</directory></directory></li>
<li>验证MongoDB是否已成功启动<br>sudo systemctl status mongod<br>可以选择通过以下命令来确保 MongoDB 将在系统重新启动后启动：<br>sudo systemctl enable mongod</li>
<li>终止MongoDB<br>sudo systemctl stop mongod</li>
<li>重启MongoDB<br>sudo systemctl restart mongod<br>可以通过查看/var/log/mongodb/mongod.log文件中的输出来跟踪错误或重要消息的进程状态。</li>
<li>开始使用MongoDB<br>在与mongod相同的主机上启动mongosh会话。 在没有命令行选项时运行mongosh，会连接到localhost:27017上的mongod实例。<br>mongosh<br>有关使用 mongosh 进行连接的更多信息，例如连接到在不同主机和(或)端口上运行的 mongod 实例，请参阅mongosh文档。</li>
</ol>
<h2 id="二-Red-Hat-CentOS："><a href="#二-Red-Hat-CentOS：" class="headerlink" title="二. Red Hat/CentOS："></a>二. Red Hat/CentOS：</h2><p>sudo yum install libcurl openssl</p>
<p>Ubuntu 18.04 LTS (“Bionic”)/Debian 10 “Buster”：</p>
<p>sudo apt-get install libcurl4 openssl</p>
<p>Ubuntu 16.04 LTS (“Xenial”)/Debian 9 “Stretch”：</p>
<p>sudo apt-get install libcurl3 openssl</p>
<p>MongoDB 源码下载地址：<a href="https://www.mongodb.com/try/download/community">https://www.mongodb.com/try/download/community</a></p>
<p><img src="/../images/20231214_1.png"></p>
<p>Server 是下载了rpm包直接 yum localinstall 安装；以后自动生成mongodbservice</p>
<p> /usr/lib/systemd/system/mongod.service </p>
<p>-rw-r–r– 1 root root 811 Nov 16 07:05 /usr/lib/systemd/system/mongod.service</p>
<p>我们下载了tgz包，Copy link 复制下载包url</p>
<p>wget <a href="https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-rhel70-7.0.4.tgz">https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-rhel70-7.0.4.tgz</a></p>
<p>tar xvf mongodb-linux-x86_64-rhel70-7.0.4.tgz</p>
<p>mv f mongodb-linux-x86_64-rhel70-7.0.4 mongodb &amp;&amp; mv mongodb /usr/local/</p>
<p>vi /etc/profile</p>
<p>export PATH=$PATH:/usr/local/mongodb/bin</p>
<p>source /etc/profile</p>
<p>在需要的数据盘下面建文件夹，</p>
<p>Cd /data &amp;&amp; mkdir -p mongo log</p>
<p>Touch log/mongodb.log</p>
<p>vi mongodb.conf</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">dbpath = /usr/local/mongodb/data  \# mongodb数据文件存储路径（指定数据库目录）</span><br><span class="line">logpath = /usr/local/mongodb/logs/mongodb.log  \# mongodb的日志路径(指定日志文件目录)</span><br><span class="line">logappend = true  \# 日志使用追加代替覆盖</span><br><span class="line">port = 27017  \# 端口</span><br><span class="line">fork = true  \# 以守护程序的方式启用，即在后台运行</span><br><span class="line">auth = false \# 认证模式，需要设置账号和密码(下一步设置)</span><br><span class="line">bind_ip = 127.0.0.1 \# 远程连接</span><br></pre></td></tr></tbody></table></figure>

<p>启动：mongod -f mongodb.conf</p>
<p>mongod  -f mongodb.conf </p>
<p>about to fork child process, waiting until server is ready for connections.</p>
<p>forked process: 26741</p>
<p>child process started successfully, parent exiting</p>
<p>添加系统服务：</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">[Unit]</span><br><span class="line">Description=MongoDB Database Server</span><br><span class="line">Documentation=https://docs.mongodb.org/manual</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=forking</span><br><span class="line">ExecStart=/usr/local/mongodb/bin/mongod --config /data/mongo/mongodb.conf</span><br><span class="line">ExecReload=/bin/kill -s HUP $MAINPID</span><br><span class="line">ExecStop=/usr/local/mongodb/bin/mongod --shundown --config /data/mongo/mongodb.conf</span><br><span class="line">ExecReload=/bin/kill -s HUP $MAINPID</span><br><span class="line">Restart=always</span><br><span class="line">PrivateTmp=true</span><br><span class="line">LimitNOFILE=64000</span><br><span class="line">LimitNPROC=64000</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>

<p> systemctl daemon-reload &amp;&amp; systemctl start mongod</p>
<p>进入mongodb时候报错了，mongo：command not found；</p>
<p>/usr/local/mongodb/bin下面没有mongo；</p>
<p><a href="https://www.mongodb.com/try/download/shell">https://www.mongodb.com/try/download/shell</a></p>
<p>需要到官网下一个mongosh，</p>
<p>wget <a href="https://downloads.mongodb.com/compass/mongodb-mongosh-2.1.1.x86_64.rpm">https://downloads.mongodb.com/compass/mongodb-mongosh-2.1.1.x86_64.rpm</a></p>
<p>yum localinstall mongodb-mongosh-2.1.1.x86_64.rpm</p>
<p><img src="/../images/20231214_2.png"></p>
<h2 id="三-使用Mongodb"><a href="#三-使用Mongodb" class="headerlink" title="三. 使用Mongodb"></a>三. 使用Mongodb</h2><p>进入以后设置管理员账号，</p>
<p>test&gt; use admin</p>
<p>switched to db admin</p>
<p>admin&gt; db.createUser({user:”root”,pwd:”admin123”,roles:[{role:”root”,db:”admin”}]})</p>
<p>{ ok: 1 }</p>
<p>修改mongodb.conf auth = true 开启授权模式；</p>
<p>普通用户授权：</p>
<p><img src="/../images/20231214_3.png"></p>
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">jary_test&gt; db.createUser({user:"jary",pwd:"abc123",roles:[{role:"readWrite",db:"jary_test"}]})</span><br><span class="line"></span><br><span class="line">{ ok: 1 }</span><br><span class="line"></span><br><span class="line">jary_test&gt; show users</span><br><span class="line"></span><br><span class="line">[</span><br><span class="line"></span><br><span class="line"> {</span><br><span class="line"></span><br><span class="line">  _id: 'jary_test.jary',</span><br><span class="line"></span><br><span class="line">  userId: UUID('64e3c53b-652e-424c-abe7-1c981d603287'),</span><br><span class="line"></span><br><span class="line">  user: 'jary',</span><br><span class="line"></span><br><span class="line">  db: 'jary_test',</span><br><span class="line"></span><br><span class="line">  roles: [ { role: 'readWrite', db: 'jary_test' } ],</span><br><span class="line"></span><br><span class="line">  mechanisms: [ 'SCRAM-SHA-1', 'SCRAM-SHA-256' ]</span><br><span class="line"></span><br><span class="line"> }</span><br><span class="line"></span><br><span class="line">]</span><br></pre></td></tr></tbody></table></figure>

<p>查看用户：</p>
<p>#切换到admin数据库</p>
<p>use admin</p>
<p>#查看所有用户</p>
<p>db.system.users.find()</p>
<p>#删除用户</p>
<p>db.system.users.deleteOne({user:”jary2”})</p>
<p>admin&gt; db.system.users.deleteOne({user:”jary2”})</p>
<p>{ acknowledged: true, deletedCount: 1 }</p>
<p><img src="/../images/20231214_4.png"></p>
<p>建立数据库：</p>
<p>admin&gt; use jary_test</p>
<p>switched to db jary_test</p>
<p>jary_test&gt; db</p>
<p>jary_test</p>
<p>插入数据：</p>
<p>jary_test&gt; db.jary_test.insertOne({“name”:”zhr”,”age”:”31”,”online”:”true”})</p>
<p>{</p>
<p> acknowledged: true,</p>
<p> insertedId: ObjectId(‘657ab816940239e3d1eaeb07’)</p>
<p>}</p>
<p>jary_test&gt; show dbs</p>
<p>admin    148.00 KiB</p>
<p>config    60.00 KiB</p>
<p>jary_test   8.00 KiB</p>
<p>local    72.00 KiB</p>
<p>use jary_test2</p>
<p>switched to db jary_test2</p>
<p>jary_test2&gt; show dbs</p>
<p>admin    180.00 KiB</p>
<p>config   108.00 KiB</p>
<p>jary_test  40.00 KiB</p>
<p>local    72.00 KiB</p>
<p>刚创建的库不在数据库列表里面，需要插入数据。</p>
<p>jary_test2&gt; db.jary_test2.insertOne({“name”:”zruo”,”score”:”98”})</p>
<p>{</p>
<p> acknowledged: true,</p>
<p> insertedId: ObjectId(‘657abb6c940239e3d1eaeb08’)</p>
<p>}</p>
<p>jary_test2&gt; show dbs</p>
<p>admin    180.00 KiB</p>
<p>config    108.00 KiB</p>
<p>jary_test   40.00 KiB</p>
<p>jary_test2  40.00 KiB</p>
<p>local     72.00 KiB</p>
<p>删除数据库：</p>
<p>jary_test2&gt; use jary_test2</p>
<p>already on db jary_test2</p>
<p>jary_test2&gt; db.dropDatabase()</p>
<p>{ ok: 1, dropped: ‘jary_test2’ }</p>
<p>jary_test2&gt; show dbs</p>
<p>admin    180.00 KiB</p>
<p>config   108.00 KiB</p>
<p>jary_test  40.00 KiB</p>
<p>local    72.00 KiB</p>
<p><img src="/../images/20231214_5.png"></p>
]]></content>
      <tags>
        <tag>mongodb</tag>
      </tags>
  </entry>
  <entry>
    <title>hexogit搭建个人网站</title>
    <url>/2023/111457802.html</url>
    <content><![CDATA[<h2 id="1-nodejs安装"><a href="#1-nodejs安装" class="headerlink" title="1. nodejs安装"></a>1. nodejs安装</h2><p> 使用Node Version Manager（nvm工具）</p>
<p> install stable`是使用Node Version Manager（nvm）安装Node.js的命令。nvm是一个用于管理多个Node.js版本的工具，可以轻松地在同一台机器上安装、切换和管理不同版本的Node.js。</p>
<p><code>nvm install stable</code>指令表示安装最新的稳定版本的Node.js。执行此命令后，nvm会从Node.js官方仓库下载并自动安装最新的稳定版Node.js。安装过程可能需要一些时间，具体取决于您的网络速度。</p>
<p>在centOS上安装Node.js，您可以按照以下步骤进行操作：</p>
<p>1). 使用以下命令更新系统软件包：</p>
<p>sudo yum update</p>
<p>2). 安装Node.js依赖项。使用以下命令执行：</p>
<p>sudo yum install -y gcc-c++ make</p>
<p>相关库</p>
<p>3). 更新系统：</p>
<p>sudo yum update<br>(2). 安装EPEL存储库（Extra Packages for Enterprise Linux，附加软件包）：</p>
<p>sudo yum install epel-release<br>(3). 安装devtoolset-7工具集：</p>
<p>sudo yum install centos-release-scl</p>
<p>sudo yum install devtoolset-7<br>(4). 启用devtoolset-7工具集：</p>
<p>scl enable devtoolset-7 bash</p>
<p>sudo yum install centos-release-scl</p>
<p>sudo yum install devtoolset-7-gcc devtoolset-7-gcc-c++ devtoolset-7-libstdc++-devel</p>
<p>ps. 在CentOS上，您可以使用Node Version Manager（NVM）来安装和管理多个Node.js版本。首先，在CentOS上安装NVM。使用以下命令从NVM的GitHub仓库获取安装脚本：</p>
<p>curl -o- <a href="https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.0/install.sh">https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.0/install.sh</a> | bash国内：</p>
<p>curl -o- <a href="https://gitee.com/mirrors/nvm/raw/v0.39.0/install.sh">https://gitee.com/mirrors/nvm/raw/v0.39.0/install.sh</a> | bash</p>
<p>注意：这是安装最新版本的NVM。您可以在NVM的GitHub页面<a href="https://github.com/nvm-sh/nvm">https://github.com/nvm-sh/nvm</a><br>上查看最新版本并使用相应的URL。</p>
<p>4). 安装完成后，关闭并重新打开终端，或者使用以下命令重新加载终端以使NVM生效：</p>
<p>source ~/.bashrc</p>
<p>5). 使用NVM安装想要的Node.js版本。例如，运行以下命令安装最新的稳定版本：</p>
<p>nvm install stable</p>
<p>或者，您可以指定其他Node.js版本，例如：</p>
<p>nvm install 14.17.6</p>
<p>nvm install 16.20.2</p>
<p>这将下载并安装指定版本的Node.js。</p>
<p>6). 检查Node.js的安装是否成功。运行以下命令检查Node.js版本：</p>
<p>[root@localhost /data/myblog]$npm -v<br>8.19.4<br>[root@localhost /data/myblog]$node -v<br>v16.20.2</p>
<p>[root@mytest2 tools]# node -v</p>
<p>node: /lib64/libm.so.6: version `GLIBC_2.27’ not found (required by node)</p>
<p>node: /lib64/libstdc++.so.6: version `GLIBCXX_3.4.20’ not found (required by node)</p>
<p>node: /lib64/libstdc++.so.6: version `CXXABI_1.3.9’ not found (required by node)</p>
<p>node: /lib64/libstdc++.so.6: version `GLIBCXX_3.4.21’ not found (required by node)</p>
<p>node: /lib64/libc.so.6: version `GLIBC_2.27’ not found (required by node)</p>
<p>node: /lib64/libc.so.6: version `GLIBC_2.28’ not found (required by node)</p>
<p>node: /lib64/libc.so.6: version `GLIBC_2.25’ not found (required by node)</p>
<p>[root@mytest2 tools]# npm -v</p>
<p>node: /lib64/libm.so.6: version `GLIBC_2.27’ not found (required by node)</p>
<p>node: /lib64/libstdc++.so.6: version `GLIBCXX_3.4.20’ not found (required by node)</p>
<p>node: /lib64/libstdc++.so.6: version `CXXABI_1.3.9’ not found (required by node)</p>
<p>node: /lib64/libstdc++.so.6: version `GLIBCXX_3.4.21’ not found (required by node)</p>
<p>node: /lib64/libc.so.6: version `GLIBC_2.27’ not found (required by node)</p>
<p>node: /lib64/libc.so.6: version `GLIBC_2.28’ not found (required by node)</p>
<p>node: /lib64/libc.so.6: version `GLIBC_2.25’ not found (required by node)</p>
<p>[root@mytest2 tools]# ldd –version</p>
<p>ldd (GNU libc) 2.17</p>
<p>版本太高换回nvm install 16.20.2</p>
<h2 id="2-git-repo仓库安装"><a href="#2-git-repo仓库安装" class="headerlink" title="2. git repo仓库安装"></a>2. git repo仓库安装</h2><p>github也可以注册账号，Github Pages可以直接生成页面，不过国外的网速实在是龟速，gitee也有这个功能，实名认证太麻烦，索性在自己测试机上直接建立git仓库，直接推送建立站点而已，后续国内服务器需要网站备案。</p>
<p>1).安装git<br>ubuntu/debian:<br>sudo apt-get install git</p>
<p>centos:<br>sudo yum install git</p>
<p>2).创建一个git用户，用来运行git服务：</p>
<p>$ sudo adduser git<br>3).创建证书登录实现git免密推送：</p>
<p>收集所有需要登录的用户的公钥id_rsa.pub文件，把所有公钥导入到/home/git/.ssh/authorized_keys文件里，一行一个。</p>
<p>4).初始化Git仓库：</p>
<p>先选定一个目录作为Git仓库，假定git是/data/blog/blog.git，工作目录：/data/myblog 在/data/blog目录下输入命令：</p>
<p>sudo git init  —bare blog.git<br>Git就会创建一个裸仓库，裸仓库没有工作区，因为服务器上的Git仓库纯粹是为了共享，所以不让用户直接登录到服务器上去改工作区，并且服务器上的Git仓库通常都以.git结尾。然后，把owner改为git：</p>
<p>$ sudo chown -R git:git blog.git</p>
<p>cd blog.git/hooks</p>
<p>vim post-receive</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/sh</span></span><br><span class="line">git --work-tree=/data/myblog --git-dir=/data/blog/blog.git checkout -f</span><br></pre></td></tr></tbody></table></figure>

<p>chmod +x post-receive</p>
<p>5).禁用shell登录：</p>
<p>出于安全考虑，第二步创建的git用户不允许登录shell，这可以通过编辑/etc/passwd文件完成。找到类似下面的一行：</p>
<p>gitx:1001:1001:,,,:/home/git:/bin/bash<br>改为：</p>
<p>gitx:1001:1001:,,,:/home/git:/usr/bin/git-shell<br>这样，git用户可以正常通过ssh使用git，但无法登录shell，因为我们为git用户指定的git-shell每次一登录就自动退出。</p>
<p>6).克隆远程仓库：</p>
<p>现在，可以通过git clone命令克隆远程仓库了，在各自的电脑上运行：</p>
<p>git clone ssh://git@ip:port/data/blog/blog.git<br>Cloning into ‘blog’…</p>
<p>几个问题：</p>
<p>a.git目录路径要看清楚，不在当前目录会报:does not appear to be a git repository<br>fatal: Could not read from remote repository.类似的错误 ；</p>
<p>git@ip:port/data/blog/blog.git</p>
<p>b. git ssh 连接 ： ssh://git@ip:port/data/blog/blog.git</p>
<h2 id="3-hexo安装及推送"><a href="#3-hexo安装及推送" class="headerlink" title="3. hexo安装及推送"></a>3. hexo安装及推送</h2><h3 id="3-1-hexo安装"><a href="#3-1-hexo安装" class="headerlink" title="3.1 hexo安装"></a>3.1 hexo安装</h3><p>npm install hexo-cli -g<br> hexo init blog<br> cd blog<br>npm install<br> hexo g # 或者hexo generate<br> hexo s # 或者hexo server，可以在<a href="http://localhost:4000/">http://localhost:4000/</a> 查看</p>
<p>也可以hexo server -p 80 -l</p>
<p>hexo generate (hexo g) 生成静态文件，会在当前目录下生成一个新的叫做public的文件夹</p>
<p>hexo server (hexo s) 启动本地web服务，用于博客的预览</p>
<p>hexo deploy (hexo d) 部署播客到远端（比如github, heroku等平台）</p>
<p>hexo new “postName” #新建文章<br> hexo new page “pageName” #新建页面</p>
<p>简写：</p>
<p>hexo n == hexo new<br>hexo g == hexo generate<br>hexo s == hexo server<br>hexo d == hexo deploy</p>
<p>hexo d -g #生成部署<br>hexo s -g #生成预览</p>
<p>经常用到：</p>
<p>hexo clean</p>
<p>hexo g</p>
<p>hexo d</p>
<h3 id="3-2使用hexo-deploy部署"><a href="#3-2使用hexo-deploy部署" class="headerlink" title="3.2使用hexo deploy部署"></a>3.2使用hexo deploy部署</h3><p>安装一个扩展：</p>
<p>$ npm install hexo-deployer-git –save</p>
<p>hexo deploy可以部署到很多平台，具体可以参考这个链接. 如果部署到github，需要在根目录/data/blog/配置文件_config.xml中作如下修改：</p>
<p>deploy:<br>  type: git<br>repo: ssh://git@ip:port/data/blog/blog.git<br>  branch: master<br>然后在命令行中执行</p>
<p>hexo d<br>即可完成部署。</p>
<p>hexo主题很多选择一个喜欢的去修改吧</p>
<p>比如：</p>
<p>git clone <a href="https://github.com/next-theme/hexo-theme-next">https://github.com/next-theme/hexo-theme-next</a> themes/next</p>
<p>下载到themes 的next 主题，或者matery大佬的主题，下载以后自己修改成自己喜欢的样式即可。</p>
<h2 id="4-web站点搭建"><a href="#4-web站点搭建" class="headerlink" title="4. web站点搭建"></a>4. web站点搭建</h2><p>首先有一台自己的服务器，比如centos或者ubuntu，debian，安装nginx或者tengine，对于个人静态站点基本上nginx可以满足，tengine需要手动安装，喜欢的可以尝试一下。</p>
<p>简单的yum install nginx</p>
<p>cd /etc/nginx/</p>
<p>vim nginx.conf</p>
<p>server_tokens off; 隐藏版本号；</p>
<p>也可以做好多优化；这里只说实现web功能</p>
<p>nginx一般在/etc/nginx/conf.d/ 配置站点conf文件，tengine在/etc/nginx/sites-enabled/配置，看个人喜好。</p>
<p>vim mybog.conf 基本配置如下：</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">server {</span><br><span class="line">    listen 80;</span><br><span class="line">    server_name blog.icmpy.net;</span><br><span class="line">    return 301 blog.icmpy.net$request_uri;</span><br><span class="line">}</span><br><span class="line">server {</span><br><span class="line">    listen 443 ssl;</span><br><span class="line">    server_name blog.icmpy.net;</span><br><span class="line">    root /data/myblog; # 根目录为web</span><br><span class="line">    index index.php index index.html index.htm;</span><br><span class="line">    ssl_certificate /etc/nginx/ssl/blog.icmpy.net.pem;</span><br><span class="line">    ssl_certificate_key /etc/nginx/ssl/blog.icmpy.net.key;</span><br><span class="line">   ssl_session_timeout  5m;</span><br><span class="line"></span><br><span class="line">    ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4;</span><br><span class="line">        ssl_prefer_server_ciphers  on;</span><br><span class="line">    # Log files for Debug</span><br><span class="line">    error_log  /var/log/nginx/blog_error.log;</span><br><span class="line">    access_log /var/log/nginx/blog_access.log;</span><br><span class="line"></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>

<p>由于做了ssl证书，80做了个跳转到443上面，域名需要到平台做解析，A记录到自己的服务器，如果流量大的话可以做cdn，Cname到平台给的记录值，ssl证书申请，主流云平台都可以免费申请，填写一些资料以后很快就可以签发证书，选择对应的证书上传即可。</p>
]]></content>
  </entry>
  <entry>
    <title>kafka Create topic 报错</title>
    <url>/2023/071361284.html</url>
    <content><![CDATA[<p>bin/kafka-console-consumer.sh –bootstrap-server localhost:9092 –topic kk_log<br>报错如下：<br>WARN [Consumer clientId=consumer-1, groupId=console-consumer-507] Connection to node -1 could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)</p>
<p>配置server.confg时候设置的<br>advertised.listeners=PLAINTEXT://10.171.222.26:9092<br>此时需要用配置的IP而非localhost地址：</p>
<p>nohup bin/zookeeper-server-start.sh config/zookeeper.properties &gt; /dev/null 2&gt;&amp;1 &amp;<br>nohup bin/kafka-server-start.sh config/server.properties &gt; /dev/null 2&gt;&amp;1 &amp;<br>netstat -ntpl|egrep “(2181|9092)”<br>运行起来再试试<br>bin/kafka-console-consumer.sh –bootstrap-server 10.171.222.26:9092 –topic kk_log<br>应该就可以了。<br>做个小笔记。</p>
<p>PS zookeeper 报错，宕掉；</p>
<p>[2016-06-27 12:07:14,065] INFO Closed socket connection for client /127.0.0.1:58824 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn) [2016-<br>[2016-06-27 12:07:17,351] INFO Refusing session request for client /127.0.0.1:58834 as it has seen zxid 0xd820 our last zxid is 0x20 client must try another server (org.apache.zookeeper.server.ZooKeeperServer)<br>[2016-06-27 12:07:17,351] INFO Closed socket connection for client /127.0.0.1:58834 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)<br>[2016-06-27 12:07:19,048] INFO Accepted socket connection from /127.0.0.1:58840 (org.apache.zookeeper.server.NIOServerCnxnFactory)<br>[2016-06-27 12:07:19,048] INFO Refusing session request for client /127.0.0.1:58840 as it has seen zxid 0xd820 our last zxid is 0x20 client must try another server (org.apache.zookeeper.server.ZooKeeperServer)</p>
<p>解决方法</p>
<p>报错原因：服务器上还有应用在不停的向zookeeper发送请求</p>
<p>解决方法：<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 用top -u [username]查看该用户下的所有进程，发现多了一个java进程在运行着；<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1、kill掉与java相关的进程；</p>
<p>2、关闭zookeeper，删除zoo.cfg中的dataDir配置的文件夹；</p>
<h2 id="3、重启zookeeper。"><a href="#3、重启zookeeper。" class="headerlink" title="3、重启zookeeper。"></a>3、重启zookeeper。</h2>]]></content>
  </entry>
  <entry>
    <title>linux install shadowsocks</title>
    <url>/2023/071659235.html</url>
    <content><![CDATA[<h1 id="1-安装Python和pip"><a href="#1-安装Python和pip" class="headerlink" title="1. 安装Python和pip"></a>1. 安装Python和pip</h1><p>sudo apt-get update</p>
<p>sudo apt-get install python-pip</p>
<h1 id="2-安装Shadowsocks"><a href="#2-安装Shadowsocks" class="headerlink" title="2. 安装Shadowsocks"></a>2. 安装Shadowsocks</h1><p>sudo pip install shadowsocks</p>
<h1 id="3-配置Shadowsocks"><a href="#3-配置Shadowsocks" class="headerlink" title="3. 配置Shadowsocks"></a>3. 配置Shadowsocks</h1><p>cat &gt;&gt; /etc/shadowsocks.json &lt;&lt;EOF<br>{</p>
<p>“server” : “ server ip”,<br>“server_port” : server port,<br>“local_port” : 1080,<br>“password” : “passwd”,<br>“timeout” : 200,<br>“method” : “aes-256-cfb”<br>}<br>EOF<br>参数的解释:<br>server：远程服务器IP地址<br>server_port：远程服务器端口号<br>local_port：本地端口号，默认为1080<br>password：远程服务器密码，自定义<br>timeout：超时时间，默认为300秒<br>method：加密方式，推荐aes-256-cfb</p>
<h1 id="4-启动Shadowsocks"><a href="#4-启动Shadowsocks" class="headerlink" title="4. 启动Shadowsocks"></a>4. 启动Shadowsocks</h1><p>在命令行中输入：</p>
<p>ssserver -c /etc/shadowsocks.json</p>
<h1 id="5-添加系统服务"><a href="#5-添加系统服务" class="headerlink" title="5.添加系统服务"></a>5.添加系统服务</h1><p>cat &gt;&gt;/etc/systemd/system/shadows.service  &lt;&lt;EOF<br>[Unit]<br>Description=shadows server<br>[Install]<br>WantedBy=multi-user.target<br>[Service]<br>User=root<br>Group=root<br>ExecStart=/usr/bin/ssserver -c /etc/shadowsocks.json start<br>Restart=on-failure<br>EOF</p>
<p>systemctl restart shadows.service<br>systemctl enable shadows.service</p>
]]></content>
      <categories>
        <category>系统</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title>linux有足够内存还使用swap</title>
    <url>/2023/11131515.html</url>
    <content><![CDATA[<p>一台主机内存swap报警上去以查看确实swap快耗尽；</p>
<p>$free -m</p>
<p>&nbsp; total&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; used&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; free&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; shared&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;buff/cache&nbsp;&nbsp; available</p>
<p>Mem: 32012&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 8293&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 243&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 594&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 23475&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 22638</p>
<p>Swap:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 7999&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 7315&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 684</p>
<p>Linux starts swapping before the RAM is filled up. This is done to improve performance and responsiveness:</p>
<p>Performance is increased because sometimes RAM is better used for disk cache than to store program memory. So it’s better to swap out a program that’s been inactive for a while, and instead keep often-used files in cache.</p>
<p>Responsiveness is improved by swapping pages out when the system is idle, rather than when the memory is full and some program is running and requesting more RAM to complete a task.</p>
<p>Swapping does slow the system down, of course — but the alternative to swapping isn’t not swapping, it’s having more RAM or using less RAM.</p>
<p>翻译：Linux在物理内存用完之前使用swap，这样有助于提高系统性能和响应能力</p>
<p>1 性能可以提升的原因是：一些内存放磁盘缓存比方内存更合适。所以，最好交换出暂时不使用的内存，而把经常使用的文件放内存里面</p>
<p>2 提升响应能力通过，当系统空闲的时候swap page out，而不是当内存忙的时候，正在执行程序的时候执行swap</p>
<p>swaping确实会是系统性能下降，当然，通过swap可以有更多的可用内存</p>
<p>如何在有内存可用的时候，不使用swap呢？</p>
<p>This behaviour can be configured by setting the value of&nbsp;/proc/sys/vm/swappiness. The default value is 60, setting it to 0 means “never use swap when there is still RAM left“ and 100 is swapping out memory as soon as possible.</p>
<p>To change the value temporarily (lost on reboot):</p>
<p>sudo sysctl vm.swappiness=10<br>1.<br>To change the value permanently: Edit the file&nbsp;/etc/sysctl.conf&nbsp;as root (e.g.&nbsp;sudo nano /etc/sysctl.conf) and change the line&nbsp;vm.swapiness=…&nbsp;to the desired value.</p>
<p>There has been some debate on whether swapping out with free memory available is good or bad, but the Ubuntu help does indeed recommend a value of 10 for Desktop systems:&nbsp;<a href="https://help.ubuntu.com/community/SwapFaq">https://help.ubuntu.com/community/SwapFaq</a></p>
<p>centos swappiness配置的路径 &nbsp;/proc/sys/vm/swappiness</p>
<p>为什么不建议关闭swap</p>
<p>It is NOT recommended to turn off swap even if you have enough memory. If your server needs more memory and it did not get it, it will crash. However, this can be prevented (to some extent) when you have a swap area.</p>
<p>Yes, your server performance will degrade when using swap, but at least it will be operational and accessible. Then, you can plan for adding more memory when needed if your server starts using swap.</p>
<p>I found&nbsp;&nbsp;this page&nbsp;talking about swap. Have a look at 3rd section.</p>
<p>Instead of turning off swap, you can control the&nbsp;&nbsp;swapiness.</p>
<p>参考</p>
<p><a href="http://unix.stackexchange.com/questions/2658/why-use-swap-when-there-is-more-than-enough-ram">http://unix.stackexchange.com/questions/2658/why-use-swap-when-there-is-more-than-enough-ram</a></p>
<p>swap知识 &nbsp;<a href="https://help.ubuntu.com/community/SwapFaq">https://help.ubuntu.com/community/SwapFaq</a></p>
<p><a href="http://linux.cloudibee.com/2007/11/linux-performance-tuning-vm-swappiness/">http://linux.cloudibee.com/2007/11/linux-performance-tuning-vm-swappiness/</a></p>
<p>转载自:&nbsp;<a href="https://blog.csdn.net/wjciayf/article/details/79913381">https://blog.csdn.net/wjciayf/article/details/79913381</a></p>
<p>关于linux内存分配机制</p>
<p>在linux的内存分配机制中，优先使用物理内存，当物理内存还有空闲时（还够用），不会释放其占用内存，就算占用内存的程序已经被关闭了，该程序所占用的内存用来做缓存使用，对于开启过的程序、或是读取刚存取过得数据会比较快。</p>
<p>一．&nbsp;&nbsp;我们先来查看一个内存使用的例子：<br>[oracle@db1 ~]$ free -m<br>&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp; &nbsp; total&nbsp; &nbsp;&nbsp; &nbsp; used&nbsp; &nbsp;&nbsp;&nbsp; free&nbsp; &nbsp;&nbsp;&nbsp;shared&nbsp; &nbsp; buffers&nbsp;&nbsp;&nbsp;&nbsp;cached<br>Mem:&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;72433&nbsp; &nbsp;&nbsp;&nbsp;67075&nbsp; &nbsp;&nbsp;&nbsp;5357&nbsp; &nbsp;&nbsp; &nbsp;0&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;558&nbsp; &nbsp;&nbsp; &nbsp; 62221<br>-/+ buffers/cache:&nbsp;&nbsp;&nbsp;&nbsp;4295&nbsp; &nbsp;&nbsp; &nbsp;68138<br>Swap:&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;72096&nbsp; &nbsp;&nbsp; &nbsp;91&nbsp; &nbsp;&nbsp; &nbsp;72004<br>上述结果显示了67075M的used，但是（-/+ buffers/cache）减去buffers和cache的结果可以看到，所以当前进程实际占用内存是4296M。<br>可以这么理解：在linux的内存分配机制中，优先使用物理内存，当物理内存还有空闲时（还够用），不会释放其占用内存，就算占用内存的程序已经被关闭了，该程序所占用的内存用来做缓存使用，对于开启过的程序、或是读取刚存取过得数据会比较快。<br>如上面的例子：使用了72433M的内存，67075M被占用，但是buuffer和cached部分作为缓存，可以使用命中率的方式提高使用效率，而且这部分缓存是根据指令随时可以释放的，我们可以认为这部分内存没有实际被使用，也可以认为它是空闲的。<br>因此查看目前进程正在实际被使用的内存，是used-(buffers+cache)，也可以认为如果swap没有大量使用，mem还是够用的，只有mem被当前进程实际占用完（没有了buffers和cache），才会使用到swap的。</p>
<p>二．&nbsp;Swap配置对性能的影响<br>分配太多的Swap空间会浪费磁盘空间，而Swap空间太少，则系统会发生错误。如果系统的物理内存用光了，系统就会跑得很慢，但仍能运行；如果Swap空间用光了，那么系统就会发生错误。例如，Web服务器能根据不同的请求数量衍生出多个服务进程（或线程），如果Swap空间用完，则服务进程无法启动，通常会出现“application is out of memory”的错误，严重时会造成服务进程的死锁。因此Swap空间的分配是很重要的。<br>通常情况下，Swap空间应大于或等于物理内存的大小，最小不应小于64M，通常Swap空间的大小应是物理内存的2-2.5倍。但根据不同的应用，应有不同的配置：如果是小的桌面系统，则只需要较小的Swap空间，而大的服务器系统则视情况不同需要不同大小的Swap空间。特别是数据库服务器和Web服务器，随着访问量的增加，对Swap空间的要求也会增加，一般来说对于4G&nbsp;以下的物理内存，配置2倍的swap，4G&nbsp;以上配置1倍。<br>另外，Swap分区的数量对性能也有很大的影响。因为Swap交换的操作是磁盘IO的操作，如果有多个Swap交换区，Swap空间的分配会以轮流的方式操作于所有的Swap，这样会大大均衡IO的负载，加快Swap交换的速度。如果只有一个交换区，所有的交换操作会使交换区变得很忙，使系统大多数时间处于等待状态，效率很低。用性能监视工具就会发现，此时的CPU并不很忙，而系统却慢。这说明，瓶颈在IO上，依靠提高CPU的速度是解决不了问题的。</p>
<p>三.&nbsp;&nbsp;Linux&nbsp;内存机制<br>Linux支持虚拟内存(VirtualMmemory)，虚拟内存是指使用磁盘当作RAM的扩展，这样可用的内存的大小就相应地增大了。内核会将暂时不用的内存块的内容写到硬盘上，这样一来，这块内存就可用于其它目的。当需要用到原始的内容时，它们被重新读入内存。这些操作对用户来说是完全透明的;Linux下运行的程序只是看到有大量的内存可供使用而并没有注意到时不时它们的一部分是驻留在硬盘上的。当然，读写硬盘要比直接使用真实内存慢得多(要慢数千倍)，所以程序就不会象一直在内存中运行的那样快。用作虚拟内存的硬盘部分被称为交换空间(Swap Space)。<br>一般，在交换空间中的页面首先被换入内存;如果此时没有足够的物理内存来容纳它们又将被交换出来(到其他的交换空间中)。如果没有足够的虚拟内存来容纳所有这些页面，Linux就会波动而不正常;但经过一段较长的时间Linux会恢复，但此时系统已不可用了。<br>有时，尽管有许多的空闲内存，仍然会有许多的交换空间正被使用。这种情况是有可能发生的，例如如果在某一时刻有进行交换的必要，但后来一个占用很多物理内存的大进程结束并释放内存时。被交换出的数据并不会自动地交换进内存，除非有这个需要时。此时物理内存会在一段时间内保持空闲状态。对此并没有什么可担心的，但是知道了是怎么一回事，也就无所谓了。<br>许多操作系统使用了虚拟内存的方法。因为它们仅在运行时才需要交换空间，以解决不会在同一时间使用交换空间，因此，除了当前正在运行的操作系统的交换空间，其它的就是一种浪费。所以让它们共享一个交换空间将会更有效率。<br>注意：如果会有几个人同时使用这个系统，他们都将消耗内存。然而，如果两个人同时运行一个程序，内存消耗的总量并不是翻倍，因为代码页以及共享的库只存在一份。</p>
<p>Linux系统常常动不动就使用交换空间，以保持尽可能多的空闲物理内存。即使并没有什么事情需要内存，Linux也会交换出暂时不用的内存页面。这可以避免等待交换所需的时间：当磁盘闲着，就可以提前做好交换。可以将交换空间分散在几个硬盘之上。针对相关磁盘的速度以及对磁盘的访问模式，这样做可以提高性能。</p>
<p>与访问物理内存相比，磁盘的读写是很慢的。另外，在相应较短的时间内多次读磁盘同样的部分也是常有的事。例如，某人也许首先阅读了一段E-mail消息，然后为了答复又将这段消息读入编辑器中，然后又在将这个消息拷贝到文件夹中时，使得邮件程序又一次读入它。或者考虑一下在一个有着许多用户的系统中&nbsp;ls命令会被使用多少次。通过将信息从磁盘上仅读入一次并将其存于内存中，除了第一次读以外，可以加快所有其它读的速度。这叫作磁盘缓冲(Disk Buffering)，被用作此目的的内存称为高速缓冲(Buffer Cache)。但是，由于内存是一种有限而又不充足的资源，高速缓冲不可能做的很大(它不可能包容要用到的所有数据)。当缓冲充满了数据时，其中最长时间不用的数据将被舍弃以腾出内存空间用于新的数据。</p>
<p>对写磁盘操作来说磁盘缓冲技术同样有效。一方面，被写入磁盘的数据常常会很快地又被读出(例如，原代码文件被保存到一个文件中，又被编译器读入)，所以将要被写的数据放入缓冲中是个好主意。另一方面，通过将数据放入缓冲中，而不是将其立刻写入磁盘，程序可以加快运行的速度。以后，写的操作可以在后台完成，而不会拖延程序的执行。<br>大多数操作系统都有高速缓冲(尽管可能称呼不同)，但是并不是都遵守上面的原理。有些是直接写(Write-Through)：数据将被立刻写入磁盘(当然，数据也被放入缓存中)。如果写操作是在以后做的，那么该缓存被称为后台写(Write-Back)。后台写比直接写更有效，但也容易出错：如果机器崩溃，或者突然掉电，缓冲中改变过的数据就被丢失了。如果仍未被写入的数据含有重要的薄记信息，这甚至可能意味着文件系统(如果有的话)已不完整。<br>针对以上的原因，出现了很多的日志文件系统，数据在缓冲区修改后，同时会被文件系统记录修改信息，这样即使此时系统掉电，系统重启后会首先从日志记录中恢复数据，保证数据不丢失。当然这些问题不再本文的叙述范围。<br>由于上述原因，在使用适当的关闭过程之前，绝对不要关掉电源，Sync命令倾空(Flushes)缓冲，也即，强迫所有未被写的数据写入磁盘，可用以确定所有的写操作都已完成。在传统的UNIX系统中，有一个叫做update的程序运行于后台，每隔30秒做一次sync操作，因此通常无需手工使用sync命令了。Linux另外有一个后台程序，Bdflush，这个程序执行更频繁的但不是全面的同步操作，以避免有时sync的大量磁盘I/O操作所带来的磁盘的突然冻结。<br>在Linux中，Bdflush是由update启动的。通常没有理由来担心此事，但如果由于某些原因bdflush进程死掉了，内核会对此作出警告，此时你就要手工地启动它了(/sbin/update)。</p>
<p>缓存(Cache)实际并不是缓冲文件的，而是缓冲块的，块是磁盘I/O操作的最小单元(在Linux中，它们通常是1KB)。这样，目录、超级块、其它文件系统的薄记数据以及非文件系统的磁盘数据都可以被缓冲了。缓冲的效力主要是由它的大小决定的。缓冲太小的话等于没用。它只能容纳一点数据，因此在被重用时，所有缓冲的数据都将被倾空。实际的大小依赖于数据读写的频次、相同数据被访问的频率。只有用实验的方法才能知道。<br>如果缓存有固定的大小，那么缓存太大了也不好，因为这会使得空闲的内存太小而导致进行交换操作(这同样是慢的)。为了最有效地使用实际内存，Linux自动地使用所有空闲的内存作为高速缓冲，当程序需要更多的内存时，它也会自动地减小缓冲的大小。&nbsp;<br>这就是一般情况下Linux内存的一般机制，真正的Linux内存的运行机制远远比这个复杂。</p>
<p>&nbsp;</p>
<p>Other：</p>
<p>swap tendency = mapped ratio / 2 + distress + swappiness</p>
<p>The mapped ratio value is the percentage of pages in all memory zones thatbelong to User Mode address spaces (sc-&gt;nr_mapped) with respect to the totalnumber of allocatable page frames. A high value of mapped_ratio means that thedynamic memory is mostly used by User Mode processes, while a low value meansthat it is mostly used by the page cache.</p>
<p>The distress value is a measure of how effectively the PFRA is reclaiming pageframes in this zone; it is based on the scanning priority of the zone in theprevious run of the PFRA, which is stored in the prev_priority field of thezone descriptor. The distress value depends on the zone’s previous priority asfollows:</p>
<p>Zone prev. priority<br>12…7<br>6<br>5<br>4<br>3<br>2<br>1<br>0</p>
<p>Distress value<br>0<br>1<br>3<br>6<br>12<br>25<br>50<br>100<br>Finally, the swappiness value is a user-defined constant, which is usually setto 60. The system administrator may tune this value by writing in the/proc/sys/vm/swappiness file or by issuing the proper sysctl( ) system call.</p>
<p>Pages will be reclaimed from the address spaces of processes only if the zone’sswap tendency is greater than or equal to 100. Thus, if the systemadministrator sets swappiness to 0, then the PFRA never reclaims pages in theUser Mode address spaces unless the zone’s previous priority is zero (anunlikely event); if the administrator sets swappiness to 100, then the PFRAreclaims pages in the User Mode address spaces at every invocation.<br>swappiness，吃参数是得到swap tendency的一个量，而swap tendency是linux内核进行内存进行回收的一个阀值和标量。</p>
<p><a href="https://blog.csdn.net/ly890700/article/details/73695750">https://blog.csdn.net/ly890700/article/details/73695750</a></p>
<p>首先是,kswapd进程来定期扫描系统资源,查看内存是否够用,由两个值影响pages_high和page_low,如果现在可使用的区间在page_high&lt;x&lt;page_low,就开始检查从文件系统读入的文件,有无被修改的内存页面,如果有就写入到磁盘,但是,如果内存页面被修改了,有可能不是从文件系统读入的,即找不到回写的位置,如malloc产生的anonymous内存数据就写入swap分区,这部分当进程在次被唤醒,获得了CPU运行时间,在从swap读入。</p>
<p>swappiness的值的大小对如何使用swap分区是有着很大的联系的。swappiness=0的时候表示最大限度使用物理内存，然后才是swap空间，swappiness＝100的时候表示积极的使用swap分区，并且把内存上的数据及时的搬运到swap空间里面。linux的基本默认设置为60，具体如下：</p>
<p>cat /proc/sys/vm/swappiness<br>#60</p>
<p>也就是说，你的内存在使用到100-60=40%的时候，就开始出现有交换分区的使用。大家知道，内存的速度会比磁盘快很多，这样子会加大系统IO，同时造的成大量页的换进换出，严重影响系统的性能，所以我们在操作系统层面，要尽可能使用内存，对该参数进行调整。</p>
<p>临时调整的方法如下，我们调成10：</p>
<p>sysctl vm.swappiness=10<br>#vm.swappiness=10</p>
<p>cat /proc/sys/vm/swappiness</p>
<p>#10</p>
<p>这只是临时调整的方法，重启后会回到默认设置的.</p>
<p>要想永久调整的话，需要在/etc/sysctl.conf修改，加上：</p>
<p>sudo vim /etc/sysctl.conf</p>
<p>加上</p>
<h1 id="Controls-the-maximum-number-of-shared-memory-segments-in-pages"><a href="#Controls-the-maximum-number-of-shared-memory-segments-in-pages" class="headerlink" title="Controls the maximum number of shared memory segments, in pages"></a>Controls the maximum number of shared memory segments, in pages</h1><p>kernel.shmall = 4294967296 #这一个可以不用设置</p>
<p>vm.swappiness = 10</p>
<p>&nbsp;生效</p>
<p>sudo sysctl -p</p>
<p>这样便完成修改设置！</p>
<p>&nbsp;</p>
<p>Ps在服务器内存充裕的情况下尽量用内存，swap缓存设置低一些，使用swap是必要的；</p>
<p>另外：swap可以扩充的，但是会不会影响线上业务，或者使用sysctl vm.swappiness=10命令时候会不会影响线上业务，一直纠结中。</p>
<p>&nbsp;</p>
<p>转自：<a href="https://www.cnblogs.com/EasonJim/p/7777904.html">https://www.cnblogs.com/EasonJim/p/7777904.html</a></p>
<p>&nbsp;</p>
<p>&nbsp;&nbsp;用文件增加swap：</p>
<p>dd if=/dev/zero of=/tmp/swapadd bs=1024 count=2048000&nbsp; &nbsp; ###添加一块2G的swap文件</p>
<p>mkswap /tmp/swapadd&nbsp; ####格式化文件</p>
<p>swapon /tmp/swapadd ###增加swap</p>
<p>free -m</p>
<p>echo “/tmp/swapadd swap swap defaults 0 0” &gt;&gt; /etc/fstab&nbsp; &nbsp; ###开机自动挂载swap分区</p>
<p>swapoff swapadd&nbsp; ###&nbsp;使用Swapoff命令收回Swap空间</p>
<p>rm swapadd&nbsp;&nbsp; &nbsp;###从文件系统中回收此文件</p>
<hr>
]]></content>
  </entry>
  <entry>
    <title>linux 磁盘挂载扩充格式化</title>
    <url>/2023/11105462.html</url>
    <content><![CDATA[<h1 id="linux服务器硬盘格式化挂载："><a href="#linux服务器硬盘格式化挂载：" class="headerlink" title="linux服务器硬盘格式化挂载："></a>linux服务器硬盘格式化挂载：</h1><p>请根据以下步骤对数据盘进行分区以及格式化，并挂载分区使数据盘可用。</p>
<h2 id="1-1-查看数据盘信息"><a href="#1-1-查看数据盘信息" class="headerlink" title="1.1 查看数据盘信息"></a>1.1 查看数据盘信息</h2><p>登录Linux云服务器后，可以使用“fdisk -l”命令查看数据盘相关信息。<br>使用“df -h”命令，无法看到未分区和格式化的数据盘。 </p>
<h2 id="1-2-数据盘分区"><a href="#1-2-数据盘分区" class="headerlink" title="1.2 数据盘分区"></a>1.2 数据盘分区</h2><p>执行以下命令，对数据盘进行分区。</p>
<p>fdisk /dev/xvdb</p>
<p>按照界面的提示，依次输入“n”(新建分区)、“p”(新建扩展分区)、“1”(使用第1个主分区)，两次回车(使用默认配置)，输入“wq”(保存分区表)，开始分区。<br>这里是以创建1个分区为例，开发者也可以根据自己的需求创建多个分区。</p>
<h2 id="1-3-查看新分区"><a href="#1-3-查看新分区" class="headerlink" title="1.3 查看新分区"></a>1.3 查看新分区</h2><p>使用“fdisk -l”命令，即可查看到，新的分区xvdb1已经创建完成。</p>
<h2 id="1-4-格式化新分区"><a href="#1-4-格式化新分区" class="headerlink" title="1.4 格式化新分区"></a>1.4 格式化新分区</h2><p>在进行分区格式化时，开发者可以自行决定文件系统的格式，如ext2、ext3等。<br>这里以“ext3”为例：<br>使用下面的命令对新分区进行格式化。 </p>
<p>mkfs.ext3 /dev/xvdb1</p>
<h2 id="1-5-挂载新分区"><a href="#1-5-挂载新分区" class="headerlink" title="1.5 挂载新分区"></a>1.5 挂载新分区</h2><p>使用命令“mkdir /mydata”创建mydata目录，再通过“mount /dev/xvdb1 /mydata”命令手动挂载新分区后，用“df -h”命令查看，出现以下信息说明挂载成功，即可以查看到数据盘了。</p>
<h2 id="1-6-添加分区信息"><a href="#1-6-添加分区信息" class="headerlink" title="1.6 添加分区信息"></a>1.6 添加分区信息</h2><p>如果希望云服务器在重启或开机时能自动挂载数据盘，必须将分区信息添加到/etc/fstab中。如果没有添加，则云服务器重启或开机后，都不能自动挂载数据盘。<br>使用“echo ‘/dev/xvdb1 /mydata ext3 defaults 0 0’ &gt;&gt; /etc/fstab”命令添加分区信息后，使用“cat /etc/fstab”命令查看，出现以下信息表示添加分区信息成功。</p>
<h1 id="2-腾讯云服务器硬盘扩充，新空间增加到已有分区空间中："><a href="#2-腾讯云服务器硬盘扩充，新空间增加到已有分区空间中：" class="headerlink" title="2.腾讯云服务器硬盘扩充，新空间增加到已有分区空间中："></a>2.腾讯云服务器硬盘扩充，新空间增加到已有分区空间中：</h1><p>  线上业务服务器1T硬盘，日志量太大，需要扩充到2T硬盘，关机购买硬盘以后启动开始在原有盘上面开始扩充：</p>
<h2 id="2-1-查看数据盘信息"><a href="#2-1-查看数据盘信息" class="headerlink" title="2.1 查看数据盘信息"></a>2.1 查看数据盘信息</h2><h2 id="root-VM-0-17-centos-fdisk-l"><a href="#root-VM-0-17-centos-fdisk-l" class="headerlink" title="[root@VM_0_17_centos ~]# fdisk -l"></a>[root@VM_0_17_centos ~]# fdisk -l</h2><p> Disk /dev/vda: 53.7 GB, 53687091200 bytes, 104857600 sectors</p>
<p>Units = sectors of 1 * 512 = 512 bytes</p>
<p>Sector size (logical/physical): 512 bytes / 512 bytes</p>
<p>I/O size (minimum/optimal): 512 bytes / 512 bytes</p>
<p>Disk label type: dos</p>
<p>Disk identifier: 0x000c7a75</p>
<p>   Device Boot      Start         End      Blocks   Id  System</p>
<p>/dev/vda1   *        2048   104857599    52427776   83  Linux</p>
<p>Disk /dev/vdb: 2147.5 GB, 2147483648000 bytes, 4194304000 sectors</p>
<p>Units = sectors of 1 * 512 = 512 bytes</p>
<p>Sector size (logical/physical): 512 bytes / 512 bytes</p>
<p>I/O size (minimum/optimal): 512 bytes / 512 bytes</p>
<p>Disk label type: dos</p>
<p>Disk identifier: 0x947d4eff</p>
<p>   Device Boot      Start         End      Blocks   Id  System</p>
<p>/dev/vdb1            2048  2097151999  1048574976   83  Linux</p>
<h2 id="2-2查看原来1T磁盘："><a href="#2-2查看原来1T磁盘：" class="headerlink" title="2.2查看原来1T磁盘："></a>2.2查看原来1T磁盘：</h2><p>df -h</p>
<p>Filesystem      Size  Used Avail Use% Mounted on</p>
<p>/dev/vda1        50G  4.1G   43G   9% /</p>
<p>devtmpfs         16G     0   16G   0% /dev</p>
<p>tmpfs            16G   24K   16G   1% /dev/shm</p>
<p>tmpfs            16G  300K   16G   1% /run</p>
<p>tmpfs            16G     0   16G   0% /sys/fs/cgroup</p>
<p>/dev/vdb1       985G  150G  785G  17% /data</p>
<p>tmpfs           3.2G     0  3.2G   0% /run/user/0</p>
<h2 id="2-3卸载原硬盘："><a href="#2-3卸载原硬盘：" class="headerlink" title="2.3卸载原硬盘："></a>2.3卸载原硬盘：</h2><p>umount /data/</p>
<p>[root@VM_0_17_centos ~]# df -h</p>
<p>Filesystem      Size  Used Avail Use% Mounted on</p>
<p>/dev/vda1        50G  4.1G   43G   9% /</p>
<p>devtmpfs         16G     0   16G   0% /dev</p>
<p>tmpfs            16G   24K   16G   1% /dev/shm</p>
<p>tmpfs            16G  300K   16G   1% /run</p>
<p>tmpfs            16G     0   16G   0% /sys/fs/cgroup</p>
<p>tmpfs           3.2G     0  3.2G   0% /run/user/0</p>
<h2 id="2-4确认卸载："><a href="#2-4确认卸载：" class="headerlink" title="2.4确认卸载："></a>2.4确认卸载：</h2><p>[root@VM_0_17_centos ~]# fdisk -l</p>
<p>Disk /dev/vda: 53.7 GB, 53687091200 bytes, 104857600 sectors</p>
<p>Units = sectors of 1 * 512 = 512 bytes</p>
<p>Sector size (logical/physical): 512 bytes / 512 bytes</p>
<p>I/O size (minimum/optimal): 512 bytes / 512 bytes</p>
<p>Disk label type: dos</p>
<p>Disk identifier: 0x000c7a75</p>
<p>   Device Boot      Start         End      Blocks   Id  System</p>
<p>/dev/vda1   *        2048   104857599    52427776   83  Linux</p>
<p>Disk /dev/vdb: 2147.5 GB, 2147483648000 bytes, 4194304000 sectors</p>
<p>Units = sectors of 1 * 512 = 512 bytes</p>
<p>Sector size (logical/physical): 512 bytes / 512 bytes</p>
<p>I/O size (minimum/optimal): 512 bytes / 512 bytes</p>
<p>Disk label type: dos</p>
<p>Disk identifier: 0x947d4eff</p>
<p>   Device Boot      Start         End      Blocks   Id  System</p>
<p>/dev/vdb1            2048  2097151999  1048574976   83  Linux</p>
<h2 id="2-5-开始格盘："><a href="#2-5-开始格盘：" class="headerlink" title="2.5 开始格盘："></a>2.5 开始格盘：</h2><p> 按照界面的提示，一次输入”p”(查看已有分区信息), ”d”(删除需要扩容的分区)、“n”(新建分区)、“p”(新建主分区)、“1”(使用第1个主分区，必须保持与需要扩容的分区一样)，两次回车(使用默认配置)，输入“w”(保存分区表)，开始分区。<br>这里是以创建1个分区为例，用户也可以根据自己的需求扩容多个分区。</p>
<p>[root@VM_0_17_centos ~]# fdisk  /dev/vdb</p>
<p>Welcome to fdisk (util-linux 2.23.2).</p>
<p>Changes will remain in memory only, until you decide to write them.</p>
<p>Be careful before using the write command.</p>
<p> Command (m for help): p</p>
<p>Disk /dev/vdb: 2147.5 GB, 2147483648000 bytes, 4194304000 sectors</p>
<p>Units = sectors of 1 * 512 = 512 bytes</p>
<p>Sector size (logical/physical): 512 bytes / 512 bytes</p>
<p>I/O size (minimum/optimal): 512 bytes / 512 bytes</p>
<p>Disk label type: dos</p>
<p>Disk identifier: 0x947d4eff</p>
<p>   Device Boot      Start         End      Blocks   Id  System</p>
<p>/dev/vdb1            2048  2097151999  1048574976   83  Linux</p>
<p>Command (m for help): d</p>
<p>Selected partition 1</p>
<p>Partition 1 is deleted</p>
<p>Command (m for help): n</p>
<p>Partition type:</p>
<p>   p   primary (0 primary, 0 extended, 4 free)</p>
<p>   e   extended</p>
<p>Select (default p): p</p>
<p>Partition number (1-4, default 1): 1</p>
<p>First sector (2048-4194303999, default 2048):</p>
<p>Using default value 2048</p>
<p>Last sector, +sectors or +size{K,M,G} (2048-4194303999, default 4194303999):</p>
<p>Using default value 4194303999</p>
<p>Partition 1 of type Linux and of size 2 TiB is set</p>
<p>Command (m for help): w</p>
<p>The partition table has been altered!</p>
<p>Calling ioctl() to re-read partition table.</p>
<p>Syncing disks.</p>
<p>[root@VM_0_17_centos ~]# fdisk -l</p>
<p>Disk /dev/vda: 53.7 GB, 53687091200 bytes, 104857600 sectors</p>
<p>Units = sectors of 1 * 512 = 512 bytes</p>
<p>Sector size (logical/physical): 512 bytes / 512 bytes</p>
<p>I/O size (minimum/optimal): 512 bytes / 512 bytes</p>
<p>Disk label type: dos</p>
<p>Disk identifier: 0x000c7a75</p>
<p>   Device Boot      Start         End      Blocks   Id  System</p>
<p>/dev/vda1   *        2048   104857599    52427776   83  Linux</p>
<p>Disk /dev/vdb: 2147.5 GB, 2147483648000 bytes, 4194304000 sectors</p>
<p>Units = sectors of 1 * 512 = 512 bytes</p>
<p>Sector size (logical/physical): 512 bytes / 512 bytes</p>
<p>I/O size (minimum/optimal): 512 bytes / 512 bytes</p>
<p>Disk label type: dos</p>
<p>Disk identifier: 0x947d4eff</p>
<pre><code>Device Boot      Start         End      Blocks   Id  System
</code></pre>
<p>/dev/vdb1            2048  4194303999  2097150976   83  Linux</p>
<h2 id="2-6确认磁盘"><a href="#2-6确认磁盘" class="headerlink" title="2.6确认磁盘"></a>2.6确认磁盘</h2><p>使用“fdisk –l /dev/vdb1”命令，即可查看到，新的分区vdb1已经创建并扩容完成：</p>
<p>[root@VM_0_17_centos ~]# fdisk -l /dev/vdb1</p>
<p> Disk /dev/vdb1: 2147.5 GB, 2147482599424 bytes, 4194301952 sectors</p>
<p>Units = sectors of 1 * 512 = 512 bytes</p>
<p>Sector size (logical/physical): 512 bytes / 512 bytes</p>
<p>I/O size (minimum/optimal): 512 bytes / 512 bytes</p>
<h2 id="2-7-再使用e2fsck-f-dev-xvdc1检查扩容的分区是否ok"><a href="#2-7-再使用e2fsck-f-dev-xvdc1检查扩容的分区是否ok" class="headerlink" title="2.7 再使用e2fsck -f /dev/xvdc1检查扩容的分区是否ok"></a>2.7 再使用e2fsck -f /dev/xvdc1检查扩容的分区是否ok</h2><p>[root@VM_0_17_centos /]# e2fsck -f /dev/vd</p>
<p>vda   vda1  vdb   vdb1 </p>
<p>[root@VM_0_17_centos /]# e2fsck -f /dev/vdb1</p>
<p>e2fsck 1.42.9 (28-Dec-2013)</p>
<p>/dev/vdb1 is mounted.</p>
<p>e2fsck: Cannot continue, aborting.</p>
<p>似乎看到一个报错，不过后面查看扩充成功了，是不是成功了半信半疑的。。</p>
<h2 id="2-8-使用resize2fs-dev-xvdc1命令扩容分区："><a href="#2-8-使用resize2fs-dev-xvdc1命令扩容分区：" class="headerlink" title="2.8 使用resize2fs /dev/xvdc1命令扩容分区："></a>2.8 使用resize2fs /dev/xvdc1命令扩容分区：</h2><p>resize2fs /dev/vdb</p>
<p>vdb   vdb1 </p>
<p>[root@VM_0_17_centos /]# resize2fs /dev/vdb1</p>
<p>resize2fs 1.42.9 (28-Dec-2013)</p>
<p>Filesystem at /dev/vdb1 is mounted on /data; on-line resizing required</p>
<p>old_desc_blocks = 125, new_desc_blocks = 250</p>
<p>The filesystem on /dev/vdb1 is now 524287744 blocks long.</p>
<p>df -h</p>
<p>Filesystem      Size  Used Avail Use% Mounted on</p>
<p>/dev/vda1        50G  4.1G   43G   9% /</p>
<p>devtmpfs         16G     0   16G   0% /dev</p>
<p>tmpfs            16G   24K   16G   1% /dev/shm</p>
<p>tmpfs            16G  300K   16G   1% /run</p>
<p>tmpfs            16G     0   16G   0% /sys/fs/cgroup</p>
<p>/dev/vdb1       2.0T  150G  1.7T   8% /data</p>
<p>tmpfs           3.2G     0  3.2G   0% /run/user/0</p>
<h2 id="2-9-挂载-data盘，写入-etc-fstab"><a href="#2-9-挂载-data盘，写入-etc-fstab" class="headerlink" title="2.9  挂载/data盘，写入/etc/fstab"></a>2.9  挂载/data盘，写入/etc/fstab</h2><p> 不过做扩充时候是自动写进去的，重启过正常，数据没丢。。</p>
<p>cat /etc/fstab</p>
<p>/dev/vda1            /                    ext3       noatime,acl,user_xattr 1 1</p>
<p>proc                 /proc                proc       defaults              0 0</p>
<p>sysfs                /sys                 sysfs      noauto                0 0</p>
<p>debugfs              /sys/kernel/debug    debugfs    noauto                0 0</p>
<p>devpts               /dev/pts             devpts     mode=0620,gid=5       0 0</p>
<p>/dev/disk/bd/virtio-diskt1            /data                    ext4       defaults,nofail 0 1</p>
]]></content>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title>/var/log/messages日志恢复</title>
    <url>/2023/112018778.html</url>
    <content><![CDATA[<p>Linux容易犯的一个错误是把日志文件给直接删除，而不是删除日志文件的内容。<br>直接删除日志文件往往导致新产生的日志记录无法被写入到日志文件中（因为它已经被删除了），而仅仅重新新建（touch）同样名字的文件是解决不了问题的。<br>本文以Unbutu系统为例，介绍如何恢复被误删除的syslog文件：<br>首先，在以root用户执行如下lsof命令，查询打开/var/log/messages文件的进程的进程ID(PID)。<br>root@zck:/var/log# lsof | grep messages<br>rsyslogd 544 syslog 7w REG 8,1 214641 134422 /var/log/messages<br>从上面命令输出可以看到，这个打开/var/log/messages文件的进程的PID是544，文件/var/log/messages的文件描述符（FD）号是7。<br>根据上述的PID和FD，可以在/proc找到对应的文件：<br>root@zck:/var/log#ls -al /proc/544/fd/7<br>l-wx—— 1 root root 64 2012-07-14 14:48 7 -&gt; /var/log/messages<br>将文件/proc/544/fd/7拷贝到/var/log/messages<br>cp /proc/544/fd/7 /var/log/messages&nbsp;</p>
<p>然后重新启动syslog服务即可恢复被误删除的日志文件，并且新的日志记录能够继续被写入日志文件。<br>以root用户运行service命令。其中，service命令的第2个参数可能是syslog、也可能是rsyslog。<br>具体可以使用通过命令查询得知。<br>登录后复制<br>root@zck:/proc/544/fd# service –status-all<br> [ ? ] …<br> [ ? ] rc.local<br> [ ? ] rsyslog<br> [ ? ] screen-cleanup<br> [ ? ] …  #——————————-</p>
<p>复制代码代码如下:<br>root@zck:/proc/544/fd# service rsyslog restart<br>rsyslog start/running, process 2673</p>
<p>清空日志文件：<br>cat /dev/null&gt;/var/log/messages</p>
<p>转自url:<a href="https://blog.51cto.com/u_11146845/6240737">https://blog.51cto.com/u_11146845/6240737</a></p>
]]></content>
      <tags>
        <tag>点滴</tag>
      </tags>
  </entry>
  <entry>
    <title>nginxlog切分</title>
    <url>/2023/111760549.html</url>
    <content><![CDATA[<p>1.设置日志文件存放目录，假设你的nginx的日志存在这个目录里<br>logs_path=”/data/log/nginx/“</p>
<p>2.设置pid文件，这个根据你自己的环境，找到nginx.pid所在目录<br>pid_path=”/var/run/nginx.pid”</p>
<p>3.创建分割存储的日期文件目录<br>datetime=<code>date -d "yesterday" +"%Y%m%d"</code>;<br>new_log_path=$logs_path$datetime<br>mkdir -p $new_log_path</p>
<p>4.按照日期移动所有该目录下的日志文件<br>log_file_list=<code>ls -l $logs_path</code>;<br>for log_file in $log_file_list;<br>do<br>    log_file_name=$logs_path$log_file;<br>    if [ -f $log_file_name ];<br>    then<br>        mv $log_file_name $new_log_path;<br>    fi<br>done</p>
<p>5.向nginx主进程发信号重新打开日志<br>kill -USR1 <code>cat ${pid_path}</code></p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line">logs_path=<span class="string">"/data/log/nginx/"</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">pid_path=<span class="string">"/var/run/nginx.pid"</span></span><br><span class="line"></span><br><span class="line">datetime=`<span class="built_in">date</span> -d <span class="string">"yesterday"</span> +<span class="string">"%Y%m%d"</span>`;</span><br><span class="line">new_log_path=$logs_path<span class="variable">$datetime</span></span><br><span class="line"><span class="built_in">mkdir</span> -p <span class="variable">$new_log_path</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">log_file_list=`<span class="built_in">ls</span> -l <span class="variable">$logs_path</span>`;</span><br><span class="line"><span class="keyword">for</span> log_file <span class="keyword">in</span> <span class="variable">$log_file_list</span>;</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">    log_file_name=$logs_path<span class="variable">$log_file</span>;</span><br><span class="line">    <span class="keyword">if</span> [ -f <span class="variable">$log_file_name</span> ];</span><br><span class="line">    <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">mv</span> <span class="variable">$log_file_name</span> <span class="variable">$new_log_path</span>;</span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"><span class="built_in">kill</span> -USR1 `<span class="built_in">cat</span> <span class="variable">${pid_path}</span>`</span><br></pre></td></tr></tbody></table></figure>


]]></content>
      <categories>
        <category>系统</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title>nginx编译ssl模块</title>
    <url>/2023/062858442.html</url>
    <content><![CDATA[<p>几个官网在一台服务器上面，其中一台是https的，增加一个官网以，重启nginx以后，https的网站直接报错，大意是ssl 在配置文件中unknow，但是这个https网站已经运行很久了，一时间有点郁闷，掉坑里了。</p>
<p>查看nginx信息 /usr/local/nginx/sbin/nginx -V显示不支持ssl，那就好办，重新编译下ssl，但是线上业务跑着，难免有点担心，在测试机上跑了一次，正常的，才敢到线上操作，大致如此从网上找的如下：</p>
<p>进入nginx源码目录：</p>
<p>cd &nbsp;nginx-1.6.2</p>
<p>./configure –prefix=/usr/local/nginx –user=www –group=www &nbsp;–with-http_stub_status_module –with-http_ssl_module –with-file-aio –with-http_realip_module</p>
<p>只添加ssl功能模块，有别的需求继续加上；</p>
<p>运行完以后记得是make，make，make不是make &amp; make install ，install就覆盖安装了，千万搞清楚~</p>
<p>make以后在当前目录生成odjs目录，下面就是新的nginx；</p>
<p>剩下就好办，备份原来的nginx，把新生成的nginx替换原来的，</p>
<p>备份旧的nginx程序</p>
<p>cp /usr/local/nginx/sbin/nginx/usr/local/nginx/sbin/nginx.bak</p>
<p>把新的nginx程序覆盖旧的</p>
<p>cp objs/nginx /usr/local/nginx/sbin/nginx</p>
<p>测试新的nginx程序是否正确</p>
<p>/usr/local/nginx/sbin/nginx -t</p>
<p>nginx: theconfiguration file /usr/local/nginx/conf/nginx.conf syntax is ok</p>
<p>nginx:configuration file /usr/local/nginx/conf/nginx.conf test issuccessful</p>
<p>平滑重启nginx</p>
<p>/usr/local/nginx/sbin/nginx -s reload</p>
<p>查看ngixn版本极其编译参数</p>
<p>/usr/local/nginx/sbin/nginx -V</p>
<p>configure arguments: –prefix=/data/app/nginx –user=www –group=www –with-http_stub_status_module –with-http_ssl_module –with-file-aio –with-http_realip_module</p>
<h6 id="权作一个跳坑记录。"><a href="#权作一个跳坑记录。" class="headerlink" title="权作一个跳坑记录。"></a>权作一个跳坑记录。</h6><hr>
]]></content>
      <tags>
        <tag>点滴</tag>
      </tags>
  </entry>
  <entry>
    <title>php 安装redis，protobuf,mcryp扩展</title>
    <url>/2023/081036272.html</url>
    <content><![CDATA[<p>&nbsp; 测试机上测试一些数据需要用到redis扩展，偷懒yum安装的php，以前yum install php-pecl-redis.x86_64可以安装扩展，这次找不到安装包，不折腾手动安装下。</p>
<p>1.下载phpredis</p>
<p>cd /usr/local/src</p>
<p>wget <a href="https://github.com/nicolasff/phpredis/archive/2.2.4.tar.gz">https://github.com/nicolasff/phpredis/archive/2.2.4.tar.gz</a></p>
<p>tar -zxvf 2.2.4.tar.gz</p>
<p>cd phpredis-2.2.4/</p>
<p>2.用phpize生成configure配置文件</p>
<p>/usr/bin/phpize&nbsp; #会生成几个新文件，默认安装路径自定义的按照自定义路径；</p>
<p>./configure –with-php-config=/usr/bin/php-config</p>
<p>make #编译</p>
<p>make install #安装</p>
<p>make test #测试</p>
<p>3.配置php支持</p>
<p>vim /usr/local/php/etc/php.ini #编辑配置文件，在最后一行添加以下内容</p>
<p>extension=”redis.so”</p>
<ol start="4">
<li></li>
</ol>
<p>重启http加载查看phpinfo信息：</p>
<p>redis</p>
<p>Redis Supportenabled</p>
<p>Redis Version2.2.4</p>
<p>成功！</p>
<p>php扩展Protobuf</p>
<p>下载protobuf扩展包：wget <a href="https://github.com/allegro/php-protobuf/archive/master.zip%E8%BF%99%E4%B8%AAmaster.zip%E4%BC%9A%E6%8A%A5%E9%94%99%EF%BC%9B">https://github.com/allegro/php-protobuf/archive/master.zip这个master.zip会报错；</a></p>
<p>master.zip</p>
<p>cd /home/tools/php-protobuf-master/</p>
<p>phpize</p>
<p>可能会报错php-devel</p>
<p>yum install php-devel</p>
<p>./configure<br>1.<br>make&nbsp;&amp;&amp;&nbsp;make&nbsp;install<br>1.</p>
<p>If you ever happen to want to link against installed libraries</p>
<p>in a given directory, LIBDIR, you must either use libtool, and</p>
<p>specify the full pathname of the library, or use the `-LLIBDIR’</p>
<p>flag during linking and do at least one of the following:</p>
<p>&nbsp;&nbsp; - add LIBDIR to the `LD_LIBRARY_PATH’ environment variable</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp; during execution</p>
<p>&nbsp;&nbsp; - add LIBDIR to the `LD_RUN_PATH’ environment variable</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp; during linking</p>
<p>&nbsp;&nbsp; - use the `-Wl,-rpath -Wl,LIBDIR’ linker flag</p>
<p>&nbsp;&nbsp; - have your system administrator add LIBDIR to `/etc/ld.so.conf’</p>
<p>&nbsp;</p>
<p>See any operating system documentation about shared libraries for</p>
<p>more information, such as the ld(1) and ld.so(8) manual pages.</p>
<hr>
<p>&nbsp;</p>
<p>Build complete.</p>
<p>Don’t forget to run ‘make test’.</p>
<p>&nbsp;</p>
<p>Installing shared extensions:&nbsp;&nbsp;&nbsp;&nbsp; /usr/lib64/php/modules/</p>
<p>然后再php.ini增加</p>
<p>extension = protocolbuffers.so</p>
<p>重启下http就可以了；</p>
<p>装载protobuff库：</p>
<p>&nbsp;pear&nbsp;channel-discover&nbsp;pear.pollinimini.net&nbsp;</p>
<p>pear&nbsp;install&nbsp;drslump/Protobuf-beta&nbsp;</p>
<p>mcryp扩展：</p>
<p>yum install libmcrypt libmcrypt-devel mcrypt mhash 如果报错找不到补丁的话手动安装；</p>
<p>下载Libmcrypt,mhash,mcrypt安装包</p>
<p>Libmcrypt(libmcrypt-2.5.8.tar.gz)：<a href="http://sourceforge.net/project/showfiles.php?group_id=87941&amp;package_id=91774&amp;release_id=487459">http://sourceforge.net/project/showfiles.php?group_id=87941&amp;package_id=91774&amp;release_id=487459</a></p>
<p>mcrypt(mcrypt-2.6.8.tar.gz ):<a href="http://sourceforge.net/project/showfiles.php?group_id=87941&amp;package_id=91948&amp;release_id=642101">http://sourceforge.net/project/showfiles.php?group_id=87941&amp;package_id=91948&amp;release_id=642101</a></p>
<p>mhash(mhash-0.9.9.9.tar.gz):<a href="http://sourceforge.net/project/showfiles.php?group_id=4286&amp;package_id=4300&amp;release_id=645636">http://sourceforge.net/project/showfiles.php?group_id=4286&amp;package_id=4300&amp;release_id=645636</a></p>
<p>2.先安装Libmcrypt</p>
<p>tar -zxvf libmcrypt-2.5.8.tar.gz</p>
<p>cd libmcrypt-2.5.8</p>
<p>./configure</p>
<p>make</p>
<p>make install</p>
<p>说明：libmcript默认安装在/usr/local&nbsp;</p>
<p>3.再安装mhash</p>
<p>tar -zxvf mhash-0.9.9.9.tar.gz</p>
<p>cd mhash-0.9.9.9</p>
<p>./configure</p>
<p>make &amp;&amp; make install</p>
<p>4.最后安装mcrypt</p>
<p>tar -zxvf mcrypt-2.6.8.tar.gz</p>
<p>cd mcrypt-2.6.8</p>
<p>LD_LIBRARY_PATH=/usr/local/lib ./configure</p>
<p>make &amp;&amp; make install</p>
<p>说明：由于在配置Mcrypt时，会找不到libmcrypt的链接库，导致无法编译，因为Libmcrypt的链接库在/usr/local/lib文件夹下。</p>
<p>因次，在配置mcrypt时要加入LD_LIBRARY_PATH=/usr/local/lib导入键接库。</p>
<p>到&nbsp;<a href="http://cn.php.net/releases/">http://cn.php.net/releases/</a>&nbsp;网页下找到自己对应php版本，下载后解压</p>
<p>cd php-5.4.16/ext/mcrypt/</p>
<p>phpize (执行phpize命令（phpize是用来扩展php扩展模块的，通过phpize可以建立php的外挂模块，如果没有？yum install php-devel)</p>
<p>phpize&nbsp;</p>
<p>Configuring for:</p>
<p>PHP Api Version:&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;20100412</p>
<p>Zend Module Api No:&nbsp; &nbsp; &nbsp; 20100525</p>
<p>Zend Extension Api No:&nbsp; &nbsp;220100525</p>
<p>yum 安装php./configure就可以，定制的需要自己的路径如比：./configure –with-php-config=/usr/bin/php-config</p>
<p>./configure</p>
<p>make &amp;&amp; make install</p>
<p>Libraries have been installed in:</p>
<p>&nbsp; &nbsp;/home/tools/php-5.4.16/ext/mcrypt/modules</p>
<p>If you ever happen to want to link against installed libraries</p>
<p>in a given directory, LIBDIR, you must either use libtool, and</p>
<p>specify the full pathname of the library, or use the `-LLIBDIR’</p>
<p>flag during linking and do at least one of the following:</p>
<p>&nbsp; &nbsp;- add LIBDIR to the `LD_LIBRARY_PATH’ environment variable</p>
<p>&nbsp; &nbsp; &nbsp;during execution</p>
<p>&nbsp; &nbsp;- add LIBDIR to the `LD_RUN_PATH’ environment variable</p>
<p>&nbsp; &nbsp; &nbsp;during linking</p>
<p>&nbsp; &nbsp;- use the `-Wl,-rpath -Wl,LIBDIR’ linker flag</p>
<p>&nbsp; &nbsp;- have your system administrator add LIBDIR to `/etc/ld.so.conf’</p>
<p>See any operating system documentation about shared libraries for</p>
<p>more information, such as the ld(1) and ld.so(8) manual pages.</p>
<hr>
<p>Build complete.</p>
<p>Don’t forget to run ‘make test’.</p>
<p>Installing shared extensions:&nbsp; &nbsp; &nbsp;/usr/lib64/php/modules/</p>
<p>php.ini添加一条extension=mcrypt.so</p>
<p>extension = protocolbuffers.so</p>
<p>extension = mcrypt.so</p>
<hr>
]]></content>
  </entry>
  <entry>
    <title>ps-top</title>
    <url>/2023/121939275.html</url>
    <content><![CDATA[<p>经常用到的命令，详细的命令参数确实掌握的不牢，复习一下~</p>
<p><strong>一</strong>.进程概念</p>
<p>　　进程就是系统未完成并且正在进行的工作</p>
<p>二.查看进程</p>
<p>【1】图形方式查看：gnome-system-monitor</p>
<p>【2】命令方式：ps</p>
<p>参数：-A 　表示所有进程   -a  表示在当前环境中运行的进程，不包含环境信息</p>
<p>　　　　　　-u  显示进程用户信息　　a  在当前环境中运行的进程　　x  列出系统中所有运行包含tty输出设</p>
<p>　　　　　　f   显示进程的父子关系　　e  显示进程的详细信息（系统资源的调用）</p>
<p>显示部分结果如下：</p>
<p> 示例：显示进程所有信息（只显示了部分截图）</p>
<p>[root@localhost mnt]# ps -A<br> PID TTY     TIME CMD<br>  1 ?    00:00:03 systemd<br>  2 ?    00:00:00 kthreadd<br>  3 ?    00:00:00 ksoftirqd/0<br>  5 ?    00:00:00 kworker/0:0H<br>  7 ?    00:00:00 migration/0<br>  8 ?    00:00:00 rcu_bh<br>  9 ?    00:00:00 rcuob/0<br>  10 ?    00:00:01 rcu_sched<br>  11 ?    00:00:01 rcuos/0<br>  12 ?    00:00:00 watchdog/0<br>  13 ?    00:00:00 khelper<br>  14 ?    00:00:00 kdevtmpfs</p>
<p> 示例：显示当前环境中运行的进程，没有进程的环境信息</p>
<p>[root@localhost mnt]# ps -a</p>
<p> PID TTY     TIME CMD<br> 7873 pts/0  00:00:00 ps</p>
<p>示例：显示当前进程的所属关系</p>
<p>[root@localhost mnt]# ps f<br> PID TTY   STAT  TIME COMMAND<br> 2180 pts/0  Ss   0:01 -bash<br> 7912 pts/0  R+   0:00 _ ps f<br> 590 tty1   Ss+  0:56 /usr/bin/Xorg :0 -background none -verbose -auth /run<br> 1210 ttyS0  Ss+  0:00 /sbin/agetty –keep-baud ttyS0 115200 38400 9600</p>
<p>ps常用组合：</p>
<p>　　　　　　ps aux 　　　　 ##显示系统中所有进程并显示进程用户<br>　　　　　　ps ef 　　　　 ##显示进程详细信息并显示进程父子关系<br>　　　　　　ps ax 　　　　 ##显示当前系统中的所有进程</p>
<p>[root@localhost mnt]# ps ef<br> PID TTY   STAT  TIME COMMAND<br> 2180 pts/0  Ss   0:01 -bash XMODIFIERS=@im=ibus LANG=en_US.UTF-8 USER=root<br> 7947 pts/0  R+   0:00 _ ps ef XDG_SESSION_ID=2 HOSTNAME=localhost TERM=x<br> 590 tty1   Ss+  0:56 /usr/bin/Xorg :0 -background none -verbose -auth /ru<br> 1210 ttyS0  Ss+  0:00 /sbin/agetty –keep-baud ttyS0 115200 38400 9600 PAT</p>
<p>显示进程指定信息：ps -o xxx </p>
<p>　　参数： comm  　 ##进程名称</p>
<p>　　　　　 user　　   ##进程所有人</p>
<p>　　　　　 group　　 ##进程所有组</p>
<p>　　　　　 %cpu ##进程cpu使用率</p>
<p>　　　　　 %mem ##进程内存使用率</p>
<p>　　　　　　pid ##进程id</p>
<p>　　　　　 nice ##进程优先级</p>
<p>[root@localhost mnt]# ps -o %cpu,%mem,pid,user,group,nice,comm<br>%CPU %MEM  PID USER   GROUP   NI COMMAND<br> 0.0 0.3 2180 root   root    0 bash<br> 0.0 0.1 7965 root   root    0 ps</p>
<p>进程排序 ：–sort=</p>
<p>　　　　ps ax –sort=+%cpu|-%cpu　　　　##表示对cpu的使用率进行排序（+有小到大；-由大到小）<br>　　　　ps ax –sort=+%mem|-%mem　　　## 对内存的占用大小排序</p>
<p>[root@localhost mnt]# ps ax –sort=-%mem -o %mem,user,uid,comm<br>%MEM USER    UID COMMAND<br>16.1 root     0 gnome-shell<br> 3.4 root     0 Xorg<br> 2.5 root     0 nautilus<br> 2.3 root     0 gnome-settings-<br> 2.1 root     0 firewalld<br> 1.9 root     0 goa-daemon<br> 1.8 root     0 tuned<br> 1.6 polkitd  999 polkitd</p>
<p>stat中显示的信息 ：</p>
<p>　　　S  ##进程状态　　　　l  ##内存中有锁定空间<br>　　　N  ##优先级低　　　　 &lt;  ##优先级高<br>　　　+  ##前台运行　　　　s  ##顶级进程</p>
<p>三.进程优先级<br>【1】进程的优先级范围：-20～19<br>【2】优先级查看：ps ax -o pid,nice,comm　</p>
<p>[root@localhost mnt]# ps a -o pid,nice,comm<br> PID NI COMMAND<br> 590  0 Xorg<br> 1210  0 agetty<br> 2180  0 bash<br> 8053  0 ps</p>
<p>【3】指定某个优先级开启进程</p>
<p>　　　nice -n　 优先级数字 进程名称<br> 示例：开启vim并且指定程序优先级为-5</p>
<p>[root@localhost mnt]# nice -n -5 vim &amp;<br>[1] 8056<br>[root@localhost mnt]# ps a -o pid,nice,comm<br> PID NI COMMAND<br> 590  0 Xorg<br> 1210  0 agetty<br> 2180  0 bash<br> 8056 -5 vim<br> 8065  0 ps<br>[1]+ Stopped         nice -n -5 vim</p>
<p>【4】改变进程优先级<br>　　renice -n 优先级数字 进程pid<br> 示例：改变1806进程的优先级为-5</p>
<p> 8056 -5 vim<br> 8065  0 ps </p>
<p>[root@localhost mnt]# renice -n -20 8056<br>8056 (process ID) old priority -5, new priority -2</p>
<p>四.环境中进程的前后台调用</p>
<p>　　jobs　　　　 　　 ##查看被打入环境后台的进程<br>　　ctrl+z　　　　　　 ##把占用终端的进程打入后台<br>　　fg jobsnum 　　  ##把后台进程调回前台<br>　　bg jobsnum 　　  ##把后台暂停的进程运行<br>　　comm &amp; 　　　　 ##让命令直接在后台运行</p>
<p>五.进程信号</p>
<p>【1】常用信号等级<br>　　　　1 　　　　 ##进程重新加载配置<br>　　　　2 　　　　 ##删除进程在内存中的数据<br>　　　　3 　　　　 ##删除鼠标在内存中的数据<br>　　　　9 　　　　 ##强行结束单个进程(不能被阻塞)<br>　　　　15 　　　  ##正常关闭进程 （可能会被阻塞）<br>　　　　18 　　　  ##运行暂停的进程<br>　　　　19 　　    ##暂停某个进程 （不能被阻塞）<br>　　　　20 　　　  ##把进程打入后台 （可以被阻塞）<br>　　　　man 7 signal ##查看信号详细信息</p>
<p>【2】kill的使用</p>
<p> kill -信号 进程pid<br> killall -信号 进程名字<br> pkill -u student -信号</p>
<p>6.用户登记审查</p>
<p> w   查看当前使用系统的用户有哪些 </p>
<p> w -f 查看使用地点</p>
<p> last 查看用户登录成功历史</p>
<p>[root@localhost mnt]# w</p>
<p> 11:14:08 up 2:58, 2 users, load average: 0.02, 0.02, 0.05<br>USER   TTY    LOGIN@  IDLE  JCPU  PCPU WHAT<br>root   :0    08:17  ?xdm?  8:12  0.11s gdm-session-worker [pam/gdm-<br>root   pts/0   08:39  0.00s 1.96s 0.00s w</p>
<p>[root@localhost mnt]# w -f<br> 11:15:15 up 2:59, 2 users, load average: 0.01, 0.02, 0.05<br>USER   TTY   FROM       LOGIN@  IDLE  JCPU  PCPU WHAT<br>root   :0    :0        08:17  ?xdm?  8:12  0.11s gdm-session-<br>root   pts/0  172.25.254.77  08:39  3.00s 1.96s 0.00s w -f</p>
<p>[root@localhost mnt]# last<br>root   pts/3    172.25.254.77  Wed Jul 25 09:54 - 09:59 (00:04)<br>root   pts/2    :0        Wed Jul 25 09:34 - 09:58 (00:24)<br>root   pts/1    :0        Wed Jul 25 08:39 - 09:58 (01:18)<br>root   pts/0    172.25.254.77  Wed Jul 25 08:39  still logged in<br>root   :0      :0        Wed Jul 25 08:17  still logged in<br>(unknown :0      :0        Wed Jul 25 08:16 - 08:17 (00:00)<br>reboot  system boot 3.10.0-123.el7.x Wed Jul 25 08:16 - 11:15 (02:59)<br>root   pts/2    172.25.254.77  Tue Jul 24 22:40 - 22:54 (00:13)<br>root   pts/1    :0        Tue Jul 24 21:09 - crash (11:06)<br>root   pts/0    :0        Tue Jul 24 20:01 - crash (12:14)<br>root   :0      :0        Tue Jul 24 20:01 - crash (12:15)</p>
<p>7.进程的动态监控</p>
<p>【1】命令：top</p>
<p>　　　　1. 　　　　##显示cpu每个核的负载</p>
<p>　　　　s 　　　　##调整刷新频率<br>　　　　c 　　　　##CPU负载排序<br>　　　　m 　　　　##内存使用量排序<br>　　　　h 　　　　##查看帮助<br>　　　　u 　　　　##查看指定用户进程<br>　　　　k 　　　　##对指定进程发起信号<br>　　　　q 　　　　##退出</p>
<p>[root@localhost mnt]# top</p>
<p>top - 11:16:24 up 3:00, 2 users, load average: 0.00, 0.01, 0.05<br>Tasks: 146 total,  2 running, 143 sleeping,  1 stopped,  0 zombie<br>%Cpu(s): 0.3 us, 0.3 sy, 0.0 ni, 99.3 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0<br>KiB Mem:  969416 total,  833532 used,  135884 free,   884 buffers<br>KiB Swap:    0 total,    0 used,    0 free.  369560 cached Mem</p>
<p> PID USER   PR NI  VIRT  RES  SHR S %CPU %MEM   TIME+ COMMAND<br> 8148 root   20  0 123632  1556  1096 R 0.3 0.2  0:00.02 top<br>  1 root   20  0  50468  3984  2208 S 0.0 0.4  0:03.37 systemd<br>  2 root   20  0    0   0   0 S 0.0 0.0  0:00.00 kthreadd<br>  3 root   20  0    0   0   0 S 0.0 0.0  0:00.04 ksoftirq+<br>  5 root    0 -20    0   0   0 S 0.0 0.0  0:00.00 kworker/+<br>  7 root   rt  0    0   0   0 S 0.0 0.0  0:00.00 migratio+<br>  8 root   20  0    0   0   0 S 0.0 0.0  0:00.00 rcu_bh<br>  9 root   20  0    0   0   0 S 0.0 0.0  0:00.00 rcuob/0<br>  10 root   20  0    0   0   0 S 0.0 0.0  0:01.21 rcu_sched<br>  11 root   20  0    0   0   0 R 0.0 0.0  0:02.01 rcuos/0<br>  12 root   rt  0    0   0   0 S 0.0 0.0  0:00.17 watchdog+<br>  13 root    0 -20    0   0   0 S 0.0 0.0  0:00.00 khelper<br>  14 root   20  0    0   0   0 S 0.0 0.0  0:00.00 kdevtmpfs<br>  15 root    0 -20    0   0   0 S 0.0 0.0  0:00.00 netns<br>  16 root    0 -20    0   0   0 S 0.0 0.0  0:00.00 writeback<br>  17 root    0 -20    0   0   0 S 0.0 0.0  0:00.00 kintegri+</p>
<p>From：<a href="https://www.cnblogs.com/uthnb/p/9367848.html">https://www.cnblogs.com/uthnb/p/9367848.html</a></p>
<p>top命令经常用来监控linux的系统状况，是常用的性能分析工具，能够实时显示系统中各个进程的资源占用情况。</p>
<p>top的使用方式 top [-d number] | top [-bnp]</p>
<p><strong>参数解释：</strong></p>
<p>-d：number代表秒数，表示top命令显示的页面更新一次的间隔。默认是5秒。-b：以批次的方式执行top。-n：与-b配合使用，表示需要进行几次top命令的输出结果。-p：指定特定的pid进程号进行观察。</p>
<p><strong>在top命令显示的页面还可以输入以下按键执行相应的功能（注意大小写区分的）：</strong></p>
<p>?：显示在top当中可以输入的命令 </p>
<p>P：以CPU的使用资源排序显示 </p>
<p>M：以内存的使用资源排序显示 </p>
<p>N：以pid排序显示 </p>
<p>T：由进程使用的时间累计排序显示 </p>
<p>k：给某一个pid一个信号。可以用来杀死进程 </p>
<p>r：给某个pid重新定制一个nice值（即优先级） </p>
<p>q：退出top（用ctrl+c也可以退出top）</p>
<p>Centos：</p>
<p><img src="/../images/20231219_1.png"> </p>
<p>Debian：</p>
<p><img src="/../images/20231219_2.png"> </p>
<p><strong>01 top前5行统计信息</strong></p>
<p>第1行：top - 05:43:27 up 4:52, 2 users, load average: 0.58, 0.41, 0.30 </p>
<p>第1行是任务队列信息，其参数如下：</p>
<p><img src="/../images/20231219_3.png"> </p>
<p>load average: 如果这个数除以逻辑CPU的数量，结果高于5的时候就表明系统在超负荷运转了。 </p>
<p>第2行：Tasks: 159 total, 1 running, 158 sleeping, 0 stopped, 0 zombie</p>
<p>第3行：%Cpu(s): 37.0 us, 3.7 sy, 0.0 ni, 59.3 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st</p>
<p>第2、3行为进程和CPU的信息 </p>
<p>当有多个CPU时，这些内容可能会超过两行，其参数如下：</p>
<p><img src="/../images/20231219_4.png"> </p>
<p>第4行：KiB Mem: 1530752 total, 1481968 used, 48784 free, 70988 buffers</p>
<p>第5行：KiB Swap: 3905532 total, 267544 used, 3637988 free. 617312 cached Mem</p>
<p>第4、5行为内存信息 </p>
<p>其参数如下：</p>
<p><img src="/../images/20231219_5.png"> </p>
<p>上述最后提到的缓冲的交换区总量，这里解释一下，所谓缓冲的交换区总量，即内存中的内容被换出到交换区，而后又被换入到内存，但使用过的交换区尚未被覆盖，该数值即为这些内容已存在于内存中的交换区的大小。</p>
<p>相应的内存再次被换出时可不必再对交换区写入。 </p>
<p>计算可用内存数有一个近似的公式： </p>
<p>第四行的free + 第四行的buffers + 第五行的cached</p>
<p><strong>02 进程信息</strong></p>
<p><img src="/../images/20231219_6.png"> </p>
<p> 默认进入top时，各进程是按照CPU的占用量来排序的。</p>
<p><img src="/../images/20231219_7.png"> </p>
<p>击键盘‘x’（打开/关闭排序列的加亮效果）可以看到现在是按”%CPU”进行排序的，可以按”shift+&gt;”或者”shift+&lt;”左右改变排序序列。</p>
<p>在Linux终端上输入top命令出现的结果及其表示的含义如下图：</p>
<p><img src="/../images/20231219_8.png"> </p>
<p>top命令的用法</p>
<p>顺便说一下uptime命令</p>
<p><img src="/../images/20231219_9.png"> </p>
<p>top命令的用法「建议收藏」</p>
<p>3、以上是默认的显示内容，可以通过快捷键来更改显示的内容：</p>
<p>&lt;1&gt;按f键：会显示如下列表</p>
<p><img src="/../images/20231219_10.png"> </p>
<p>top命令的用法「建议收藏」</p>
<p>选a-z键就可以显示或者隐藏对应的列，按回车键确定。</p>
<p>&lt;2&gt;按o键可以改变列的显示顺序。按a-z将相应的列向后移；按A-Z将相应的列向左移。</p>
<p>&lt;3&gt;按F或者O键，然后按照a-z可以将进程按照相应的列进行排序，大写的R键可以将当前的排序倒转。</p>
<p>4、参数选项：</p>
<p>****top -d 秒数****：表示进程界面更新时间（默认5秒）</p>
<p><em><strong>*top -b p 2&gt;/tmp/top.txt*</strong></em> 表示将top进程表在/tmp/top.txt中打印两次。</p>
<p><em><strong>*top -p 1*</strong></em> 查看进程号为1的进程</p>
<p><em><strong>*-q*</strong></em> top没有任何延迟时间的进行刷新。如果调用程序有超级用户权限，top将会以尽可能高的优先级运行。</p>
<p><em><strong>*-S*</strong></em> 指定累计模式</p>
<p><em><strong>*-s*</strong></em> 使top命令在安全模式中运行。将去除交互命令带来的潜在危险。</p>
<p><em><strong>*-i*</strong></em> 使top不显示任何闲置或者僵死的进程。</p>
<p><em><strong>*-c*</strong></em> 显示整个命令行而不是整个命令名</p>
<p><img src="/../images/20231219_11.png"> </p>
<p>top命令的用法</p>
<p>5、使用情况举例；</p>
<p>&lt;1&gt;2000毫秒刷新一次，总共5次，输出内容存放在cur.txt中。</p>
<p>#<em><strong>*top -b -d 2.5 -n 5&gt;cur.txt*</strong></em></p>
<p>&lt;2&gt;快速按%CPU列排序：大写字母P</p>
<p>快速按%MEM列排序：大写字母M</p>
<p>快速按%TIME+列排序：大写字母T</p>
<p>（默认降序，升序可使用R）</p>
<p>&lt;3&gt;选择显示列或者其他列：小写字母f</p>
<p>交换列显示顺序：小写字母o</p>
<p>选择需要排序的列：大写字母F</p>
<p>6、top命令显示过程中使用一些交互命令：</p>
<p>****Ctrl L****：擦除并且重写屏幕</p>
<p><em><strong>*h*<em><strong>或者</strong></em>*？*</strong></em> ：显示帮助画面</p>
<p><em><strong>*k*</strong></em> :终止一个进程；默认使用15信号，可以使用信号9来强制结束该进程。但是在安全模式下此命令被屏蔽。</p>
<p><em><strong>*i*</strong></em> :忽略闲置和僵死进程，开关式命令。</p>
<p><em><strong>*q*</strong></em> :退出程序。</p>
<p><em><strong>*r*</strong></em> :重新安排一个进程的优先级。默认值是10，输入一个正值使优先级降低；输入一个负值使优先级升高。</p>
<p><em><strong>*S*</strong></em> ：切换到累计模式。</p>
<p><em><strong>*s*</strong></em> :改变两次刷新的延迟时间。单位为秒，如果有小数，切换为ms，输入0则系统不断的刷新，默认值是5.</p>
<p><em><strong>*f*<em><strong>或者</strong></em>*F*</strong></em> ：从当前显示中添加或者删除项目。</p>
<p><em><strong>*o*<em><strong>或者</strong></em>*O*</strong></em> ：改变显示项目的顺序。</p>
<p><em><strong>*t*</strong></em> ：切换显示进程和CPU状态信息。</p>
<p><em><strong>*m*</strong></em> :切换显示内存信息。</p>
<p><em><strong>*I*</strong></em> :切换显示平均负载和CPU状态信息。</p>
<p><em><strong>*M*</strong></em> ：根据驻留内存大小进行排序。</p>
<p><em><strong>*P*</strong></em> ：根据CPU使用百分比大小进行排序。</p>
<p><em><strong>*T*</strong></em> ：根据时间或者累计时间进行排序。</p>
<p><em><strong>*W*</strong></em> ：写top配置文件的方法。将当前设置写入~/toprc文件中。</p>
<p>转自：<a href="https://javaforall.cn/128103.html%E5%8E%9F%E6%96%87%E9%93%BE%E6%8E%A5%EF%BC%9Ahttps://javaforall.cn">https://javaforall.cn/128103.html原文链接：https://javaforall.cn</a></p>
]]></content>
      <categories>
        <category>系统</category>
      </categories>
  </entry>
  <entry>
    <title>ssh免密登录问题</title>
    <url>/2023/071760022.html</url>
    <content><![CDATA[<p>一台内网多个开发公用服务器，各自用户对对应的a，b台服务器做过免密登录，一直很好用，突然不能用了；追缘由以前的服务器多用户感觉吃力太慢，于是乎换了一台高配服务器，开发省事直接把原来的公钥给复制过来了，倒也是相安无事，前几天小伙伴处理服务器c免密，把公钥重新生成了，覆盖了原来的文件，vim&nbsp;id_rsa.pub 复制到服务器上面的，结果，开发a.b服务器不能免密了，处理的c服务器也不能免密登录；开发的a,b服务器因为公钥改了导致，c服务器检查了sshd_conf和authorized_keys以后，vim&nbsp;id_rsa.pub贴上去的内容有问题，so还是&nbsp;scp id_rsa.pub root@B:~/id_rsa.pub，然后登录b服务器cat ~/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys这样安全些。</p>
<p>免密登录出问题：&nbsp;1.sshd_conf 配置检查；</p>
<p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;2.id_rsa.pub变动；</p>
<p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;3.查看authorized_keys；</p>
<p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;4.权限问题 ：.ssh目录下的authorized_keys文件需要600或644权限</p>
<p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 5.&nbsp;StrictModes问题编辑sudo vi /etc/ssh/sshd_config，找到#StrictModes yes改成StrictModes no</p>
<p>服务器A需要免密码访问服务器B：</p>
<ol>
<li>在A上面生成公钥密钥，执行命令</li>
</ol>
<p>&nbsp;</p>
<p>&nbsp;ssh-keygen -t rsa 或者 ssh-keygen -t rsa -P ‘’</p>
<p>一路回车即可，会在~/.ssh目录下生成 id_rsa和id_rsa.pub两个文件，id_rsa为私钥，id_rsa.pub为公钥</p>
<ol start="2">
<li>将公钥id_rsa.pub拷贝到B机器上</li>
</ol>
<p>&nbsp;scp id_rsa.pub root@B:~/id_rsa.pub</p>
<ol start="3">
<li>在服务器B对应的用户root/.ssh下面将id_rsa.pub追加到~/.ssh/authorized_keys文件中</li>
</ol>
<p>cd&nbsp;/home/user/.ssh</p>
<p>cat id_rsa.pub &gt;&gt; authorized_keys&nbsp; 注意是&gt;&gt;别覆盖了；</p>
<ol start="4">
<li>设置 authorized_keys权限</li>
</ol>
<p>&nbsp;chmod 600 ~/.ssh/authorized_keys</p>
<hr>
]]></content>
      <categories>
        <category>系统</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title>vsftp 锁定用户目录</title>
    <url>/2023/071114619.html</url>
    <content><![CDATA[<p>vsftp 安装以后给用户权限和锁定目录；</p>
<p>关闭SELinux：</p>
<p>修改/etc/selinux/config文件中的SELINUX=”” 为 disabled ，然后重启。</p>
<p>如果不想重启系统，使用命令setenforce 0</p>
<p>添加用户：</p>
<p>useradd -d /var/www -s /sbin/nologin ftpuser</p>
<p>主要是修改/etc/vsftpd/vsftpd.conf如下：</p>
<p>chroot_local_user=NO</p>
<p>chroot_list_enable=YES</p>
<p>chroot_list_file=/etc/vsftpd/vsftpd.chroot_list</p>
<p>vim chroot_list</p>
<p>添加锁定目录用户</p>
<p>Ftpuser</p>
<p>Upload</p>
<p>当然可以修改路径：</p>
<p>usermod –d /www/html&nbsp; &nbsp;ftpuser</p>
<p>**vsftpd.user_list：该文件里的用户账户在默认情况下也不能访问FTP服务器，仅当vsftpd .conf配置文件里启用userlist_enable=NO选项时才允许访问。</p>
<p>/etc/vsftpd/user_list ，添加上需要阻止的本地用户，一个用户名一行&nbsp;用被阻止的用户</p>
<p>grep -v “^#” vsftpd.conf&nbsp;</p>
<p>anonymous_enable=NO</p>
<p>local_enable=YES</p>
<p>write_enable=YES</p>
<p>local_umask=000</p>
<p>dirmessage_enable=YES</p>
<p>xferlog_enable=YES</p>
<p>connect_from_port_20=YES</p>
<p>xferlog_file=/var/log/xferlog</p>
<p>xferlog_std_format=YES</p>
<p>chroot_local_user=NO</p>
<p>chroot_list_enable=YES</p>
<p>chroot_list_file=/etc/vsftpd/chroot_list</p>
<p>listen=YES</p>
<p>listen_port=21</p>
<p>pasv_address=192.168.10.123</p>
<p>pasv_addr_resolve=yes</p>
<p>pasv_enable=YES</p>
<p>pasv_min_port=5000</p>
<p>pasv_max_port=5008</p>
<p>use_localtime=YES</p>
<p>listen_ipv6=NO</p>
<p>allow_writeable_chroot=YES</p>
<p>pam_service_name=vsftpd</p>
<p>userlist_enable=YES</p>
<p>配置相关来源网络：</p>
<p>登录和对匿名用户的设置</p>
<p>write_enable=YES&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //是否对登录用户开启写权限。属全局性设置。默认NO<br>local_enable=YES&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //是否允许本地用户登录FTP服务器。默认为NO<br>anonymous_enable=YES&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //设置是否允许匿名用户登录FTP服务器。默认为YES<br>ftp_username=ftp&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //定义匿名用户的账户名称，默认值为ftp。<br>no_anon_password=YES&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //匿名用户登录时是否询问口令。设置为YES，则不询问。默&nbsp;<br>认NO<br>anon_world_readable_only=YES&nbsp;&nbsp; //匿名用户是否允许下载可阅读的文档，默认为YES。<br>&nbsp;&nbsp; anon_upload_enable=YES&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //是否允许匿名用户上传文件。只有在write_enable设置为<br>YES时，该配置项才有效。而且匿名用户对相应的目录必须有写权限。默认为NO。<br>anon_mkdir_write_enable=YES //是否允许匿名用户创建目录。只有在write_enable设置为&nbsp;&nbsp;&nbsp; YES时有效。且匿名用户对上层目录有写入的权限。默认为NO。<br>anon_other_write_enable=NO&nbsp;&nbsp;&nbsp; //若设置为YES，则匿名用户会被允许拥有多于<br>上传和建立目录的权限，还会拥有删除和更名权限。默认值为NO。</p>
<p>2．设置用户登录后所在的目录&nbsp;<br>local_root=/var/ftp&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>// 设置本地用户登录后所在的目录。默认配置文件中没有设置该项，此时用户登录FTP服务器后，所在的目录为该用户的主目录，对于root用户，则为/root目录。<br>anon_root=/var/ftp&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>//设置匿名用户登录后所在的目录。若未指定，则默认为/var/ftp目录。</p>
<p>&nbsp;</p>
<p>3．控制用户是否允许切换到上级目录&nbsp;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 在默认配置下，用户可以使用“cd..”命名切换到上级目录。比如，若用户登录后所在的目录为/var/ftp，则在“ftp&gt;”命令行 下，执行“cd..”命令后，用户将切换到其上级目录/var，若继续执行该命令，则可进入Linux系统的根目录，从而可以对整个Linux的文件系统 进行操作。</p>
<p>若设置了write_enable=YES，则用户还可对根目录下的文件进行改写操作，会给系统带来极大的安全隐患，因此，必须防止用户切换到Linux的根目录，相关的配置项如下：<br>chroot_list_enable=YES&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>// 设置是否启用chroot_list_file配置项指定的用户列表文件。设置为YES则除了列在j/etc/vsftpd/chroot_list文件中的的帐号外，所有登录的用户都可以进入ftp根目录之外的目录。默认NO<br>chroot_list_file=/etc/vsftpd/chroot_list&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>// 用于指定用户列表文件，该文件用于控制哪些用户可以切换到FTP站点根目录的上级目录。<br>chroot_local_user=YES&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>// 用于指定用户列表文件中的用户，是否允许切换到上级目录。默认NO<br>注意：要对本地用户查看效果，需先设置local_root=/var/ftp</p>
<p>具体情况有以下几种：<br>1）当chroot_list_enable=YES，chroot_local_user=YES时，在/etc/vsftpd/chroot_list文件中列出的用户，可以切换到上级目录；未在文件中列出的用户，不能切换到站点根目录的上级目录。<br>2）当chroot_list_enable=YES，chroot_local_user=NO时，在/etc/vsftpd/chroot_list文件中列出的用户，不能切换到站点根目录的上级目录；未在文件中列出的用户，可以切换到上级目录。<br>3）当chroot_list_enable=NO，chroot_local_user=YES时，所有用户均不能切换到上级目录。<br>4）当chroot_list_enable=NO，chroot_local_user=NO时，所有用户均可以切换到上级目录。<br>5）当用户不允许切换到上级目录时，登录后FTP站点的根目录“/”是该FTP账户的主目录，即文件的系统的/var/ftp目录。</p>
<p>&nbsp;</p>
<p>4．设置访问控制&nbsp;<br>（1）设置允许或不允许访问的主机（见TBP14）<br>tcp_wrappers=YES用来设置vsftpd服务器是否与tcp wrapper相结合，进行主机的访问控制。默认设置为YES，vsftpd服务器会检查/etc/hosts.allow和/etc /hosts.deny中的设置，以决定请求连接的主机是否允许访问该FTP服务器。这两个文件可以起到简易的防火墙功能。<br>比如，若要仅允许192.168.168.1～192.168.168.254的用户，可以访问连接vsftpd服务器，则可在/etc/hosts.allow文件中添加以下内容：<br>vsftpd：192.168.168.0/255.255.255.0 ：allow<br>all：all：deny</p>
<p>（2）设置允许或不允许访问的用户<br>对用户的访问控制由/etc/vsftpd/user_list和/etc/vsftpd/ftpusers文件来控制实现。相关配置命令如下：<br>userlist_enable=YES&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>// 决定/etc/vsftpd/user_list文件是否启用生效。YES则生效，NO不生效。<br>userlist_deny=YES&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>// 决定/etc/vsftpd/user_list文件中的用户是允许访问还是不允许访问。若设置为YES，则/etc/vsftpd/user_list 文件中的用户将不允许访问FTP服务器；若设置为NO，则只有vsftpd.user_list文件中的用户，才能访问FTP服务器。</p>
<p>&nbsp;</p>
<p>5．设置访问速度&nbsp;<br>anon_max_rate=0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>//设置匿名用户所能使用的最大传输速度，单位为b/s。若设置为0，则不受速度限制，此为默认值。<br>local_max_rate=0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>// 设置本地用户所能使用的最大传输速度。默认为0，不受限制。</p>
<p>&nbsp;</p>
<p>6．定义用户配置文件&nbsp;<br>在vsftpd服务器中，不同用户还可使用不同的配置，这要通过用户配置文件来实现。<br>user_config_dir=/etc/vsftpd/userconf //用于设置用户配置文件所在的目录。<br>设置了该配置项后，当用户登录FTP服务器时，系统就会到/etc/vsftpd/userconf目录下读取与当前用户名相同的文件，并根据文件中的配 置命令，对当前用户进行更进一步的配置。比如，利用用户配置文件，可实现对不同用户进行访问的速度进行控制，在各用户配置文件中，定义 local_max_rate配置，以决定该用户允许的访问速度。</p>
<p>&nbsp;</p>
<p>7．与连接相关的设置&nbsp;<br>listen=YES&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>//设置vsftpd服务器是否以standalone模式运行。以standalone模式运行是一种较好的方式，此时listen必须设置为YES， 此为默认值，建议不要更改。很多与服务器运行相关的配置命令，需要此运行模式才有效。若设置为NO，则vsftpd不是以独立的服务运行，要受 xinetd服务的管理控制，功能上会受限制。</p>
<p>max_clients=0<br>//设置vsftpd允许的最大连接数，默认为0，表示不受限制。若设置为150时，则同时允许有150个连接，超出的将拒绝建立连接。只有在以standalone模式运行时才有效。</p>
<p>max_per_ip=0<br>// 设置每个IP地址允许与FTP服务器同时建立连接的数目。默认为0，不受限制。通常可对此配置进行设置，防止同一个用户建立太多的连接。只有在以standalone模式运行时才有效。</p>
<p>listen_address=IP地址&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>//设置在指定的IP地址上侦听用户的FTP请求。若不设置，则对服务器所绑定的所有IP地址进行侦听。只有在以standalone模式运行时才有效。 对于只绑定了一个IP地址的服务器，不需要配置该项，默认情况下，配置文件中没有该配置项。若服务器同时绑定了多个IP地址，则应通过该配置项，指定在哪 个IP地址上提供FTP服务，即指定FTP服务器所使用的IP地址。<br>注意：设置此值前后，可以通过netstat -tnl对比端口的监听情况</p>
<p>accept_timeout=60&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>//设置建立被动（PASV）数据连接的超时时间，单位为秒，默认值为60。<br>connect_timeout=60&nbsp;&nbsp;&nbsp;&nbsp;<br>// PORT方式下建立数据连接的超时时间，单位为秒。<br>data_connection_timeout=300&nbsp;&nbsp;&nbsp;<br>//设置建立FTP数据连接的超时时间，默认为300秒。</p>
<p>idle_session_timeout＝600&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>//设置多长时间不对FTP服务器进行任何操作，则断开该FTP连接，单位为秒，默认为600秒。即设置发呆的逾时时间，在这个时间内，若没有数据传送或指令的输入，则会强行断开连接。<br>pam_service_name=vsftpd&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>//设置在PAM所使用的名称，默认值为vsftpd。</p>
<p>setproctitle_enable=NO|YES&nbsp;&nbsp;&nbsp;<br>//设置每个与FTP服务器的连接，是否以不同的进程表现出来，默认值为NO，此时只有一个名为vsftpd的进程。若设置为YES，则每个连接都会有一个vsftpd进程，使用“ps -ef|grep ftp”命令可查看到详细的FTP连接信息。安全起见，建议关闭。</p>
<p>&nbsp;PS:有时候不能上传文件，查看锁定目录权限和allow_writeable_chroot=YES 还可以查看下</p>
<p>getsebool -a|grep ftp</p>
<p>输入setsebool -P ftpd_full_access=on打开权限即可：</p>
<p>getsebool -a|grep ftp查看：</p>
<p>getsebool -a|grep ftp</p>
<p>ftpd_anon_write –&gt; off</p>
<p>ftpd_connect_all_unreserved –&gt; off</p>
<p>ftpd_connect_db –&gt; off</p>
<p>ftpd_full_access –&gt; on</p>
<p>ftpd_use_cifs –&gt; off</p>
<p>ftpd_use_fusefs –&gt; off</p>
<p>ftpd_use_nfs –&gt; off</p>
<p>ftpd_use_passive_mode –&gt; off</p>
<p>httpd_can_connect_ftp –&gt; off</p>
<p>httpd_enable_ftp_server –&gt; off</p>
<p>tftp_anon_write –&gt; off</p>
<p>tftp_home_dir –&gt; off</p>
<h2 id="vsftp用户锁定目录折腾好久，只对自己做一个小笔记而已。"><a href="#vsftp用户锁定目录折腾好久，只对自己做一个小笔记而已。" class="headerlink" title="vsftp用户锁定目录折腾好久，只对自己做一个小笔记而已。"></a>vsftp用户锁定目录折腾好久，只对自己做一个小笔记而已。</h2>]]></content>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title>windows2012 RDP 连接失败</title>
    <url>/2023/120114297.html</url>
    <content><![CDATA[<p>   完美解决RDO”连接无法继续，因为未启用身份验证，并且远程计算机需要启用身份验证以进行连接” </p>
<p><img src="/../images/20231201_1.jpg" alt="img"> </p>
<p>解决：<br>1.先用win7自带远程工具mstsc连接到Win10 （或者 服务器Windows Server 2016 ）<br>2.开始-运行-gpedit.msc，进入组策略编辑器<br>3.找到左侧边栏 计算机配置-管理模板-Windows组件-远程桌面服务-远程桌面会话主机-【安全】项<br>4.修改“远程（RDP）连接要求使用指定的安全层”，改为启用，安全层选择RDP<br>5.修改“要求使用网络级别的身份验证对远程连接的用户进行身份验证”，改为禁用<br>6.重启计算机 （或者运行 gpupdate 更新组策略）</p>
<p>.<img src="/../images/20231201_2.jpg" alt="img"></p>
<p>打开【安全】项的原始状态是： (计算机配置-管理模板-Windows组件-远程桌面服务-远程桌面会话主机-【安全】)</p>
<p>​    需要修改的是右边窗口的两项：“****远程（RDP）连接要求使用指定的安全层*<em><strong>” 、“</strong></em>*要求使用网络级别的身份验证对远程连接的用户进行身份验证****”</p>
<p><img src="/../images/20231201_3.jpg" alt="img"> </p>
<p>开始修改，如下方两个截图说明：</p>
<p><img src="/../images/20231201_4.jpg" alt="img"> </p>
<p><img src="/../images/20231201_5.jpg" alt="img"> </p>
<p>完成。</p>
<p>转自：<a href="https://www.579yun.cn/helparticle/44.html">https://www.579yun.cn/helparticle/44.html</a></p>
]]></content>
      <tags>
        <tag>点滴</tag>
      </tags>
  </entry>
  <entry>
    <title>xtrabackup还原mysql</title>
    <url>/2023/11284499.html</url>
    <content><![CDATA[<p>1.下载ALI平台备份包：</p>
<p>wget -c  “<a href="http://rdsbak-shanghai-v2-3az.oss-cn-shanghai-internal.aliyuncs.com/custins69321456/hins25992165_data_20230823211743_qp.xb?Expires=16931mOQ1VDcN">http://rdsbak-shanghai-v2-3az.oss-cn-shanghai-internal.aliyuncs.com/custins69321456/hins25992165_data_20230823211743_qp.xb?Expires=16931mOQ1VDcN</a>…..” -O 2023082121_qp.xb &gt; /tmp/download.log </p>
<p>命令：nohup wget -c -t 0 “备份文件下载地址” -O 下载的目标路径及文件名 &gt; 下载输出日志到对应文件 &amp;</p>
<p>示例：nohup wget -c -t 0 “<a href="https://example.aliyundoc.com/examplebackup.qp.xb">https://example.aliyundoc.com/examplebackup.qp.xb</a>“ -O /backup/examplebackup.qp.xb &gt; /tmp/download.log &amp;</p>
<p>各命令代表含义如下：</p>
<p>-t 0：无限重试。</p>
<p>-c：支持断点续传。</p>
<p>-O：下载的目标路径及文件名。</p>
<p>nohup：避免因手误执行复制操作或者终端断开连接，把正在进行的下载中断，且当下载完毕后，之前的进程将会自动退出。</p>
<p>命令：nohup curl -C - –retry 10 “备份文件下载地址” -o 自定义文件名 &gt; 下载输出日志到对应文件 &amp;</p>
<p>示例：nohup curl -C –retry 10 “<a href="https://example.aliyundoc.com/examplebackup.qp.xb">https://example.aliyundoc.com/examplebackup.qp.xb</a>“ -o backup.qp.xb &gt; /tmp/download.log &amp;</p>
<p>各命令代表含义如下：</p>
<p>–retry 10：任务失败时的重试次数，以上示例表示重试10次。</p>
<p>-C -：支持自动断点续传。</p>
<p>-o：下载的目标路径及文件名。</p>
<p>nohup：避免因手误执行复制操作或者终端断开连接，把正在进行的下载中断，且当下载完毕后，之前的进程将会自动退出。</p>
<p>2  XtraBackup 还原</p>
<p>下载Percona XtraBackup 2.4.28为例，安装命令如下：</p>
<p>如果是MySQL 5.7、5.6或5.5实例，下载并安装Percona XtraBackup 2.4，如果是MySQL 8.0实例，下载并安装Percona XtraBackup 8.0，具体请参见<a href="https://docs.percona.com/percona-xtrabackup/8.0/installation.html">Percona XtraBackup 8.0</a>。</p>
<p>wget <a href="https://downloads.percona.com/downloads/Percona-XtraBackup-2.4/Percona-XtraBackup-2.4.28/binary/redhat/7/x86_64/percona-xtrabackup-24-2.4.28-1.el7.x86_64.rpm">https://downloads.percona.com/downloads/Percona-XtraBackup-2.4/Percona-XtraBackup-2.4.28/binary/redhat/7/x86_64/percona-xtrabackup-24-2.4.28-1.el7.x86_64.rpm</a></p>
<p> sudo yum localinstall -y percona-xtrabackup-24-2.4.28-1.el7.x86_64.rpm</p>
<p> 安装解压工具qpress：</p>
<p>## 下载可执行文件的tar包</p>
<p>wget “<a href="https://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/file-manage-files/zh-CN/20230406/flxd/qpress-11-linux-x64.tar">https://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/file-manage-files/zh-CN/20230406/flxd/qpress-11-linux-x64.tar</a>“</p>
<p> ## 解压下载的tar包，取出可执行文件</p>
<p>tar -xvf qpress-11-linux-x64.tar</p>
<p> ## 设置qpress文件的执行权限</p>
<p>sudo chmod 775 qpress</p>
<p> ## 拷贝qpress到/usr/bin中</p>
<p>sudo cp qpress /usr/bin</p>
<p>解压：</p>
<p>cat 20230823211743_qp.xb |xbstream -x -v -C /data/mysql_data/</p>
<p>innobackupex –decompress –remove-original /data/mysql_data/</p>
<p>## 步骤一：解包</p>
<p>cat 20230823211743_qp.xb |xbstream -x -v -C /data/mysql_data/</p>
<p> ## 步骤二：解压</p>
<p>### MySQL 5.5/5.6/5.7</p>
<p>innobackupex –decompress –remove-original /data/mysql_data/</p>
<p><img src="/../images/20231128_1.png" alt="img"> </p>
<p>Mysql5.7恢复：</p>
<p>innobackupex –defaults-file=/var/mysql_bkdata/backup-my.cnf –apply-log /data/mysql_data/</p>
<p><img src="/../images/20231128_2.png" alt="img"> </p>
<p>编辑my.cnf</p>
<p>datadir=/data/mysql/</p>
<p>innodb_undo_tablespaces=2</p>
<p>innodb_undo_directory=/data/mysql/</p>
<p>#@</p>
<p> 修改****datadir****的参数取值为/var/mysql_newdata。</p>
<p>放大查看复制代码</p>
<p>datadir = /var/mysql_newdata</p>
<p> mysql_newdata为自建数据库的新数据目录，已在[准备工作]中创建。</p>
<p>在my.cnf中添加如下内容。</p>
<p>innodb_undo_tablespaces=2</p>
<p>innodb_undo_directory=/var/mysql_newdata</p>
<p>参数****innodb_undo_tablespaces****的取值需要与/var/mysql_bkdata/backup-my.cnf中的取值相同，您可以使用cat /var/mysql_bkdata/backup-my.cnf | grep innodb_undo_tablespaces查询。</p>
<p>恢复数据。</p>
<p>sudo innobackupex –defaults-file=/etc/my.cnf –copy-back /data/mysql_data/</p>
<p>从备份目录copy到数据目录</p>
<p><img src="/../images/20231128_3.png" alt="img"> </p>
<p><img src="/../images/20231128_4.png" alt="img"> </p>
<p>给于mysql新目录权限，进入mysql</p>
]]></content>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title>zabbix 清理历史数据</title>
    <url>/2023/071761914.html</url>
    <content><![CDATA[<p> 项目上线不到一个月，zabbix数据居然快100G，监控项太多，数据量太大，zabbix负载重，暂时不想升级硬件，只好内部挖掘下，清除下历史数据；一般保留1个月的数据，zabbix这个项目只是做监控报警用，数据保留太多没太大参考意义；</p>
<p>&nbsp; &nbsp; 一般都是这几个表太大，&nbsp;history，&nbsp;history_uint，history_log，有的直接了当直接清空表，简洁方便，不过要是有人需要参考数据，那还蛮尴尬的；有的做一个独立分表，做存储过程，蛮高效，不过项目不一样只做简单监控不必那么麻烦；</p>
<p>套路都一样：停掉zabbix，mysql添加skip new以便于删除数据后压缩存储空间，截取需要清除的时间点：</p>
<p>root@Testl]$ date +%s -d”20160929”</p>
<p>1475078400</p>
<p>mysql&gt; delete from history where clock&lt;1475078400;</p>
<p>Query OK, 36093 rows affected (43.64 sec)</p>
<p>&nbsp;</p>
<p>mysql&gt; delete from history_uint whereclock &lt; 1475078400;</p>
<p>Query OK, 21501392 rows affected (25 min51.48 sec)</p>
<p>&nbsp;</p>
<p>mysql&gt; optimize table history;</p>
<p>Query OK, 12175692 rows affected (5 min9.16 sec)</p>
<p>Records: 12175692&nbsp; Duplicates: 0&nbsp;Warnings: 0</p>
<p>&nbsp;</p>
<p>mysql&gt; optimize table history_uint;</p>
<p>Query OK, 145195609 rows affected (54 min29.07 sec)</p>
<p>Records: 145195609&nbsp; Duplicates: 0&nbsp;Warnings: 0</p>
<p>漫长时间等待以后看下效果：</p>
<p>原来数据：</p>
<p>-rw-rw—- 1 mysql mysql 1.4G Oct 28 13:23history.ibd</p>
<p>-rw-rw—- 1 mysql mysql&nbsp; 12M Oct 28 13:23 items.ibd</p>
<p>-rw-rw—- 1 mysql mysql&nbsp; 96M Oct 28 13:23 events.ibd</p>
<p>-rw-rw—- 1 mysql mysql&nbsp; 17G Oct 28 13:23 history_uint.ibd</p>
<p>-rw-rw—- 1 mysql mysql&nbsp; 56G Oct 28 13:23 history_log.ibd</p>
<p>-rw-rw—- 1 mysql mysql 252M Oct 28 13:23 trends_uint.ibd</p>
<p>-rw-rw—- 1 mysql mysql&nbsp; 72M Oct 28 13:23 trends.ibd</p>
<p>-rw-rw—- 1 mysql mysql 112K Oct 28 13:59sessions.ibd</p>
<p>压缩中：</p>
<p>缩进过程生成/#sql-5f11_3.ibd文件，作业完毕就是history_uint.ibd文件；</p>
<p>find -size +50M -exec ls -lh {} ;</p>
<p>-rw-rw—- 1 mysql mysql 960M Oct 28 14:42./history.ibd</p>
<p>-rw-rw—- 1 mysql mysql 9.2G Oct 28 15:31./#sql-5f11_3.ibd</p>
<p>-rw-rw—- 1 mysql mysql 56G Oct 28 13:23./history_log.ibd</p>
<p>-rw-rw—- 1 mysql mysql 96M Oct 28 13:23 ./events.ibd</p>
<p>-rw-rw—- 1 mysql mysql 252M Oct 28 13:23./trends_uint.ibd</p>
<p>-rw-rw—- 1 mysql mysql 72M Oct 28 13:23./trends.ibd</p>
<p>-rw-rw—- 1 mysql mysql 17G Oct 28 14:59./history_uint.ibd</p>
<p>最终删两个表以后数据：</p>
<p>zabbix]$ find -size +50M -execls -lh {} ;</p>
<p>-rw-rw—- 1 mysql mysql 960M Oct 28 15:42./history.ibd</p>
<p>-rw-rw—- 1 mysql mysql 56G Oct 28 15:42./history_log.ibd</p>
<p>-rw-rw—- 1 mysql mysql 96M Oct 28 15:42./events.ibd</p>
<p>-rw-rw—- 1 mysql mysql 252M Oct 28 15:41./trends_uint.ibd</p>
<p>-rw-rw—- 1 mysql mysql 72M Oct 28 15:41./trends.ibd</p>
<p>-rw-rw—- 1 mysql mysql 11G Oct 28 15:42./history_uint.ibd</p>
<p>完了以后，重启mysql，zabbix，nginx试试；</p>
<p>看着history_log那么大好忧伤，准备truncate掉。以后可以做个脚本，每月定期执行删除记录；</p>
<hr>
]]></content>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title>zabbix 设置163报警邮箱</title>
    <url>/2023/120119617.html</url>
    <content><![CDATA[<h2 id="1-测试端口是否开放："><a href="#1-测试端口是否开放：" class="headerlink" title="1.测试端口是否开放："></a>1.测试端口是否开放：</h2><p>nc -w 2 smtp.exmail.qq.com 465 &lt; /dev/null &amp;&amp; echo “port is ok”</p>
<p>nc -w 2 smtp.exmail.qq.com 25 &lt; /dev/null &amp;&amp; echo “port is ok”</p>
<p>首先拿到163邮箱的授权码，邮箱设置–选择“POP/SMTP/IMAP”选项，选择“IMAP/SMTP服务”，点击开启，扫码页面可以选择扫码发送短信，或者点击下方“手动发送短信”，点击“我已发送”后，如果系统检测到用户成功发送短信，即获取到授权码。授权码可以在多个第三方客户端使用。</p>
<h2 id="2-配置163邮箱"><a href="#2-配置163邮箱" class="headerlink" title="2.配置163邮箱"></a>2.配置163邮箱</h2><p>zabbix路径:/usr/lib/zabbix/,执行：</p>
<p>certutil -A -n “GeoTrust SSL CA - G3” -t “Pu,Pu,Pu” -d /usr/lib/zabbix/.certs./ -i /usr/lib/zabbix/.certs./163.crt</p>
<p>certutil:  unable to open “/usr/lib/zabbix/.certs./163.crt” for reading (-5950, 2).</p>
<p>没有到.certs 目录下执行或者certs不可读</p>
<p>cd .certs/</p>
<p> certutil -A -n “GeoTrust SSL CA - G3” -t “Pu,Pu,Pu” -d ./ -i 163.crt</p>
<p>Notice: Trust flag u is set automatically if the private key is present.</p>
<p>依然报错；</p>
<p> echo “hehe” | mail -v -s “test”  <a href="mailto:abc1@qq.com">abc1@qq.com</a></p>
<p>Resolving host smtp.163.com . . .Could not resolve host: smtp.163.com</p>
<p>Vim /etc/mail.rc</p>
<p>set from=邮箱地址</p>
<p>set smtp=smtps://smtp.163.com:465</p>
<p>set smtp-auth-user=账号名不要加@</p>
<p>set smtp-auth-password=授权码</p>
<p>set smtp-auth=login</p>
<p>set ssl-verify=ignore</p>
<p>=后面不要“”</p>
<p>测试发邮件：</p>
<p> echo “邮件正文” | mail -s “ZABBIX-TEST” <a href="mailto:cxxx@163.com">cxxx@163.com</a></p>
<p>Resolving host smtp.163.com . . . done.</p>
<p>Connecting to 103.74.29.40:465 . . . connected.</p>
<p>Error initializing NSS: Unknown error -8015.</p>
<p>Error initializing NSS: Unknown error -8015.</p>
<p>“/root/dead.letter” 11/320</p>
<p>. . . message not sent.</p>
<p>很莫名奇妙，最终在root下面生产.certs，首先在/root下生成相应文件，在copy到zabbix路径下面；</p>
<p>cd /root</p>
<p> mkdir .certs</p>
<p> echo -n | openssl s_client -connect smtp.163.com:465 | sed -ne ‘/-BEGIN CERTIFICATE-/,/-END CERTIFICATE-/p’ &gt; /root/.certs/163.crt</p>
<p>depth=2 C = US, O = DigiCert Inc, OU = <a href="http://www.digicert.com/">www.digicert.com</a>, CN = DigiCert Global Root CA</p>
<p>verify return:1</p>
<p>depth=1 C = US, O = DigiCert Inc, CN = GeoTrust RSA CN CA G2</p>
<p>verify return:1</p>
<p>depth=0 C = CN, ST = zhejiang, L = hangzhou, O = “NetEase (Hangzhou) Network Co., Ltd”, CN = *.163.com</p>
<p>verify return:1</p>
<p>DONE</p>
<p>certutil -A -n “GeoTrust SSL CA” -t “C,,” -d /root/.certs -i /root/.certs/163.crt</p>
<p>certutil -A -n “GeoTrust Global CA” -t “C,,” -d /root/.certs -i /root/.certs/163.crt</p>
<p>Cd .certs</p>
<p>certutil -A -n “GeoTrust SSL CA - G3” -t “Pu,Pu,Pu” -d /root/.certs/./ -i /root/.certs/163.crt</p>
<p>Notice: Trust flag u is set automatically if the private key is present.</p>
<p> ls /root/.certs/</p>
<p>163.crt  cert8.db  key3.db  secmod.db</p>
<p>certutil -L -d /root/.certs</p>
<p>Certificate Nickname                     Trust Attributes</p>
<p>​                               SSL,S/MIME,JAR/XPI</p>
<p>GeoTrust SSL CA                        P,P,P</p>
<p>cp -a /root/.certs/ /etc/zabbix/ &amp;&amp; cd /etc/zabbix &amp;&amp; chmod 777 -R .certs</p>
<p> tail -10f /etc/mail.rc</p>
<p>set from=<a href="mailto:email@163.com">email@163.com</a></p>
<p>set smtp=smtps://smtp.163.com:465</p>
<p>set smtp-auth-user=用户名不带@</p>
<p>set smtp-auth-password=授权码</p>
<p>set smtp-auth=login</p>
<p>set ssl-verify=ignore</p>
<p>set nss-config-dir=/etc/zabbix/.certs</p>
<p> echo “邮件正文” | mail -s “ZABBIX-TEST” <a href="mailto:cxxx@163.com">cxxx@163.com</a></p>
<p>成功了；</p>
<p>Zabbix安装，参照官网<a href="https://www.zabbix.com/cn/download">https://www.zabbix.com/cn/download</a></p>
<p>或者网上一大堆源码安装教程；</p>
<h2 id="3-邮件报警配置："><a href="#3-邮件报警配置：" class="headerlink" title="3.邮件报警配置："></a>3.邮件报警配置：</h2><p>Zabbix5.0安装调试完毕，邮件系统发送，给多用户发送遇到了问题，期初创建了多个用户，用163邮件通知，也有sendmail脚本通知，钉钉通知脚本都用过，</p>
<p>设置了3种通知方式：163邮件通知，钉钉报警给机器人，sendmail脚本发送报警；</p>
<p><img src="/../images/20231201_6.png"></p>
<p> 1）163邮件通知：</p>
<p><img src="/../images/20231201_7.png"></p>
<p><img src="/../images/20231201_8.png"></p>
<p>消息模版：</p>
<p>问题：</p>
<p>主题：</p>
<p>TRIGGER.STATUS,服务器:HOSTNAME1,发生:TRIGGER.NAME</p>
<p>消息：</p>
<p>告警主机:HOST.NAME</p>
<p>告警IP:HOST.IP</p>
<p>告警时间:EVENT.DATE-EVENT.TIME</p>
<p>告警等级:TRIGGER.SEVERITY</p>
<p>告警信息:TRIGGER.NAME:ITEM.VALUE</p>
<p>问题详情:ITEM.NAME:ITEM.VALUE</p>
<p>当前状态:TRIGGER.STATUS:ITEM.VALUE</p>
<p>事件ID:EVENT.ID</p>
<p>——-FROM ZABBIX 平台——-163邮局—-</p>
<p>问题恢复：</p>
<p>主题：</p>
<p>恢复{TRIGGER.STATUS}, 服务器:{HOSTNAME1}: {TRIGGER.NAME} 已恢复！</p>
<p>消息：</p>
<p>告警主机: {HOSTNAME1}</p>
<p>主机地址: {HOST.IP}</p>
<p>告警等级: {TRIGGER.SEVERITY}</p>
<p>监控项目: {TRIGGER.KEY1}</p>
<p>问题详情: {ITEM.NAME}:{ITEM.VALUE}</p>
<p>当前状态: {TRIGGER.STATUS}: {ITEM.VALUE1}</p>
<p>告警信息: {TRIGGER.NAME}</p>
<p>告警时间: {EVENT.DATE} {EVENT.TIME}</p>
<p>事件ID: {EVENT.ID}</p>
<p>——来自zabbix监控平台–163邮局—–</p>
<p>问题更新：</p>
<p>Updated problem in {EVENT.AGE}: {EVENT.NAME}</p>
<p>消息：</p>
<p>{USER.FULLNAME} {EVENT.UPDATE.ACTION} problem at {EVENT.UPDATE.DATE} {EVENT.UPDATE.TIME}.</p>
<p>{EVENT.UPDATE.MESSAGE}</p>
<p>Current problem status is {EVENT.STATUS}, age is {EVENT.AGE}, acknowledged: {EVENT.ACK.STATUS}.</p>
<p>——来自zabbix监控平台–163邮局—–</p>
<p> 2）Sendmail.sh</p>
<p>脚本：</p>
<figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">\#!/bin/bash</span><br><span class="line"></span><br><span class="line">\#export.UTF-8</span><br><span class="line"></span><br><span class="line">FILE=/var/log/zabbix/mailtmp.txt</span><br><span class="line"></span><br><span class="line">echo "$3" &gt;$FILE</span><br><span class="line"></span><br><span class="line">dos2unix -k $FILE</span><br><span class="line"></span><br><span class="line">/bin/mail -s "$2" $1 &lt; $FILE</span><br><span class="line"></span><br><span class="line">\#!/bin/bash</span><br><span class="line"></span><br><span class="line">\#messages=`echo $3 | tr '\r\n' '\n'`</span><br><span class="line"></span><br><span class="line">\#subject=`echo $2 | tr '\r\n' '\n'`</span><br><span class="line"></span><br><span class="line">\#echo "${messages}" | mail -v -s "${subject}" $1 &gt;&gt;/var/log/zabbix/mailx.log 2&gt;&amp;1</span><br></pre></td></tr></tbody></table></figure>


<p>消息模版基本一致；</p>
<p>3）钉钉告警：</p>
<p>钉钉脚本：</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">\<span class="comment">#!/usr/bin/env python</span></span><br><span class="line"></span><br><span class="line">\<span class="comment">#coding:utf-8</span></span><br><span class="line"></span><br><span class="line">\<span class="comment">#zabbix钉钉报警</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> requests,json,sys,os,datetime</span><br><span class="line"></span><br><span class="line">webhook=<span class="string">"https://oapi.dingtalk.com/robot/send?access_token=21211212111abcababcb..."</span>    <span class="comment">#说明：这里改为自己创建的机器人的webhook的值，钉钉个人现在不好申请了；</span></span><br><span class="line"></span><br><span class="line">user=sys.argv[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">text=sys.argv[<span class="number">3</span>]</span><br><span class="line"></span><br><span class="line">data={</span><br><span class="line"></span><br><span class="line">  <span class="string">"msgtype"</span>: <span class="string">"text"</span>,</span><br><span class="line"></span><br><span class="line">  <span class="string">"text"</span>: {</span><br><span class="line"></span><br><span class="line">​    <span class="string">"content"</span>: text</span><br><span class="line"></span><br><span class="line">  },</span><br><span class="line"></span><br><span class="line">  <span class="string">"at"</span>: {</span><br><span class="line"></span><br><span class="line">​    <span class="string">"atMobiles"</span>: [</span><br><span class="line"></span><br><span class="line">​      user</span><br><span class="line"></span><br><span class="line">​    ],</span><br><span class="line"></span><br><span class="line">​    <span class="string">"isAtAll"</span>: <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">  }</span><br><span class="line"></span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">headers = {<span class="string">'Content-Type'</span>: <span class="string">'application/json'</span>}</span><br><span class="line"></span><br><span class="line">x=requests.post(url=webhook,data=json.dumps(data),headers=headers)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> os.path.exists(<span class="string">"/usr/local/zabbix/log/ding.log"</span>):</span><br><span class="line"></span><br><span class="line">  f=<span class="built_in">open</span>(<span class="string">"/usr/local/zabbix/log/ding.log"</span>,<span class="string">"a+"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line"></span><br><span class="line">  f=<span class="built_in">open</span>(<span class="string">"/usr/local/zabbix/log/ding.log"</span>,<span class="string">"w+"</span>)</span><br><span class="line"></span><br><span class="line">f.write(<span class="string">"\n"</span>+<span class="string">"--"</span>*<span class="number">30</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> x.json()[<span class="string">"errcode"</span>] == <span class="number">0</span>:</span><br><span class="line"></span><br><span class="line">  f.write(<span class="string">"\n"</span>+<span class="built_in">str</span>(datetime.datetime.now())+<span class="string">"   "</span>+<span class="built_in">str</span>(user)+<span class="string">"   "</span>+<span class="string">"发送成功"</span>+<span class="string">"\n"</span>+<span class="built_in">str</span>(text))</span><br><span class="line"></span><br><span class="line">  f.close()</span><br><span class="line"></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line"></span><br><span class="line">  f.write(<span class="string">"\n"</span>+<span class="built_in">str</span>(datetime.datetime.now()) + <span class="string">"   "</span> + <span class="built_in">str</span>(user) + <span class="string">"   "</span> + <span class="string">"发送失败"</span> + <span class="string">"\n"</span> + <span class="built_in">str</span>(text))</span><br><span class="line"></span><br><span class="line">  f.close()</span><br></pre></td></tr></tbody></table></figure>

<p>Zabbix_server.conf</p>
<p>设置脚本路径：AlertScriptsPath=/usr/lib/zabbix/alertscripts</p>
<p>ExternalScripts=/usr/lib/zabbix/externalscripts</p>
<p>所监控的服务器设置监控脚本：/etc/zabbix/zabbix_agentd.conf</p>
<p># UserParameter=</p>
<p>UserParameter=dis.process,/usr/lib/zabbix/alertscripts/discovery_process.sh</p>
<p>UserParameter=proc.check[*],/usr/lib/zabbix/alertscripts/process_check.sh $1 $2 $3</p>
<p>遇到问题：邮件只能发送给admin，建立的其他用户一直没收到邮件，后来添加到admin用户以后可以收到，其他用户没收到邮件挺奇怪的事情，现在没头绪。</p>
<p><img src="/../images/20231201_9.png"></p>
]]></content>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title>zabbix3.0.1安装过程的小坑</title>
    <url>/2023/081629672.html</url>
    <content><![CDATA[<p>1.安装</p>
<p>首先lamp环境安装完毕，开始安装zabbix；</p>
<p>下载完毕zabbix-3.0.1.tar.gz，解压</p>
<p>cd &nbsp;zabbix-3.0.1</p>
<p>./configure –prefix=/usr/local/zabbix&nbsp; –enable-server \</p>
<p>–enable-proxy –enable-agent –enable-ipv6–with-mysql=/usr/local/mysql/bin/mysql_config –with-net-snmp \</p>
<p>–with-libcurl –with-openipmi–with-unixodbc –with-ldap –with-ssh2 –enable-java –enable-ipv6–enable-proxy</p>
<p>自行编译但是会报错：</p>
<p>Unixodbc没找到</p>
<p>mysql_config</p>
<p>configure: error: SSH2 library not found</p>
<p>yum install php-pecl-ssh2.x86_64 libssh2-devel.x86_64</p>
<p>yum install net-snmp-devel</p>
<p>yum -y install unixODBC*</p>
<p>yum install openldap openldap-devel</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; yumlist openldap</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; yumlist openldap-devel</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>checking for SSH2 support… yes</p>
<p>checking for OPENIPMI support… no</p>
<p>configure: error: Invalid OPENIPMIdirectory - unable to find ipmiif.h</p>
<p>&nbsp;</p>
<p>&nbsp;<a href="https://centos.pkgs.org/6/centos-x86_64/OpenIPMI-2.0.16-14.el6.x86_64.rpm.html">https://centos.pkgs.org/6/centos-x86_64/OpenIPMI-2.0.16-14.el6.x86_64.rpm.html</a></p>
<p>rpm -ivh OpenIPMI-2.0.16-14.el6.x86_64.rpm</p>
<p>&nbsp;<br>vhOpenIPMI-de<br>pum install OpenIPMI-devel</p>
<p>&nbsp;</p>
<p>报错checking for OPENIPMI support… no</p>
<p>configure: error: Invalid OPENIPMIdirectory - unable to find ipmiif.h</p>
<p>需要安装OpenIPMI和OpenIPMI-devel</p>
<p>&nbsp;</p>
<p>Yum安装OpenIPMI并下载OpenIPMI-devel-2.0.16-14.el6.x86_64.rpm</p>
<p> yum install OpenIPMI</p>
<p> rpm -ivhOpenIPMI-devel-2.0.16-14.el6.x86_64.rpm</p>
<p>报错 error: Failed dependencies:</p>
<p>pkgconfig(ncurses) is needed byOpenIPMI-devel-2.0.16-14.el6.x86_64</p>
<p> yum install ncurses-devel</p>
<p> rpm -ivhOpenIPMI-devel-2.0.16-14.el6.x86_64.rpm</p>
<p>onfigure: error: Invalid OPENIPMI directory- unable to find ipmiif.h</p>
<p>需要安装libssh2-devel</p>
<p>configure: error: Invalid OPENIPMIdirectory - unable to find ipmiif.h</p>
<p>需要安装OpenIPMI-devel</p>
<p>hecking for SSH2 support… yes</p>
<p>checking for OPENIPMI support… yes</p>
<p>checking for javac… no</p>
<p>configure: error: Unable to find”javac” executable in path</p>
<p>configure: error: Jabber library notfound&nbsp; #yum install iksemel-devel即可，</p>
<p>&nbsp;configure: error: LIBXML2 library not found&nbsp;&nbsp;&nbsp;</p>
<p>#yum install libxml2-devel&nbsp;</p>
<p>&nbsp;configure: error: unixODBC library notfound&nbsp;&nbsp;&nbsp;</p>
<p>#yum install unixODBC-devel&nbsp;&nbsp;</p>
<p>configure: error: Invalid OPENIPMIdirectory - unable to find ipmiif.h&nbsp;&nbsp;&nbsp;</p>
<p>#yum install OpenIPMI-devel&nbsp;&nbsp;</p>
<p>configure: error: Unable to find”javac” executable in path&nbsp;&nbsp;&nbsp;</p>
<p>#yum install java*&nbsp;&nbsp;&nbsp; 具体什么包没找，直接通配算逑，生产环境可去掉–enable-java选项</p>
<p>&nbsp;configure: error: Curl library not found&nbsp;</p>
<p>&nbsp;#yum install curl-devel</p>
<p>&nbsp;</p>
<p>make &amp;&amp; make install</p>
<ol start="2">
<li>导数据库顺序schema-p_w_picpath-data,</li>
</ol>
<p>添加系统软连接：</p>
<p>[<a href="mailto:root@vm_1_11zabbix-3.0.1">root@vm_1_11zabbix-3.0.1</a>]# ln -s /usr/local/zabbix/sbin/* /usr/local/sbin/</p>
<p>[root@vm_1_11 zabbix-3.0.1]# ln -s /usr/local/zabbix/bin/* /usr/local/bin/</p>
<p>添加zabbix服务对应的端口：</p>
<p>[root@vm_1_11 mysql]# vim /etc/services</p>
<p>在文件末尾添加：</p>
<p> Zabbix</p>
<p>zabbix-agent 10050/tcp # Zabbix Agent</p>
<p>zabbix-agent 10050/udp # Zabbix Agent</p>
<p>zabbix-trapper 10051/tcp # Zabbix Trapper</p>
<p>zabbix-trapper 10051/udp # Zabbix Trapper</p>
<p>修改zabbix配置文件：</p>
<p>[root@vm_1_11 tools]# vim /usr/local/zabbix/etc/zabbix_server.conf</p>
<p>修改以下几处：</p>
<p>DBName=zabbix</p>
<p>DBUser=zabbix</p>
<p>DBPassword=zabbix</p>
<p>AlertScriptsPath==/usr/local/zabbix/share/zabbix/alertscripts &nbsp;#zabbix运行脚本存放目录</p>
<p>DBPort=3306</p>
<p>&nbsp;vim /usr/local/zabbix/etc/zabbix_agentd.conf</p>
<p>Include=/usr/local/zabbix/etc/zabbix_agentd.conf.d/</p>
<p>UnsafeUserParameters=1 &nbsp;#启用自定义key</p>
<p>添加开机启动脚本：</p>
<p>[root@vm_1_11 tools]# cp /usr/local/src/zabbix-3.0.3/misc/init.d/fedora/core/zabbix_server /etc/rc.d/init.d/zabbix_server</p>
<p>客户端：</p>
<p>[root@vm_1_11 tools]# cp /usr/local/src/zabbix-3.0.3/misc/init.d/fedora/core/zabbix_agentd /etc/rc.d/init.d/zabbix_agentd</p>
<p>[root@vm_1_11 tools]# chmod a+x /etc/rc.d/init.d/zabbix_*</p>
<p>[root@vm_1_11 tools]# chkconfig zabbix_server on</p>
<p>[root@vm_1_11 tools]# chkconfig zabbix_agentd on</p>
<p>修改zabbix开机启动脚本中的zabbix安装目录：</p>
<p>[root@vm_1_11 tools]# vim /etc/rc.d/init.d/zabbix_server</p>
<p>修改以下内容：</p>
<p>BASEDIR=/usr/local/zabbix/</p>
<p>[root@vm_1_11 tools]# vim /etc/rc.d/init.d/zabbix_agentd</p>
<p>修改以下内容：</p>
<p>BASEDIR=/usr/local/zabbix/</p>
<p>复制zabbix的web站点文件到nginx：</p>
<p>[root@vm_1_11 tools]# cp -r /usr/local/src/zabbix-3.0.3/frontends/php/* /usr/local/nginx/html/zabbix/</p>
<p>启动：</p>
<p>[root@vm_1_11 tools]# systemctl daemon-reload</p>
<p>[root@vm_1_11 tools]# service zabbix_server start</p>
<p>[root@vm_1_11 tools]# service zabbix_agentd start</p>
<p>&nbsp;查看进程：ps -eaf|grep zabbix_server</p>
<p>zabbix_server [7212]: cannot run as root!</p>
<p>添加zabbix用户；</p>
<p>在zabbix/setup/php 页面会检测信息可能会报错要都ok才能下一步哦，</p>
<p>按照报错信息调试vim /etc/php.ini</p>
<p>查找如下参数并修改为：</p>
<hr>
<p>post_max_size = 16M</p>
<p>max_execution_time = 300</p>
<p>max_input_time = 300</p>
<p><img src="/../images/20231114_1.png"></p>
<p>/etc/php.ini修改以后还是这样，可能php.ini路径修改了，</p>
<p>本例中就是到</p>
<p>-rw-r–r– 1 root root 73930 Mar 27 18:19php.ini</p>
<p>-rw-r–r– 1 root root 73928 Mar 27 18:18php.ini_0327</p>
<p>[root@VM_54_42_centos etc]# pwd</p>
<p>/usr/local/php/etc</p>
<p>vim /usr/local/nginx/html/zabbix/include/locales.inc.php</p>
<p>修改中文字符；chinese–true</p>
<p>邮件报警：在zabbix mkdir&nbsp;alertscripts vim send_email.sh</p>
<p>#!/bin/sh</p>
<p>#export.UTF-8</p>
<p>FILE=/var/log/zabbix/mailtmp.txt</p>
<p>echo “$3” &gt;$FILE</p>
<p>dos2unix -k $FILE</p>
<p>/bin/mail -s “$2” $1 &lt; $FILE</p>
<p>zabbix-管理–示警媒介类型–定制脚本-sendmail脚本，–添加联系人邮件。。</p>
]]></content>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title>zabbix监控业务进程变动</title>
    <url>/2023/111359213.html</url>
    <content><![CDATA[<p>Zabbix 监控进程宕机</p>
<p>  业务需求后端进程宕机以后能在短时间内迅速拉起，业务影响不大，但是开发需要查看coredump，要求能监控到pid变化；在现有构架下zabbix能监控并报警；</p>
<p>当然zabbix设置报警设置就不再一一</p>
<p>在每台服务器/etc/zabbix/zabbix_agentd.conf设置路径：此例只需要piddiff.sh</p>
<p>UserParameter=checkpid,sh /usr/local/script/piddiff.sh</p>
<p>UserParameter=test,sh /usr/local/script/test.sh</p>
<p>UserParameter=discovery.process,/usr/local/script/disprocess.sh</p>
<p>UserParameter=process.check[*],/usr/local/script/proc_check.sh $1 $2 $3</p>
<p>/usr/local/script下面存放脚本</p>
<p>Vim piddiff.sh</p>
<p>aapid为业务监控id 取值根据业务需求；</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment">#/bin/sh</span></span><br><span class="line"></span><br><span class="line">onl_ok=1</span><br><span class="line"></span><br><span class="line">onl_cored=3</span><br><span class="line"></span><br><span class="line"><span class="built_in">dir</span>=/usr/local/script</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [[ ! -f <span class="string">"<span class="variable">$dir</span>/old.txt"</span> ]];<span class="keyword">then</span></span><br><span class="line"></span><br><span class="line"> ps aux|grep aapid |grep -v grep|grep -v /bin/bash|awk  <span class="string">'{print $2,$11}'</span> &gt; <span class="variable">$dir</span>/old.txt</span><br><span class="line"></span><br><span class="line">      <span class="keyword">else</span></span><br><span class="line">    </span><br><span class="line">         <span class="built_in">sleep</span> 1s           </span><br><span class="line"></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"> ps aux|grep aapid |grep -v grep|grep -v /bin/bash|awk  <span class="string">'{print $2,$11}'</span> &gt; <span class="variable">$dir</span>/now.txt</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> ! diff -q <span class="variable">$dir</span>/old.txt  <span class="variable">$dir</span>/now.txt &gt; /dev/null; <span class="keyword">then</span></span><br><span class="line"></span><br><span class="line">          <span class="built_in">echo</span> <span class="variable">$onl_cored</span></span><br><span class="line">    </span><br><span class="line">          diff -c <span class="variable">$dir</span>/old.txt  <span class="variable">$dir</span>/now.txt &gt; <span class="variable">$dir</span>/`<span class="built_in">date</span> <span class="string">"+%Y%m%d%H%M"</span>`_diff.txt</span><br><span class="line">    </span><br><span class="line">          <span class="built_in">cat</span> <span class="variable">$dir</span>/now.txt &gt;<span class="variable">$dir</span>/old.txt</span><br><span class="line">    </span><br><span class="line">     <span class="keyword">else</span></span><br><span class="line">    </span><br><span class="line">          <span class="built_in">echo</span> <span class="variable">$onl_ok</span>    </span><br><span class="line"></span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></tbody></table></figure>

<p>一个简单的判断脚本；</p>
<p>Zabbix30秒会抓取一次，正常没变化为1，有变化为3，那么zabbix抓取数值为3则表示pid有变化，会发出警报；</p>
<p>Zabbix设置：</p>
<p>监控项模板添加如下：</p>
<p><img src="/../images/20231113_1.png"></p>
<p>触发器：{Template OS Linux:checkpid.last()}=3</p>
<p><img src="/../images/20231113_2.png"></p>
<hr>
]]></content>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
</search>
